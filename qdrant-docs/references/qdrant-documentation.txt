================================================================================
QDRANT DOCUMENTATION - COMPLETE COLLECTION
Scraped on: 2026-01-16 04:05:33
Total pages: 39
================================================================================

================================================================================
PAGE 1/39
================================================================================
Title: Qdrant Documentation
URL: https://qdrant.tech/documentation/
--------------------------------------------------------------------------------

Qdrant Documentation Qdrant is an AI-native vector database and a semantic search engine. You can use it to extract meaningful information from unstructured data.

Clone this repo now and build a search engine in five minutes.

Cloud Quickstart Local Quickstart Ready to start developing?

Qdrant is open-source and can be self-hosted. However, the quickest way to get started is with our free tier on Qdrant Cloud. It scales easily and provides a UI where you can interact with data.

Create your first Qdrant Cloud cluster today Get Started Optimize Qdrant's performance Boost search speed, reduce latency, and improve the accuracy and memory usage of your Qdrant deployment.

Learn More Documents Distributed Deployment Scale Qdrant beyond a single node and optimize for high availability, fault tolerance, and billion-scale performance.

Read More Documents Multitenancy Build vector search apps that serve millions of users. Learn about data isolation, security, and performance tuning.

Read More Blog Vector Quantization Learn about cutting-edge techniques for vector quantization and how they can be used to improve search performance.

Read More
================================================================================
PAGE 2/39
================================================================================
Title: Qdrant Overview
URL: https://qdrant.tech/documentation/overview/
--------------------------------------------------------------------------------

Qdrant Overview Welcome!

Whether you‚Äôre getting started with Qdrant Open-Source or Cloud, this brief primer will help you with understanding an overview of the platform.

It‚Äôs highly recommended you read this overview before starting your development with Qdrant!

Retrieval Process Vector search is a transformative information retrieval technique that goes beyond keyword matching to find data based on semantic meaning. It begins with embedding models , which convert unstructured data (text, images, audio) into dense vector embeddings , fixed-length lists of numbers that represent the data‚Äôs conceptual essence. These vectors are mapped into a high-dimensional vector space , where items with similar meanings are positioned closely together. This spatial organization allows a search for ‚Äúclimate change‚Äù to retrieve documents about ‚Äúglobal warming,‚Äù even if the exact words differ.

While dense vectors excel at capturing context, they can sometimes miss specific technical terms or unique identifiers. To bridge this gap, Qdrant also utilizes sparse vectors designed to capture precise lexical matches for specific keywords. Learn more in this guide .

The process of generating embeddings from unstructured data is called inference . On Qdrant Cloud, you can use Cloud Inference to let Qdrant generate embeddings on the server side. Alternatively, you can use a library like FastEmbed to generate embeddings on the client side.

The search process itself revolves into the concept of Top-K retrieval. When a user submits a request, it is instantly transformed into a query vector . The engine then calculates the similarity between this query vector and document vectors, returning the ‚ÄúTop-K‚Äù closest matches, where K is a user-defined number representing the desired volume of results. This allows developers to fine-tune the balance between the breadth of the search and the precision of the answers.

To deliver the most robust search experience, Qdrant enables Hybrid Retrieval with semantic and lexical search, which you can learn more about here .

Architecture Qdrants operates in a client-server architecture, providing official client libraries for Python, JavaScript/TypeScript, Rust, Go, .NET, and Java. However, Qdrant exposes HTTP and gRPC interfaces to facilitate integration with virtually any programming language.

Data Structure Qdrant collections are designed for horizontal and vertical scaling. You can learn about the details in the above diagram from links below: Collections Points Indexing Storage Distributed Deployment Strict Mode Deployments Qdrant supports multiple deployment models to match different infrastructure and operational needs. The right option depends on your security constraints and operational model: Qdrant-managed infrastructure ( Managed Cloud ), shared responsibility with your own clusters ( Hybrid Cloud ), or full ownership and independence ( Private Cloud or Open Source ).

Feature Benefits OSS Managed Hybrid Private Deployment Choose how and where to deploy your Qdrant vector database based on your infrastructure needs.

‚úÖ ‚úÖ ‚úÖ ‚úÖ High Availability Automatic failover and replication to ensure your vector search is always available.

‚ùå ‚úÖ ‚úÖ ‚úÖ Zero-Downtime Upgrades Upgrade your Qdrant database without any service interruption using replication.

‚ùå ‚úÖ ‚úÖ ‚úÖ Monitoring & Alerting Built-in monitoring and alerting to observe the health and performance of your clusters.

‚ùå ‚úÖ ‚úÖ ‚ùå Central Management UI A unified console to create, configure, and manage all your Qdrant database clusters.

‚ùå ‚úÖ ‚úÖ ‚ùå Horizontal & Vertical Scaling Scale your clusters up, down, or out with automatic shard rebalancing and resharding support.

‚ùå ‚úÖ ‚úÖ ‚úÖ Backups & Disaster Recovery Automated backups and restore functionality to ensure data durability and graceful recovery.

‚ùå ‚úÖ ‚úÖ ‚úÖ Data Privacy & Control Keep all user data within your own infrastructure and network, not accessible by external parties.

‚úÖ ‚ùå ‚úÖ ‚úÖ Multi-Cloud & On-Premises Deploy on AWS, GCP, Azure, on-premises, or edge locations based on your requirements.

‚úÖ ‚ùå ‚úÖ ‚úÖ Enterprise Support Access to Qdrant‚Äôs enterprise support services for production deployments.

‚ùå ‚úÖ ‚úÖ ‚úÖ No Infrastructure Management Qdrant fully manages your infrastructure, so you can focus on building your application.

‚ùå ‚úÖ ‚ùå ‚ùå Scaling Considerations The default configuration of Qdrant is sensible when you are starting to work on a POC or your side project. However, when transitioning to production and experiencing the growth of data size and concurrent users, your expectations regarding high availability, latency, or throughput will change. If you foresee scaling the service, you should build your system ready for these kinds of challenges from the outset. There are a few common scenarios you should be aware of, especially if you are taking your first steps with Qdrant, anticipate rapid growth soon, and want to make your system future-proof.

Memory Requirements Memory is a critical resource when scaling vector search. By default, Qdrant stores vectors in RAM for maximum search performance, but as collections grow to millions of vectors, keeping everything in memory becomes expensive. Qdrant lets you control the memory usage by offloading data to disk, and you can enable that mechanism at any time, even on an existing collection: Frequently accessed vectors naturally stay cached, while others are read from disk only when needed, if you store vectors on disk Graph traversal may require IO operations if you store the HNSW index on disk Put both on disk only when RAM is severely constrained, and ensure you have fast NVMe storage.

Filtering Vector search alone can provide a decent search experience to your users; however, semantic similarity is rarely the only factor you have to consider. Embeddings won‚Äôt capture attributes such as price, and typically, a filter on a specific payload attribute has to be applied. To make that filtering effective, there are some specific Qdrant mechanisms you should be aware of, including with payload indexes .

Payload Indexes The payload index is a helper data structure that enables effective filtering on a particular payload attribute. It‚Äôs a concept familiar from relational databases, where we create an index on a column that we often filter by. Similarly, in Qdrant, you should also make a payload index on a field used for filtering.

A unique aspect of the payload index is that it extends the HNSW graph, allowing filtering criteria to be applied during the semantic search phase. That means it‚Äôs a single-pass graph traversal, rather than pre- or post-filtering, which both have some drawbacks.

The fact that a payload index extends the HNSW graph means it‚Äôs more efficient to create it before indexing the data, as the optimizer will need to build the graph once. However, in some cases, you may already have a collection with a lot of vectors and recognize a need to filter by a specific attribute. In such cases, you can still create a payload index, yet it won‚Äôt immediately affect the HNSW graph .

ACORN is an additional mechanism that can improve the search accuracy if you have multiple high cardinality filters in your search operations.

Scaling Vertical scaling has natural limits - eventually, you‚Äôll hit the maximum capacity of available hardware, and single-node deployments lack redundancy. Optimize scaling with sharding , replication , and segment configuration options.

Sharding Qdrant uses sharding to split collections across multiple nodes, where each shard is an independent store of points. A common recommendation is to start with 12 shards, which provides flexibility to scale from 1 node up to 2, 3, 6, or 12 nodes without resharding. However, this approach can limit throughput on small clusters since each node manages multiple shards.

For optimal throughput, set shard_number equal to your node count (read more here). If you want to have better control over sharding, Qdrant supports custom shards .

Replication The replication factor determines how many copies of each shard exist.

For production systems, a replication factor of at least 2 is strongly recommended .

Segment Configuration Each shard stores data in multiple segments . A segment stores all the data structures of a subset of the points in a shard. Fewer segments create larger segments with better search throughput, as larger HNSW indexes require fewer comparisons. However, larger segments take longer to build and recreate, slowing writes and optimization. More segments mean faster indexing but lower search performance since queries scan more segments. Read more on segment configuration.

Safety Some of the collection-level operations may degrade performance of the Qdrant cluster. Qdrant‚Äôs strict mode prevents inefficient usage patterns through multiple controls: it may block filtering and updates on non-indexed payload fields, limit query result sizes and timeout durations, restrict the complexity and number of filter conditions, cap payload index counts, constrain batch upsert sizes, enforce maximum collection storage limits (for vectors, payloads, and point counts), and implement rate limiting for read and write operations to prevent system overload.

The OSS version does not enforce anything, but please consider enabling and configuring strict mode settings according to the application needs. Otherwise, some of the API calls may impact the performance of your cluster by using Qdrant in a suboptimal way.

Getting Help If you‚Äôre new to Qdrant, start with the free Essentials Course , which covers core concepts and best practices. For questions, troubleshooting, and community support, join the Discord Community - it‚Äôs the best place to get help from both Qdrant users and the core team. Paid customers have access to the Support Portal through the Qdrant Cloud Console, for direct technical assistance and priority response times.

================================================================================
PAGE 3/39
================================================================================
Title: No Title
URL: https://qdrant.tech/documentation/quick-start/
--------------------------------------------------------------------------------

================================================================================
PAGE 4/39
================================================================================
Title: Interfaces
URL: https://qdrant.tech/documentation/interfaces/
--------------------------------------------------------------------------------

Interfaces Qdrant supports these ‚Äúofficial‚Äù clients.

Note: If you are using a language that is not listed here, you can use the REST API directly or generate a client for your language using OpenAPI or protobuf definitions.

Client Libraries Client Repository Installation Version Python + (Client Docs) pip install qdrant-client[fastembed] Latest Release JavaScript / Typescript npm install @qdrant/js-client-rest Latest Release Rust cargo add qdrant-client Latest Release Go go get github.com/qdrant/go-client Latest Release .NET dotnet add package Qdrant.Client Latest Release Java Available on Maven Central Latest Release API Reference All interaction with Qdrant takes place via the REST API. We recommend using REST API if you are using Qdrant for the first time or if you are working on a prototype.

API Documentation REST API OpenAPI Specification gRPC API gRPC protobuf definitions gRPC Interface The gRPC methods follow the same principles as REST. For each REST endpoint, there is a corresponding gRPC method.

As per the configuration file , the gRPC interface is available on the specified port. service : grpc_port : 6334 Running the service inside of Docker will look like this: docker run -p 6333:6333 -p 6334:6334 \ -v $( pwd ) /qdrant_storage:/qdrant/storage:z \ qdrant/qdrant When to use gRPC: The choice between gRPC and the REST API is a trade-off between convenience and speed. gRPC is a binary protocol and can be more challenging to debug. We recommend using gRPC if you are already familiar with Qdrant and are trying to optimize the performance of your application.

================================================================================
PAGE 5/39
================================================================================
Title: Qdrant Web UI
URL: https://qdrant.tech/documentation/web-ui/
--------------------------------------------------------------------------------

Qdrant Web UI You can manage both local and cloud Qdrant deployments through the Web UI.

If you‚Äôve set up a deployment locally with the Qdrant Quickstart , navigate to http://localhost:6333/dashboard.

If you‚Äôve set up a deployment in a cloud cluster, find your Cluster URL in your cloud dashboard, at https://cloud.qdrant.io . Add :6333/dashboard to the end of the URL.

Access the Web UI Qdrant‚Äôs Web UI is an intuitive and efficient graphic interface for your Qdrant Collections, REST API and data points.

In the Console , you may use the REST API to interact with Qdrant, while in Collections , you can manage all the collections and upload Snapshots.

Qdrant Web UI features In the Qdrant Web UI, you can: Run HTTP-based calls from the console List and search existing collections Learn from our interactive tutorial You can navigate to these options directly. For example, if you used our quick start to set up a cluster on localhost, you can review our tutorial at http://localhost:6333/dashboard#/tutorial.

================================================================================
PAGE 6/39
================================================================================
Title: Collections
URL: https://qdrant.tech/documentation/concepts/collections/
--------------------------------------------------------------------------------

Collections A collection is a named set of points (vectors with a payload) among which you can search. The vector of each point within the same collection must have the same dimensionality and be compared by a single metric.

Named vectors can be used to have multiple vectors in a single point, each of which can have their own dimensionality and metric requirements.

Distance metrics are used to measure similarities among vectors.

The choice of metric depends on the way vectors obtaining and, in particular, on the method of neural network encoder training.

Qdrant supports these most popular types of metrics: Dot product: Dot - [wiki] Cosine similarity: Cosine - [wiki] Euclidean distance: Euclid - [wiki] Manhattan distance: Manhattan - [wiki] In addition to metrics and vector size, each collection uses its own set of parameters that controls collection optimization, index construction, and vacuum.

These settings can be changed at any time by a corresponding request.

Setting up multitenancy How many collections should you create?

In most cases, you should only use a single collection with payload-based partitioning. This approach is called multitenancy . It is efficient for most of users, but it requires additional configuration.

Learn how to set it up When should you create multiple collections?

When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.

Create a collection PUT /collections/{collection_name} { "vectors": { "size": 300, "distance": "Cosine" } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "size": 100, "distance": "Cosine" } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 100 , distance = models .

Distance .

COSINE ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 100 , distance : "Cosine" }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , VectorParamsBuilder , Distance }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 100 , Distance :: Cosine )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( "{collection_name}" , VectorParams . newBuilder (). setDistance ( Distance .

Cosine ). setSize ( 100 ). build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 100 , Distance = Distance .

Cosine } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 100 , Distance : qdrant .

Distance_Cosine , }), }) In addition to the required options, you can also specify custom values for the following collection options: hnsw_config - see indexing for details. wal_config - Write-Ahead-Log related configuration. See more details about WAL optimizers_config - see optimizer for details. shard_number - which defines how many shards the collection should have. See distributed deployment section for details. on_disk_payload - defines where to store payload data. If true - payload will be stored on disk only. Might be useful for limiting the RAM usage in case of large payload. quantization_config - see quantization for details. strict_mode_config - see strict mode for details.

Default parameters for the optional collection parameters are defined in configuration file .

See schema definitions and a configuration file for more information about collection and vector parameters.

Available as of v1.2.0 Vectors all live in RAM for very quick access. The on_disk parameter can be set in the vector configuration. If true, all vectors will live on disk. This will enable the use of memmaps , which is suitable for ingesting a large amount of data.

Collection with multiple vectors Available as of v0.10.0 It is possible to have multiple vectors per record.

This feature allows for multiple vector storages per collection.

To distinguish vectors in one record, they should have a unique name defined when creating the collection.

Each named vector in this mode has its distance and size: PUT /collections/{collection_name} { "vectors": { "image": { "size": 4, "distance": "Dot" }, "text": { "size": 8, "distance": "Cosine" } } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "image": { "size": 4, "distance": "Dot" }, "text": { "size": 8, "distance": "Cosine" } } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = { "image" : models .

VectorParams ( size = 4 , distance = models .

Distance .

DOT ), "text" : models .

VectorParams ( size = 8 , distance = models .

Distance .

COSINE ), }, ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { image : { size : 4 , distance : "Dot" }, text : { size : 8 , distance : "Cosine" }, }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder , VectorsConfigBuilder , }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut vectors_config = VectorsConfigBuilder :: default (); vectors_config . add_named_vector_params ( "image" , VectorParamsBuilder :: new ( 4 , Distance :: Dot ). build ()); vectors_config . add_named_vector_params ( "text" , VectorParamsBuilder :: new ( 8 , Distance :: Cosine ). build (), ); client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ). vectors_config ( vectors_config ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( "{collection_name}" , Map . of ( "image" , VectorParams . newBuilder (). setSize ( 4 ). setDistance ( Distance .

Dot ). build (), "text" , VectorParams . newBuilder (). setSize ( 8 ). setDistance ( Distance .

Cosine ). build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParamsMap { Map = { ["image"] = new VectorParams { Size = 4 , Distance = Distance .

Dot }, ["text"] = new VectorParams { Size = 8 , Distance = Distance .

Cosine }, } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfigMap ( map [ string ] * qdrant .

VectorParams { "image" : { Size : 4 , Distance : qdrant .

Distance_Dot , }, "text" : { Size : 8 , Distance : qdrant .

Distance_Cosine , }, }), }) For rare use cases, it is possible to create a collection without any vector storage.

Available as of v1.1.1 For each named vector you can optionally specify hnsw_config or quantization_config to deviate from the collection configuration. This can be useful to fine-tune search performance on a vector level.

Available as of v1.2.0 Vectors all live in RAM for very quick access. On a per-vector basis you can set on_disk to true to store all vectors on disk at all times. This will enable the use of memmaps , which is suitable for ingesting a large amount of data.

Vector datatypes Available as of v1.9.0 Some embedding providers may provide embeddings in a pre-quantized format.

One of the most notable examples is the Cohere int8 & binary embeddings .

Qdrant has direct support for uint8 embeddings, which you can also use in combination with binary quantization.

To create a collection with uint8 embeddings, you can use the following configuration: PUT /collections/{collection_name} { "vectors": { "size": 1024, "distance": "Cosine", "datatype": "uint8" } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "size": 1024, "distance": "Cosine", "datatype": "uint8" } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 1024 , distance = models .

Distance .

COSINE , datatype = models .

Datatype .

UINT8 , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { image : { size : 1024 , distance : "Cosine" , datatype : "uint8" }, }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , Datatype , Distance , VectorParamsBuilder , }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ). vectors_config ( VectorParamsBuilder :: new ( 1024 , Distance :: Cosine ). datatype ( Datatype :: Uint8 ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.Datatype ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( "{collection_name}" , VectorParams . newBuilder () . setSize ( 1024 ) . setDistance ( Distance .

Cosine ) . setDatatype ( Datatype .

Uint8 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 1024 , Distance = Distance .

Cosine , Datatype = Datatype .

Uint8 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 1024 , Distance : qdrant .

Distance_Cosine , Datatype : qdrant .

Datatype_Uint8 .

Enum (), }), }) Vectors with uint8 datatype are stored in a more compact format, which can save memory and improve search speed at the cost of some precision.

If you choose to use the uint8 datatype, elements of the vector will be stored as unsigned 8-bit integers, which can take values from 0 to 255 .

Collection with sparse vectors Available as of v1.7.0 Qdrant supports sparse vectors as a first-class citizen.

Sparse vectors are useful for text search, where each word is represented as a separate dimension.

Collections can contain sparse vectors as additional named vectors along side regular dense vectors in a single point.

Unlike dense vectors, sparse vectors must be named.

And additionally, sparse vectors and dense vectors must have different names within a collection.

PUT /collections/{collection_name} { "sparse_vectors": { "text": { } } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "sparse_vectors": { "text": { } } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = {}, sparse_vectors_config = { "text" : models .

SparseVectorParams (), }, ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { sparse_vectors : { text : { }, }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , SparseVectorParamsBuilder , SparseVectorsConfigBuilder , }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut sparse_vector_config = SparseVectorsConfigBuilder :: default (); sparse_vector_config . add_named_vector_params ( "text" , SparseVectorParamsBuilder :: default ()); client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . sparse_vectors_config ( sparse_vector_config ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.SparseVectorConfig ; import io.qdrant.client.grpc.Collections.SparseVectorParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setSparseVectorsConfig ( SparseVectorConfig . newBuilder () . putMap ( "text" , SparseVectorParams . getDefaultInstance ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , sparseVectorsConfig : ( "text" , new SparseVectorParams ()) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , SparseVectorsConfig : qdrant .

NewSparseVectorsConfig ( map [ string ] * qdrant .

SparseVectorParams { "text" : {}, }), }) Outside of a unique name, there are no required configuration parameters for sparse vectors.

The distance function for sparse vectors is always Dot and does not need to be specified.

However, there are optional parameters to tune the underlying sparse vector index .

Create collection from another collection To create a collection from another collection, use the Migration Tool . You can use it to either copy a collection within the same Qdrant instance or to copy a collection to another instance.

For example, to copy a collection from a local instance to a Qdrant Cloud instance, run the following command: docker run --net = host --rm -it registry.cloud.qdrant.io/library/qdrant-migration qdrant \ --source.url 'http://localhost:6334' \ --source.collection 'source-collection' \ --target.url 'https://example.cloud-region.cloud-provider.cloud.qdrant.io:6334' \ --target.api-key 'qdrant-key' \ --target.collection 'target-collection' \ --migration.batch-size 64 Check collection existence Available as of v1.8.0 GET http://localhost:6333/collections/{collection_name}/exists curl -X GET http://localhost:6333/collections/ { collection_name } /exists client . collection_exists ( collection_name = " {collection_name} " ) client . collectionExists ( "{collection_name}" ); client . collection_exists ( "{collection_name}" ). await ? ; client . collectionExistsAsync ( "{collection_name}" ). get (); await client .

CollectionExistsAsync ( "{collection_name}" ); import "context" client .

CollectionExists ( context .

Background (), "my_collection" ) Delete collection DELETE http://localhost:6333/collections/{collection_name} curl -X DELETE http://localhost:6333/collections/ { collection_name } client . delete_collection ( collection_name = " {collection_name} " ) client . deleteCollection ( "{collection_name}" ); client . delete_collection ( "{collection_name}" ). await ? ; client . deleteCollectionAsync ( "{collection_name}" ). get (); await client .

DeleteCollectionAsync ( "{collection_name}" ); import "context" client .

DeleteCollection ( context .

Background (), "{collection_name}" ) Update collection parameters Dynamic parameter updates may be helpful, for example, for more efficient initial loading of vectors.

For example, you can disable indexing during the upload process, and enable it immediately after the upload is finished.

As a result, you will not waste extra computation resources on rebuilding the index.

The following command enables indexing for segments that have more than 10000 kB of vectors stored: PATCH /collections/{collection_name} { "optimizers_config": { "indexing_threshold": 10000 } } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "optimizers_config": { "indexing_threshold": 10000 } }' client . update_collection ( collection_name = " {collection_name} " , optimizers_config = models .

OptimizersConfigDiff ( indexing_threshold = 10000 ), ) client . updateCollection ( "{collection_name}" , { optimizers_config : { indexing_threshold : 10000 , }, }); use qdrant_client :: qdrant :: { OptimizersConfigDiffBuilder , UpdateCollectionBuilder }; client . update_collection ( UpdateCollectionBuilder :: new ( "{collection_name}" ). optimizers_config ( OptimizersConfigDiffBuilder :: default (). indexing_threshold ( 10000 ), ), ) . await ? ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.UpdateCollection ; client . updateCollectionAsync ( UpdateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setOptimizersConfig ( OptimizersConfigDiff . newBuilder (). setIndexingThreshold ( 10000 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionAsync ( collectionName : "{collection_name}" , optimizersConfig : new OptimizersConfigDiff { IndexingThreshold = 10000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateCollection ( context .

Background (), & qdrant .

UpdateCollection { CollectionName : "{collection_name}" , OptimizersConfig : & qdrant .

OptimizersConfigDiff { IndexingThreshold : qdrant .

PtrOf ( uint64 ( 10000 )), }, }) The following parameters can be updated: optimizers_config - see optimizer for details. hnsw_config - see indexing for details. quantization_config - see quantization for details. vectors_config - vector-specific configuration, including individual hnsw_config , quantization_config and on_disk settings. params - other collection parameters, including write_consistency_factor and on_disk_payload . strict_mode_config - see strict mode for details.

Full API specification is available in schema definitions .

Calls to this endpoint may be blocking as it waits for existing optimizers to finish. We recommended against using this in a production database as it may introduce huge overhead due to the rebuilding of the index.

Update vector parameters Available as of v1.4.0 Qdrant 1.4 adds support for updating more collection parameters at runtime. HNSW index, quantization and disk configurations can now be changed without recreating a collection. Segments (with index and quantized data) will automatically be rebuilt in the background to match updated parameters.

To put vector data on disk for a collection that does not have named vectors, use "" as name: PATCH /collections/{collection_name} { "vectors": { "": { "on_disk": true } } } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "": { "on_disk": true } } }' To put vector data on disk for a collection that does have named vectors: Note: To create a vector name, follow the procedure from our Points .

PATCH /collections/{collection_name} { "vectors": { "my_vector": { "on_disk": true } } } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "my_vector": { "on_disk": true } } }' In the following example the HNSW index and quantization parameters are updated, both for the whole collection, and for my_vector specifically: PATCH /collections/{collection_name} { "vectors": { "my_vector": { "hnsw_config": { "m": 32, "ef_construct": 123 }, "quantization_config": { "product": { "compression": "x32", "always_ram": true } }, "on_disk": true } }, "hnsw_config": { "ef_construct": 123 }, "quantization_config": { "scalar": { "type": "int8", "quantile": 0.8, "always_ram": false } } } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "my_vector": { "hnsw_config": { "m": 32, "ef_construct": 123 }, "quantization_config": { "product": { "compression": "x32", "always_ram": true } }, "on_disk": true } }, "hnsw_config": { "ef_construct": 123 }, "quantization_config": { "scalar": { "type": "int8", "quantile": 0.8, "always_ram": false } } }' client . update_collection ( collection_name = " {collection_name} " , vectors_config = { "my_vector" : models .

VectorParamsDiff ( hnsw_config = models .

HnswConfigDiff ( m = 32 , ef_construct = 123 , ), quantization_config = models .

ProductQuantization ( product = models .

ProductQuantizationConfig ( compression = models .

CompressionRatio .

X32 , always_ram = True , ), ), on_disk = True , ), }, hnsw_config = models .

HnswConfigDiff ( ef_construct = 123 , ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , quantile = 0.8 , always_ram = False , ), ), ) client . updateCollection ( "{collection_name}" , { vectors : { my_vector : { hnsw_config : { m : 32 , ef_construct : 123 , }, quantization_config : { product : { compression : "x32" , always_ram : true , }, }, on_disk : true , }, }, hnsw_config : { ef_construct : 123 , }, quantization_config : { scalar : { type : "int8" , quantile : 0.8 , always_ram : true , }, }, }); use std :: collections :: HashMap ; use qdrant_client :: qdrant :: { quantization_config_diff :: Quantization , vectors_config_diff :: Config , HnswConfigDiffBuilder , QuantizationType , ScalarQuantizationBuilder , UpdateCollectionBuilder , VectorParamsDiffBuilder , VectorParamsDiffMap , }; client . update_collection ( UpdateCollectionBuilder :: new ( "{collection_name}" ) . hnsw_config ( HnswConfigDiffBuilder :: default (). ef_construct ( 123 )) . vectors_config ( Config :: ParamsMap ( VectorParamsDiffMap { map : HashMap :: from ([( ( "my_vector" . into ()), VectorParamsDiffBuilder :: default () . hnsw_config ( HnswConfigDiffBuilder :: default (). m ( 32 ). ef_construct ( 123 )) . build (), )]), })) . quantization_config ( Quantization :: Scalar ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . quantile ( 0.8 ) . always_ram ( true ) . build (), )), ) . await ? ; import io.qdrant.client.grpc.Collections.HnswConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.UpdateCollection ; import io.qdrant.client.grpc.Collections.VectorParamsDiff ; import io.qdrant.client.grpc.Collections.VectorParamsDiffMap ; import io.qdrant.client.grpc.Collections.VectorsConfigDiff ; client . updateCollectionAsync ( UpdateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setHnswConfig ( HnswConfigDiff . newBuilder (). setEfConstruct ( 123 ). build ()) . setVectorsConfig ( VectorsConfigDiff . newBuilder () . setParamsMap ( VectorParamsDiffMap . newBuilder () . putMap ( "my_vector" , VectorParamsDiff . newBuilder () . setHnswConfig ( HnswConfigDiff . newBuilder () . setM ( 3 ) . setEfConstruct ( 123 ) . build ()) . build ()))) . setQuantizationConfig ( QuantizationConfigDiff . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setQuantile ( 0 .

8f ) . setAlwaysRam ( true ) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionAsync ( collectionName : "{collection_name}" , hnswConfig : new HnswConfigDiff { EfConstruct = 123 }, vectorsConfig : new VectorParamsDiffMap { Map = { { "my_vector" , new VectorParamsDiff { HnswConfig = new HnswConfigDiff { M = 3 , EfConstruct = 123 } } } } }, quantizationConfig : new QuantizationConfigDiff { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , Quantile = 0.8f , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateCollection ( context .

Background (), & qdrant .

UpdateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfigDiffMap ( map [ string ] * qdrant .

VectorParamsDiff { "my_vector" : { HnswConfig : & qdrant .

HnswConfigDiff { M : qdrant .

PtrOf ( uint64 ( 3 )), EfConstruct : qdrant .

PtrOf ( uint64 ( 123 )), }, }, }), QuantizationConfig : qdrant .

NewQuantizationDiffScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , Quantile : qdrant .

PtrOf ( float32 ( 0.8 )), AlwaysRam : qdrant .

PtrOf ( true ), }), }) Collection info Qdrant allows determining the configuration parameters of an existing collection to better understand how the points are distributed and indexed.

GET /collections/{collection_name} curl -X GET http://localhost:6333/collections/ { collection_name } client . get_collection ( collection_name = " {collection_name} " ) client . getCollection ( "{collection_name}" ); client . collection_info ( "{collection_name}" ). await ? ; client . getCollectionInfoAsync ( "{collection_name}" ). get (); await client .

GetCollectionInfoAsync ( "{collection_name}" ); import "context" client .

GetCollectionInfo ( context .

Background (), "{collection_name}" ) Expected result { "result" : { "status" : "green" , "optimizer_status" : "ok" , "indexed_vectors_count" : 1024232 , "points_count" : 1068786 , "segments_count" : 31 , "config" : { "params" : { "vectors" : { "size" : 384 , "distance" : "Cosine" }, "shard_number" : 1 , "replication_factor" : 1 , "write_consistency_factor" : 1 , "on_disk_payload" : false }, "hnsw_config" : { "m" : 16 , "ef_construct" : 100 , "full_scan_threshold" : 10000 , "max_indexing_threads" : 0 }, "optimizer_config" : { "deleted_threshold" : 0.2 , "vacuum_min_vector_number" : 1000 , "default_segment_number" : 0 , "max_segment_size" : null , "memmap_threshold" : null , "indexing_threshold" : 20000 , "flush_interval_sec" : 5 , "max_optimization_threads" : 1 }, "wal_config" : { "wal_capacity_mb" : 32 , "wal_segments_ahead" : 0 } }, "payload_schema" : {} }, "status" : "ok" , "time" : 0.00010143 } If you insert the vectors into the collection, the status field may become yellow whilst it is optimizing. It will become green once all the points are successfully processed.

The following color statuses are possible: üü¢ green : collection is ready üü° yellow : collection is optimizing ‚ö´ grey : collection is pending optimization ( help ) üî¥ red : an error occurred which the engine could not recover from Grey collection status Available as of v1.9.0 A collection may have the grey ‚ö´ status or show ‚Äúoptimizations pending, awaiting update operation‚Äù as optimization status. This state is normally caused by restarting a Qdrant instance while optimizations were ongoing.

It means the collection has optimizations pending, but they are paused. You must send any update operation to trigger and start the optimizations again.

For example: PATCH /collections/{collection_name} { "optimizers_config": {} } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "optimizers_config": {} }' client . update_collection ( collection_name = " {collection_name} " , optimizer_config = models .

OptimizersConfigDiff (), ) client . updateCollection ( "{collection_name}" , { optimizers_config : {}, }); use qdrant_client :: qdrant :: { OptimizersConfigDiffBuilder , UpdateCollectionBuilder }; client . update_collection ( UpdateCollectionBuilder :: new ( "{collection_name}" ) . optimizers_config ( OptimizersConfigDiffBuilder :: default ()), ) . await ? ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.UpdateCollection ; client . updateCollectionAsync ( UpdateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setOptimizersConfig ( OptimizersConfigDiff . getDefaultInstance ()) . build ()); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionAsync ( collectionName : "{collection_name}" , optimizersConfig : new OptimizersConfigDiff { } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateCollection ( context .

Background (), & qdrant .

UpdateCollection { CollectionName : "{collection_name}" , OptimizersConfig : & qdrant .

OptimizersConfigDiff {}, }) Alternatively you may use the Trigger Optimizers button in the Qdrant Web UI .

It is shown next to the grey collection status on the collection info page.

Approximate point and vector counts You may be interested in the count attributes: points_count - total number of objects (vectors and their payloads) stored in the collection indexed_vectors_count - total number of vectors stored in the HNSW or sparse index. Qdrant does not store all the vectors in the index, but only if an index segment might be created for a given configuration.

The above counts are not exact, but should be considered approximate. Depending on how you use Qdrant these may give very different numbers than what you may expect. It‚Äôs therefore important not to rely on them.

More specifically, these numbers represent the count of points and vectors in Qdrant‚Äôs internal storage. Internally, Qdrant may temporarily duplicate points as part of automatic optimizations. It may keep changed or deleted points for a bit. And it may delay indexing of new points. All of that is for optimization reasons.

Updates you do are therefore not directly reflected in these numbers. If you see a wildly different count of points, it will likely resolve itself once a new round of automatic optimizations is completed.

To clarify: these numbers don‚Äôt represent the exact amount of points or vectors you have inserted, nor does it represent the exact number of distinguishable points or vectors you can query. If you want to know exact counts, refer to the count API .

Note: these numbers may be removed in a future version of Qdrant.

Indexing vectors in HNSW In some cases, you might be surprised the value of indexed_vectors_count is lower than you expected. This is an intended behaviour and depends on the optimizer configuration . A new index segment is built if the size of non-indexed vectors is higher than the value of indexing_threshold (in kB). If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW segment created and indexed_vectors_count might be equal to 0 .

It is possible to reduce the indexing_threshold for an existing collection by updating collection parameters .

Collection metadata Available as of v1.16.0 For convenience and better data organization, Qdrant allows attaching custom metadata to collections in the form of key-value pairs.

Adding metadata is treated as a part of collection configuration and synchronized across all nodes in a cluster with consensus protocol.

Collection metadata can be specified during collection creation: PUT /collections/{collection_name} { "vectors": { "size": 300, "distance": "Cosine" }, "metadata": { "my-metadata-field": "value-1", "another-field": 123 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "vectors": { "size": 300, "distance": "Cosine" }, "metadata": { "my-metadata-field": "value-1", "another-field": 123 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , metadata = { "my-metadata-field" : "value-1" , "another-field" : 123 }, ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 100 , distance : "Cosine" }, metadata : { "my-metadata-field" : "value-1" , "another-field" : 123 } }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder }; use qdrant_client :: Qdrant ; use serde_json :: { json , Value }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut metadata : HashMap < String , Value > = HashMap :: new (); metadata . insert ( "my-metadata-field" . to_string (), json!

( "value-1" )); metadata . insert ( "another-field" . to_string (), json!

( 123 )); client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 100 , Distance :: Cosine )) . metadata ( metadata ), ) . await ? ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setDistance ( Distance .

Cosine ) . setSize ( 100 ) . build ()) . build ()) . putAllMetadata ( Map . of ( "my-metadata-field" , value ( "value-1" ), "another-field" , value ( 123 ))) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 100 , Distance = Distance .

Cosine }, metadata : new () { ["my-metadata-field"] = "value-1" , ["another-field"] = 123 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 100 , Distance : qdrant .

Distance_Cosine , }), Metadata : qdrant .

NewValueMap ( map [ string ] any { "my-metadata-field" : "value-1" , "another-field" : 123 , }), }) as well as updated later: PATCH /collections/{collection_name} { "metadata": { "my-metadata-field": { "key-a": "value-a", "key-b": 42 } } } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "metadata": { "my-metadata-field": { "key-a": "value-a", "key-b": 42 } } }' client . update_collection ( collection_name = " {collection_name} " , metadata = { "my-metadata-field" : { "key-a" : "value-a" , "key-b" : 42 } }, ) client . updateCollection ( "{collection_name}" , { metadata : { "my-metadata-field" : { "key-a" : "value-a" , "key-b" : 42 } }, }); use qdrant_client :: qdrant :: { UpdateCollectionBuilder }; use qdrant_client :: Qdrant ; use serde_json :: { json , Value }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut metadata : HashMap < String , Value > = HashMap :: new (); metadata . insert ( "my-metadata-field" . to_string (), json!

({ "key-a" : "value-a" , "key-b" : 42 })); client . update_collection ( UpdateCollectionBuilder :: new ( "{collection_name}" ). metadata ( metadata ), ) . await ? ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.UpdateCollection ; import java.util.Map ; client . updateCollectionAsync ( UpdateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setOptimizersConfig ( OptimizersConfigDiff . newBuilder (). setIndexingThreshold ( 10000 ). build ()) . putAllMetadata ( Map . of ( "my-metadata-field" , value ( Map . of ( "key-a" , value ( "value-a" ), "key-b" , value ( 42 ))))) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionAsync ( collectionName : "{collection_name}" , optimizersConfig : new OptimizersConfigDiff { IndexingThreshold = 10000 }, metadata : new () { ["my-metadata-field"] = new Dictionary < string , Value > { ["key-a"] = "value-a" , ["key-b"] = 42 }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateCollection ( context .

Background (), & qdrant .

UpdateCollection { CollectionName : "{collection_name}" , OptimizersConfig : & qdrant .

OptimizersConfigDiff { IndexingThreshold : qdrant .

PtrOf ( uint64 ( 10000 )), }, Metadata : qdrant .

NewValueMap ( map [ string ] any { "my-metadata-field" : map [ string ] any { "key-a" : "value-a" , "key-b" : 42 , }, }), }) Note, that update operation only modifies the specified metadata fields, leaving other fields unchanged.

When specified, metadata is returned as part of collection info: { "result" : { "config" : { "metadata" : { "my-metadata-field" : { "key-a" : "value-a" , "key-b" : 42 }, "another-field" : 123 } } } } Collection aliases In a production environment, it is sometimes necessary to switch different versions of vectors seamlessly.

For example, when upgrading to a new version of the neural network.

There is no way to stop the service and rebuild the collection with new vectors in these situations.

Aliases are additional names for existing collections.

All queries to the collection can also be done identically, using an alias instead of the collection name.

Thus, it is possible to build a second collection in the background and then switch alias from the old to the new collection.

Since all changes of aliases happen atomically, no concurrent requests will be affected during the switch.

Create alias POST /collections/aliases { "actions": [ { "create_alias": { "collection_name": "example_collection", "alias_name": "production_collection" } } ] } curl -X POST http://localhost:6333/collections/aliases \ -H 'Content-Type: application/json' \ --data-raw '{ "actions": [ { "create_alias": { "collection_name": "example_collection", "alias_name": "production_collection" } } ] }' client . update_collection_aliases ( change_aliases_operations = [ models .

CreateAliasOperation ( create_alias = models .

CreateAlias ( collection_name = "example_collection" , alias_name = "production_collection" ) ) ] ) client . updateCollectionAliases ({ actions : [ { create_alias : { collection_name : "example_collection" , alias_name : "production_collection" , }, }, ], }); use qdrant_client :: qdrant :: CreateAliasBuilder ; client . create_alias ( CreateAliasBuilder :: new ( "example_collection" , "production_collection" , )) . await ? ; client . createAliasAsync ( "production_collection" , "example_collection" ). get (); await client .

CreateAliasAsync ( aliasName : "production_collection" , collectionName : "example_collection" ); import "context" client .

CreateAlias ( context .

Background (), "production_collection" , "example_collection" ) Remove alias POST /collections/aliases { "actions": [ { "delete_alias": { "alias_name": "production_collection" } } ] } curl -X POST http://localhost:6333/collections/aliases \ -H 'Content-Type: application/json' \ --data-raw '{ "actions": [ { "delete_alias": { "alias_name": "production_collection" } } ] }' client . update_collection_aliases ( change_aliases_operations = [ models .

DeleteAliasOperation ( delete_alias = models .

DeleteAlias ( alias_name = "production_collection" ) ), ] ) client . updateCollectionAliases ({ actions : [ { delete_alias : { alias_name : "production_collection" , }, }, ], }); client . delete_alias ( "production_collection" ). await ? ; client . deleteAliasAsync ( "production_collection" ). get (); await client .

DeleteAliasAsync ( "production_collection" ); import "context" client .

DeleteAlias ( context .

Background (), "production_collection" ) Switch collection Multiple alias actions are performed atomically.

For example, you can switch underlying collection with the following command: POST /collections/aliases { "actions": [ { "delete_alias": { "alias_name": "production_collection" } }, { "create_alias": { "collection_name": "example_collection", "alias_name": "production_collection" } } ] } curl -X POST http://localhost:6333/collections/aliases \ -H 'Content-Type: application/json' \ --data-raw '{ "actions": [ { "delete_alias": { "alias_name": "production_collection" } }, { "create_alias": { "collection_name": "example_collection", "alias_name": "production_collection" } } ] }' client . update_collection_aliases ( change_aliases_operations = [ models .

DeleteAliasOperation ( delete_alias = models .

DeleteAlias ( alias_name = "production_collection" ) ), models .

CreateAliasOperation ( create_alias = models .

CreateAlias ( collection_name = "example_collection" , alias_name = "production_collection" ) ), ] ) client . updateCollectionAliases ({ actions : [ { delete_alias : { alias_name : "production_collection" , }, }, { create_alias : { collection_name : "example_collection" , alias_name : "production_collection" , }, }, ], }); use qdrant_client :: qdrant :: CreateAliasBuilder ; client . delete_alias ( "production_collection" ). await ? ; client . create_alias ( CreateAliasBuilder :: new ( "example_collection" , "production_collection" , )) . await ? ; client . deleteAliasAsync ( "production_collection" ). get (); client . createAliasAsync ( "production_collection" , "example_collection" ). get (); await client .

DeleteAliasAsync ( "production_collection" ); await client .

CreateAliasAsync ( aliasName : "production_collection" , collectionName : "example_collection" ); import "context" client .

DeleteAlias ( context .

Background (), "production_collection" ) client .

CreateAlias ( context .

Background (), "production_collection" , "example_collection" ) List collection aliases GET /collections/{collection_name}/aliases curl -X GET http://localhost:6333/collections/ { collection_name } /aliases from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . get_collection_aliases ( collection_name = " {collection_name} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . getCollectionAliases ( "{collection_name}" ); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . list_collection_aliases ( "{collection_name}" ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . listCollectionAliasesAsync ( "{collection_name}" ). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ListCollectionAliasesAsync ( "{collection_name}" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

ListCollectionAliases ( context .

Background (), "{collection_name}" ) List all aliases GET /aliases curl -X GET http://localhost:6333/aliases from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . get_aliases () import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . getAliases (); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . list_aliases (). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . listAliasesAsync (). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ListAliasesAsync (); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

ListAliases ( context .

Background ()) List all collections GET /collections curl -X GET http://localhost:6333/collections from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . get_collections () import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . getCollections (); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . list_collections (). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . listCollectionsAsync (). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ListCollectionsAsync (); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

ListCollections ( context .

Background ())
================================================================================
PAGE 7/39
================================================================================
Title: Payload
URL: https://qdrant.tech/documentation/concepts/payload/
--------------------------------------------------------------------------------

Payload One of the significant features of Qdrant is the ability to store additional information along with vectors.

This information is called payload in Qdrant terminology.

Qdrant allows you to store any information that can be represented using JSON.

Here is an example of a typical payload: { "name" : "jacket" , "colors" : [ "red" , "blue" ], "count" : 10 , "price" : 11.99 , "locations" : [ { "lon" : 52.5200 , "lat" : 13.4050 } ], "reviews" : [ { "user" : "alice" , "score" : 4 }, { "user" : "bob" , "score" : 5 } ] } Payload types In addition to storing payloads, Qdrant also allows you search based on certain kinds of values.

This feature is implemented as additional filters during the search and will enable you to incorporate custom logic on top of semantic similarity.

During the filtering, Qdrant will check the conditions over those values that match the type of the filtering condition. If the stored value type does not fit the filtering condition - it will be considered not satisfied.

For example, you will get an empty output if you apply the range condition on the string data.

However, arrays (multiple values of the same type) are treated a little bit different. When we apply a filter to an array, it will succeed if at least one of the values inside the array meets the condition.

The filtering process is discussed in detail in the section Filtering .

Let‚Äôs look at the data types that Qdrant supports for searching: Integer integer - 64-bit integer in the range from -9223372036854775808 to 9223372036854775807 .

Example of single and multiple integer values: { "count" : 10 , "sizes" : [ 35 , 36 , 38 ] } Float float - 64-bit floating point number.

Example of single and multiple float values: { "price" : 11.99 , "ratings" : [ 9.1 , 9.2 , 9.4 ] } Bool Bool - binary value. Equals to true or false .

Example of single and multiple bool values: { "is_delivered" : true , "responses" : [ false , false , true , false ] } Keyword keyword - string value.

Example of single and multiple keyword values: { "name" : "Alice" , "friends" : [ "bob" , "eva" , "jack" ] } Geo geo is used to represent geographical coordinates.

Example of single and multiple geo values: { "location" : { "lon" : 52.5200 , "lat" : 13.4050 }, "cities" : [ { "lon" : 51.5072 , "lat" : 0.1276 }, { "lon" : 40.7128 , "lat" : 74.0060 } ] } Coordinate should be described as an object containing two fields: lon - for longitude, and lat - for latitude.

Datetime Available as of v1.8.0 datetime - date and time in RFC 3339 format.

See the following examples of single and multiple datetime values: { "created_at" : "2023-02-08T10:49:00Z" , "updated_at" : [ "2023-02-08T13:52:00Z" , "2023-02-21T21:23:00Z" ] } The following formats are supported: "2023-02-08T10:49:00Z" ( RFC 3339 , UTC) "2023-02-08T11:49:00+01:00" ( RFC 3339 , with timezone) "2023-02-08T10:49:00" (without timezone, UTC is assumed) "2023-02-08T10:49" (without timezone and seconds) "2023-02-08" (only date, midnight is assumed) Notes about the format: T can be replaced with a space.

The T and Z symbols are case-insensitive.

UTC is always assumed when the timezone is not specified.

Timezone can have the following formats: ¬±HH:MM , ¬±HHMM , ¬±HH , or Z .

Seconds can have up to 6 decimals, so the finest granularity for datetime is microseconds.

UUID Available as of v1.11.0 In addition to the basic keyword type, Qdrant supports uuid type for storing UUID values.

Functionally, it works the same as keyword , internally stores parsed UUID values.

{ "uuid" : "550e8400-e29b-41d4-a716-446655440000" , "uuids" : [ "550e8400-e29b-41d4-a716-446655440000" , "550e8400-e29b-41d4-a716-446655440001" ] } String representation of UUID (e.g.

550e8400-e29b-41d4-a716-446655440000 ) occupies 36 bytes.

But when numeric representation is used, it is only 128 bits (16 bytes).

Usage of uuid index type is recommended in payload-heavy collections to save RAM and improve search performance.

Create point with payload REST API ( Schema ) PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": [0.05, 0.61, 0.76, 0.74], "payload": {"city": "Berlin", "price": 1.99} }, { "id": 2, "vector": [0.19, 0.81, 0.75, 0.11], "payload": {"city": ["Berlin", "London"], "price": 1.99} }, { "id": 3, "vector": [0.36, 0.55, 0.47, 0.94], "payload": {"city": ["Berlin", "Moscow"], "price": [1.99, 2.99]} } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = [ 0.05 , 0.61 , 0.76 , 0.74 ], payload = { "city" : "Berlin" , "price" : 1.99 , }, ), models .

PointStruct ( id = 2 , vector = [ 0.19 , 0.81 , 0.75 , 0.11 ], payload = { "city" : [ "Berlin" , "London" ], "price" : 1.99 , }, ), models .

PointStruct ( id = 3 , vector = [ 0.36 , 0.55 , 0.47 , 0.94 ], payload = { "city" : [ "Berlin" , "Moscow" ], "price" : [ 1.99 , 2.99 ], }, ), ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : [ 0.05 , 0.61 , 0.76 , 0.74 ], payload : { city : "Berlin" , price : 1.99 , }, }, { id : 2 , vector : [ 0.19 , 0.81 , 0.75 , 0.11 ], payload : { city : [ "Berlin" , "London" ], price : 1.99 , }, }, { id : 3 , vector : [ 0.36 , 0.55 , 0.47 , 0.94 ], payload : { city : [ "Berlin" , "Moscow" ], price : [ 1.99 , 2.99 ], }, }, ], }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: { Payload , Qdrant }; use serde_json :: json ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let points = vec!

[ PointStruct :: new ( 1 , vec!

[ 0.05 , 0.61 , 0.76 , 0.74 ], Payload :: try_from ( json!

({ "city" : "Berlin" , "price" : 1.99 })). unwrap (), ), PointStruct :: new ( 2 , vec!

[ 0.19 , 0.81 , 0.75 , 0.11 ], Payload :: try_from ( json!

({ "city" : [ "Berlin" , "London" ]})). unwrap (), ), PointStruct :: new ( 3 , vec!

[ 0.36 , 0.55 , 0.47 , 0.94 ], Payload :: try_from ( json!

({ "city" : [ "Berlin" , "Moscow" ], "price" : [ 1.99 , 2.99 ]})) . unwrap (), ), ]; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , points ). wait ( true )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.list ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

05f , 0 .

61f , 0 .

76f , 0 .

74f )) . putAllPayload ( Map . of ( "city" , value ( "Berlin" ), "price" , value ( 1 .

99 ))) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( vectors ( 0 .

19f , 0 .

81f , 0 .

75f , 0 .

11f )) . putAllPayload ( Map . of ( "city" , list ( List . of ( value ( "Berlin" ), value ( "London" ))))) . build (), PointStruct . newBuilder () . setId ( id ( 3 )) . setVectors ( vectors ( 0 .

36f , 0 .

55f , 0 .

47f , 0 .

94f )) . putAllPayload ( Map . of ( "city" , list ( List . of ( value ( "Berlin" ), value ( "London" ))), "price" , list ( List . of ( value ( 1 .

99 ), value ( 2 .

99 ))))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new PointStruct { Id = 1 , Vectors = new [] { 0.05f , 0.61f , 0.76f , 0.74f }, Payload = { [ "city" ] = "Berlin" , [ "price" ] = 1.99 } }, new PointStruct { Id = 2 , Vectors = new [] { 0.19f , 0.81f , 0.75f , 0.11f }, Payload = { [ "city" ] = new [] { "Berlin" , "London" } } }, new PointStruct { Id = 3 , Vectors = new [] { 0.36f , 0.55f , 0.47f , 0.94f }, Payload = { ["city"] = new [] { "Berlin" , "Moscow" }, ["price"] = new Value [] { 1.99 , 2.99 } } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.05 , 0.61 , 0.76 , 0.74 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "city" : "Berlin" , "price" : 1.99 }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectors ( 0.19 , 0.81 , 0.75 , 0.11 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "city" : [] any { "Berlin" , "London" }}), }, { Id : qdrant .

NewIDNum ( 3 ), Vectors : qdrant .

NewVectors ( 0.36 , 0.55 , 0.47 , 0.94 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "city" : [] any { "Berlin" , "London" }, "price" : [] any { 1.99 , 2.99 }}), }, }, }) Update payload Updating payloads in Qdrant offers flexible methods to manage vector metadata. The set payload method updates specific fields while keeping others unchanged, while the overwrite method replaces the entire payload. Developers can also use clear payload to remove all metadata or delete fields to remove specific keys without affecting the rest. These options provide precise control for adapting to dynamic datasets.

Set payload Set only the given payload values on a point.

REST API ( Schema ): POST /collections/{collection_name}/points/payload { "payload": { "property1": "string", "property2": "string" }, "points": [ 0, 3, 100 ] } client . set_payload ( collection_name = " {collection_name} " , payload = { "property1" : "string" , "property2" : "string" , }, points = [ 0 , 3 , 10 ], ) client . setPayload ( "{collection_name}" , { payload : { property1 : "string" , property2 : "string" , }, points : [ 0 , 3 , 10 ], }); use qdrant_client :: qdrant :: { PointsIdsList , SetPayloadPointsBuilder , }; use qdrant_client :: Payload ; use serde_json :: json ; client . set_payload ( SetPayloadPointsBuilder :: new ( "{collection_name}" , Payload :: try_from ( json!

({ "property1" : "string" , "property2" : "string" , })) . unwrap (), ) . points_selector ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 10. into ()], }) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import java.util.List ; import java.util.Map ; client . setPayloadAsync ( "{collection_name}" , Map . of ( "property1" , value ( "string" ), "property2" , value ( "string" )), List . of ( id ( 0 ), id ( 3 ), id ( 10 )), true , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

SetPayloadAsync ( collectionName : "{collection_name}" , payload : new Dictionary < string , Value > { { "property1" , "string" }, { "property2" , "string" } }, ids : new ulong [] { 0 , 3 , 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

SetPayload ( context .

Background (), & qdrant .

SetPayloadPoints { CollectionName : "{collection_name}" , Payload : qdrant .

NewValueMap ( map [ string ] any { "property1" : "string" , "property2" : "string" }), PointsSelector : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 )), }) You don‚Äôt need to know the ids of the points you want to modify. The alternative is to use filters.

POST /collections/{collection_name}/points/payload { "payload": { "property1": "string", "property2": "string" }, "filter": { "must": [ { "key": "color", "match": { "value": "red" } } ] } } client . set_payload ( collection_name = " {collection_name} " , payload = { "property1" : "string" , "property2" : "string" , }, points = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ), ], ), ) client . setPayload ( "{collection_name}" , { payload : { property1 : "string" , property2 : "string" , }, filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , SetPayloadPointsBuilder }; use qdrant_client :: Payload ; use serde_json :: json ; client . set_payload ( SetPayloadPointsBuilder :: new ( "{collection_name}" , Payload :: try_from ( json!

({ "property1" : "string" , "property2" : "string" , })) . unwrap (), ) . points_selector ( Filter :: must ([ Condition :: matches ( "color" , "red" . to_string (), )])) . wait ( true ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.grpc.Common.Filter ; import java.util.Map ; client . setPayloadAsync ( "{collection_name}" , Map . of ( "property1" , value ( "string" ), "property2" , value ( "string" )), Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build (), true , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

SetPayloadAsync ( collectionName : "{collection_name}" , payload : new Dictionary < string , Value > { { "property1" , "string" }, { "property2" , "string" } }, filter : MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

SetPayload ( context .

Background (), & qdrant .

SetPayloadPoints { CollectionName : "{collection_name}" , Payload : qdrant .

NewValueMap ( map [ string ] any { "property1" : "string" , "property2" : "string" }), PointsSelector : qdrant .

NewPointsSelectorFilter ( & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }), }) Available as of v1.8.0 It is possible to modify only a specific key of the payload by using the key parameter.

For instance, given the following payload JSON object on a point: { "property1" : { "nested_property" : "foo" , }, "property2" : { "nested_property" : "bar" , } } You can modify the nested_property of property1 with the following request: POST /collections/{collection_name}/points/payload { "payload": { "nested_property": "qux", }, "key": "property1", "points": [1] } Resulting in the following payload: { "property1" : { "nested_property" : "qux" , }, "property2" : { "nested_property" : "bar" , } } Overwrite payload Fully replace any existing payload with the given one.

REST API ( Schema ): PUT /collections/{collection_name}/points/payload { "payload": { "property1": "string", "property2": "string" }, "points": [ 0, 3, 100 ] } client . overwrite_payload ( collection_name = " {collection_name} " , payload = { "property1" : "string" , "property2" : "string" , }, points = [ 0 , 3 , 10 ], ) client . overwritePayload ( "{collection_name}" , { payload : { property1 : "string" , property2 : "string" , }, points : [ 0 , 3 , 10 ], }); use qdrant_client :: qdrant :: { PointsIdsList , SetPayloadPointsBuilder }; use qdrant_client :: Payload ; use serde_json :: json ; client . overwrite_payload ( SetPayloadPointsBuilder :: new ( "{collection_name}" , Payload :: try_from ( json!

({ "property1" : "string" , "property2" : "string" , })) . unwrap (), ) . points_selector ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 10. into ()], }) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import java.util.List ; import java.util.Map ; client . overwritePayloadAsync ( "{collection_name}" , Map . of ( "property1" , value ( "string" ), "property2" , value ( "string" )), List . of ( id ( 0 ), id ( 3 ), id ( 10 )), true , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

OverwritePayloadAsync ( collectionName : "{collection_name}" , payload : new Dictionary < string , Value > { { "property1" , "string" }, { "property2" , "string" } }, ids : new ulong [] { 0 , 3 , 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

OverwritePayload ( context .

Background (), & qdrant .

SetPayloadPoints { CollectionName : "{collection_name}" , Payload : qdrant .

NewValueMap ( map [ string ] any { "property1" : "string" , "property2" : "string" }), PointsSelector : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 )), }) Like set payload , you don‚Äôt need to know the ids of the points you want to modify. The alternative is to use filters.

Clear payload This method removes all payload keys from specified points REST API ( Schema ): POST /collections/{collection_name}/points/payload/clear { "points": [0, 3, 100] } client . clear_payload ( collection_name = " {collection_name} " , points_selector = [ 0 , 3 , 100 ], ) client . clearPayload ( "{collection_name}" , { points : [ 0 , 3 , 100 ], }); use qdrant_client :: qdrant :: { ClearPayloadPointsBuilder , PointsIdsList }; client . clear_payload ( ClearPayloadPointsBuilder :: new ( "{collection_name}" ) . points ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 10. into ()], }) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import java.util.List ; client . clearPayloadAsync ( "{collection_name}" , List . of ( id ( 0 ), id ( 3 ), id ( 100 )), true , null , null ) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ClearPayloadAsync ( collectionName : "{collection_name}" , ids : new ulong [] { 0 , 3 , 100 }); import ( "context" "github.com/qdrant/go-client/qdrant" ) client .

ClearPayload ( context .

Background (), & qdrant .

ClearPayloadPoints { CollectionName : "{collection_name}" , Points : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 )), }) Delete payload keys Delete specific payload keys from points.

REST API ( Schema ): POST /collections/{collection_name}/points/payload/delete { "keys": ["color", "price"], "points": [0, 3, 100] } client . delete_payload ( collection_name = " {collection_name} " , keys = [ "color" , "price" ], points = [ 0 , 3 , 100 ], ) client . deletePayload ( "{collection_name}" , { keys : [ "color" , "price" ], points : [ 0 , 3 , 100 ], }); use qdrant_client :: qdrant :: { DeletePayloadPointsBuilder , PointsIdsList }; client . delete_payload ( DeletePayloadPointsBuilder :: new ( "{collection_name}" , vec!

[ "color" . to_string (), "price" . to_string ()], ) . points_selector ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 10. into ()], }) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import java.util.List ; client . deletePayloadAsync ( "{collection_name}" , List . of ( "color" , "price" ), List . of ( id ( 0 ), id ( 3 ), id ( 100 )), true , null , null ) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeletePayloadAsync ( collectionName : "{collection_name}" , keys : [ "color" , "price" ], ids : new ulong [] { 0 , 3 , 100 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

DeletePayload ( context .

Background (), & qdrant .

DeletePayloadPoints { CollectionName : "{collection_name}" , Keys : [] string { "color" , "price" }, PointsSelector : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 )), }) Alternatively, you can use filters to delete payload keys from the points.

POST /collections/{collection_name}/points/payload/delete { "keys": ["color", "price"], "filter": { "must": [ { "key": "color", "match": { "value": "red" } } ] } } client . delete_payload ( collection_name = " {collection_name} " , keys = [ "color" , "price" ], points = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ), ], ), ) client . deletePayload ( "{collection_name}" , { keys : [ "color" , "price" ], filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , DeletePayloadPointsBuilder , Filter }; client . delete_payload ( DeletePayloadPointsBuilder :: new ( "{collection_name}" , vec!

[ "color" . to_string (), "price" . to_string ()], ) . points_selector ( Filter :: must ([ Condition :: matches ( "color" , "red" . to_string (), )])) . wait ( true ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import java.util.List ; client . deletePayloadAsync ( "{collection_name}" , List . of ( "color" , "price" ), Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build (), true , null , null ) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeletePayloadAsync ( collectionName : "{collection_name}" , keys : [ "color" , "price" ], filter : MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

DeletePayload ( context .

Background (), & qdrant .

DeletePayloadPoints { CollectionName : "{collection_name}" , Keys : [] string { "color" , "price" }, PointsSelector : qdrant .

NewPointsSelectorFilter ( & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" )}, }, ), }) Payload indexing To search more efficiently with filters, Qdrant allows you to create indexes for payload fields by specifying the name and type of field it is intended to be.

The indexed fields also affect the vector index. See Indexing for details.

In practice, we recommend creating an index on those fields that could potentially constrain the results the most.

For example, using an index for the object ID will be much more efficient, being unique for each record, than an index by its color, which has only a few possible values.

In compound queries involving multiple fields, Qdrant will attempt to use the most restrictive index first.

To create index for the field, you can use the following: REST API ( Schema ) PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": "keyword" } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = "keyword" , ) client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : "keyword" , }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , FieldType }; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Keyword , ) . wait ( true ), ) . await ? ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Keyword , null , true , null , null ); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), }) The index usage flag is displayed in the payload schema with the collection info API .

Payload schema example: { "payload_schema" : { "property1" : { "data_type" : "keyword" }, "property2" : { "data_type" : "integer" } } } Facet counts Available as of v1.12.0 Faceting is a special counting technique that can be used for various purposes: Know which unique values exist for a payload key.

Know the number of points that contain each unique value.

Know how restrictive a filter would become by matching a specific value.

Specifically, it is a counting aggregation for the values in a field, akin to a GROUP BY with COUNT(*) commands in SQL.

These results for a specific field is called a ‚Äúfacet‚Äù. For example, when you look at an e-commerce search results page, you might see a list of brands on the sidebar, showing the number of products for each brand. This would be a facet for a "brand" field.

To get the facet counts for a field, you can use the following: REST API ( Facet ) POST /collections/{collection_name}/facet { "key": "size", "filter": { "must": { "key": "color", "match": { "value": "red" } } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . facet ( collection_name = " {collection_name} " , key = "size" , facet_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ) ] ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . facet ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, key : "size" , }); use qdrant_client :: qdrant :: { Condition , FacetCountsBuilder , Filter }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . facet ( FacetCountsBuilder :: new ( "{collection_name}" , "size" ) . limit ( 10 ) . filter ( Filter :: must ( vec!

[ Condition :: matches ( "color" , "red" . to_string (), )])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . facetAsync ( Points .

FacetCounts . newBuilder () . setCollectionName ( "{collection_name}" ) . setKey ( "size" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

FacetAsync ( "{collection_name}" , key : "size" , filter : MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) res , err := client .

Facet ( context .

Background (), & qdrant .

FacetCounts { CollectionName : "{collection_name}" , Key : "size" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, }) The response will contain the counts for each unique value in the field: { "response" : { "hits" : [ { "value" : "L" , "count" : 19 }, { "value" : "S" , "count" : 10 }, { "value" : "M" , "count" : 5 }, { "value" : "XL" , "count" : 1 }, { "value" : "XXL" , "count" : 1 } ] }, "time" : 0.0001 } The results are sorted by the count in descending order, then by the value in ascending order.

Only values with non-zero counts will be returned.

By default, the way Qdrant the counts for each value is approximate to achieve fast results. This should accurate enough for most cases, but if you need to debug your storage, you can use the exact parameter to get exact counts.

POST /collections/{collection_name}/facet { "key": "size", "exact": true } client . facet ( collection_name = " {collection_name} " , key = "size" , exact = True , ) client . facet ( "{collection_name}" , { key : "size" , exact : true , }); use qdrant_client :: qdrant :: FacetCountsBuilder ; client . facet ( FacetCountsBuilder :: new ( "{collection_name}" , "size" ) . limit ( 10 ) . exact ( true ), ) . await ? ; import io.qdrant.client.grpc.Points.FacetCounts ; client . facetAsync ( FacetCounts . newBuilder () . setCollectionName ( "{collection_name}" ) . setKey ( "foo" ) . setExact ( true ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; await client .

FacetAsync ( "{collection_name}" , key : "size" , exact : true ); res , err := client .

Facet ( context .

Background (), & qdrant .

FacetCounts { CollectionName : "{collection_name}" , Key : "key" , Exact : qdrant .

PtrOf ( true ), })
================================================================================
PAGE 8/39
================================================================================
Title: Similarity search
URL: https://qdrant.tech/documentation/concepts/search/
--------------------------------------------------------------------------------

Similarity search Searching for the nearest vectors is at the core of many representational learning applications.

Modern neural networks are trained to transform objects into vectors so that objects close in the real world appear close in vector space.

It could be, for example, texts with similar meanings, visually similar pictures, or songs of the same genre.

This is how vector similarity works Query API Available as of v1.10.0 Qdrant provides a single interface for all kinds of search and exploration requests - the Query API .

Here is a reference list of what kind of queries you can perform with the Query API in Qdrant: Depending on the query parameter, Qdrant might prefer different strategies for the search.

Nearest Neighbors Search Vector Similarity Search, also known as k-NN Search By Id Search by an already stored vector - skip embedding model inference Recommendations Provide positive and negative examples Discovery Search Guide the search using context as a one-shot training set Scroll Get all points with optional filtering Grouping Group results by a certain field Order By Order points by payload key Hybrid Search Combine multiple queries to get better results Multi-Stage Search Optimize performance for large embeddings Random Sampling Get random points from the collection Nearest Neighbors Search POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7] // <--- Dense vector } client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], # <--- Dense vector ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], // <--- Dense vector }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ])) ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collectionName}" ) . setQuery ( nearest ( List . of ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f ))) . build ()). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), }) Search By Id POST /collections/{collection_name}/points/query { "query": "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" // <--- point id } client . query_points ( collection_name = " {collection_name} " , query = "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" , # <--- point id ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : '43cf51e2-8777-4f52-bc74-c2cbde0c8b04' , // <--- point id }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PointId , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( PointId :: from ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ))) ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.UUID ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collectionName}" ) . setQuery ( nearest ( UUID . fromString ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ))) . build ()). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : Guid .

Parse ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryID ( qdrant .

NewID ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" )), }) Metrics There are many ways to estimate the similarity of vectors with each other.

In Qdrant terms, these ways are called metrics.

The choice of metric depends on the vectors obtained and, in particular, on the neural network encoder training method.

Qdrant supports these most popular types of metrics: Dot product: Dot - https://en.wikipedia.org/wiki/Dot_product Cosine similarity: Cosine - https://en.wikipedia.org/wiki/Cosine_similarity Euclidean distance: Euclid - https://en.wikipedia.org/wiki/Euclidean_distance Manhattan distance: Manhattan *- https://en.wikipedia.org/wiki/Taxicab_geometry *Available as of v1.7 The most typical metric used in similarity learning models is the cosine metric.

Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved.

The first step is to normalize the vector when adding it to the collection.

It happens only once for each vector.

The second step is the comparison of vectors.

In this case, it becomes equivalent to dot production - a very fast operation due to SIMD.

Depending on the query configuration, Qdrant might prefer different strategies for the search.

Read more about it in the query planning section.

Search API Let‚Äôs look at an example of a search query.

REST API - API Schema definition is available here POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.79], "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "params": { "hnsw_ef": 128, "exact": false }, "limit": 3 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" , ), ) ] ), search_params = models .

SearchParams ( hnsw_ef = 128 , exact = False ), limit = 3 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], filter : { must : [ { key : "city" , match : { value : "London" , }, }, ], }, params : { hnsw_ef : 128 , exact : false , }, limit : 3 , }); use qdrant_client :: qdrant :: { Condition , Filter , QueryPointsBuilder , SearchParamsBuilder }; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . filter ( Filter :: must ([ Condition :: matches ( "city" , "London" . to_string (), )])) . params ( SearchParamsBuilder :: default (). hnsw_ef ( 128 ). exact ( false )), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "city" , "London" )). build ()) . setParams ( SearchParams . newBuilder (). setExact ( false ). setHnswEf ( 128 ). build ()) . setLimit ( 3 ) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, filter : MatchKeyword ( "city" , "London" ), searchParams : new SearchParams { Exact = false , HnswEf = 128 }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, }, Params : & qdrant .

SearchParams { Exact : qdrant .

PtrOf ( false ), HnswEf : qdrant .

PtrOf ( uint64 ( 128 )), }, }) In this example, we are looking for vectors similar to vector [0.2, 0.1, 0.9, 0.7] .

Parameter limit (or its alias - top ) specifies the amount of most similar results we would like to retrieve.

Values under the key params specify custom parameters for the search.

Currently, it could be: hnsw_ef - value that specifies ef parameter of the HNSW algorithm. exact - option to not use the approximate search (ANN). If set to true, the search may run for a long as it performs a full scan to retrieve exact results. indexed_only - With this option you can disable the search in those segments where vector index is not built yet. This may be useful if you want to minimize the impact to the search performance whilst the collection is also being updated. Using this option may lead to a partial result if the collection is not fully indexed yet, consider using it only if eventual consistency is acceptable for your use case. quantization - parameters related to quantization. See Searching with Quantization guide. acorn - parameters related to the ACORN search algorithm .

Since the filter parameter is specified, the search is performed only among those points that satisfy the filter condition.

See details of possible filters and their work in the filtering section.

Example result of this API would be { "result" : [ { "id" : 10 , "score" : 0.81 }, { "id" : 14 , "score" : 0.75 }, { "id" : 11 , "score" : 0.73 } ], "status" : "ok" , "time" : 0.001 } The result contains ordered by score list of found point ids.

Note that payload and vector data is missing in these results by default.

See payload and vector in the result on how to include it.

If the collection was created with multiple vectors, the name of the vector to use for searching should be provided: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "using": "image", "limit": 3 } from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], using = "image" , limit = 3 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], using : "image" , limit : 3 , }); use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . using ( "image" ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setUsing ( "image" ) . setLimit ( 3 ) . build ()). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, usingVector : "image" , limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Using : qdrant .

PtrOf ( "image" ), }) Search is processing only among vectors with the same name.

If the collection was created with sparse vectors, the name of the sparse vector to use for searching should be provided: You can still use payload filtering and other features of the search API with sparse vectors.

There are however important differences between dense and sparse vector search: Index Sparse Query Dense Query Scoring Metric Default is Dot product , no need to specify it Distance has supported metrics e.g. Dot, Cosine Search Type Always exact in Qdrant HNSW is an approximate NN Return Behaviour Returns only vectors with non-zero values in the same indices as the query vector Returns limit vectors In general, the speed of the search is proportional to the number of non-zero values in the query vector.

POST /collections/{collection_name}/points/query { "query": { "indices": [1, 3, 5, 7], "values": [0.1, 0.2, 0.3, 0.4] }, "using": "text" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) result = client . query_points ( collection_name = " {collection_name} " , query = models .

SparseVector ( indices = [ 1 , 3 , 5 , 7 ], values = [ 0.1 , 0.2 , 0.3 , 0.4 ]), using = "text" , ) . points import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { indices : [ 1 , 3 , 5 , 7 ], values : [ 0.1 , 0.2 , 0.3 , 0.4 ] }, using : "text" , limit : 3 , }); use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[( 1 , 0.2 ), ( 3 , 0.1 ), ( 5 , 0.9 ), ( 7 , 0.7 )]) . limit ( 10 ) . using ( "text" ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setUsing ( "text" ) . setQuery ( nearest ( List . of ( 0 .

1f , 0 .

2f , 0 .

3f , 0 .

4f ), List . of ( 1 , 3 , 5 , 7 ))) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new ( float , uint )[] {( 0.1f , 1 ), ( 0.2f , 3 ), ( 0.3f , 5 ), ( 0.4f , 7 )}, usingVector : "text" , limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuerySparse ( [] uint32 { 1 , 3 , 5 , 7 }, [] float32 { 0.1 , 0.2 , 0.3 , 0.4 }), Using : qdrant .

PtrOf ( "text" ), }) Filtering results by score In addition to payload filtering, it might be useful to filter out results with a low similarity score.

For example, if you know the minimal acceptance score for your model and do not want any results which are less similar than the threshold.

In this case, you can use score_threshold parameter of the search query.

It will exclude all results with a score worse than the given.

Payload and vector in the result By default, retrieval methods do not return any stored information such as payload and vectors. Additional parameters with_vectors and with_payload alter this behavior.

Example: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "with_vectors": true, "with_payload": true } client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], with_vectors = True , with_payload = True , ) client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], with_vector : true , with_payload : true , }); use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . with_payload ( true ) . with_vectors ( true ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.WithPayloadSelectorFactory.enable ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.WithVectorsSelectorFactory ; import io.qdrant.client.grpc.Points.QueryPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setWithPayload ( enable ( true )) . setWithVectors ( WithVectorsSelectorFactory . enable ( true )) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, payloadSelector : true , vectorsSelector : true , limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), WithPayload : qdrant .

NewWithPayload ( true ), WithVectors : qdrant .

NewWithVectors ( true ), }) You can use with_payload to scope to or filter a specific payload subset.

You can even specify an array of items to include, such as city , village , and town : POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "with_payload": ["city", "village", "town"] } from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], with_payload = [ "city" , "village" , "town" ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], with_payload : [ "city" , "village" , "town" ], }); use qdrant_client :: qdrant :: { with_payload_selector :: SelectorOptions , QueryPointsBuilder }; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . with_payload ( SelectorOptions :: Include ( vec!

[ "city" . to_string (), "village" . to_string (), "town" . to_string (), ] . into (), )) . with_vectors ( true ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.WithPayloadSelectorFactory.include ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setWithPayload ( include ( List . of ( "city" , "village" , "town" ))) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, payloadSelector : new WithPayloadSelector { Include = new PayloadIncludeSelector { Fields = { new string [] { "city" , "village" , "town" } } } }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), WithPayload : qdrant .

NewWithPayloadInclude ( "city" , "village" , "town" ), }) Or use include or exclude explicitly. For example, to exclude city : POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "with_payload": { "exclude": ["city"] } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], with_payload = models .

PayloadSelectorExclude ( exclude = [ "city" ], ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], with_payload : { exclude : [ "city" ], }, }); use qdrant_client :: qdrant :: { with_payload_selector :: SelectorOptions , QueryPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . with_payload ( SelectorOptions :: Exclude ( vec!

[ "city" . to_string ()]. into ())) . with_vectors ( true ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.WithPayloadSelectorFactory.exclude ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setWithPayload ( exclude ( List . of ( "city" ))) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, payloadSelector : new WithPayloadSelector { Exclude = new PayloadExcludeSelector { Fields = { new string [] { "city" } } } }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), WithPayload : qdrant .

NewWithPayloadExclude ( "city" ), }) It is possible to target nested fields using a dot notation: payload.nested_field - for a nested field payload.nested_array[].sub_field - for projecting nested fields within an array Accessing array elements by index is currently not supported.

ACORN Search Algorithm Available as of v1.16.0 For filtered vector search, you are recommended to create a payload index for the fields you want to filter by.

During the search, Qdrant will use a combined filterable index .

However, when combining multiple strict payload filters, this mechanism might not provide sufficient accuracy.

In such cases, you can use the ACORN search algorithm.

It is an extension to the regular HNSW search algorithm, based on the ACORN-1 algorithm described in the paper ACORN: Performant and Predicate-Agnostic Search Over Vector Embeddings and Structured Data .

During graph traversal, it explores not just direct neighbors (first hop), but also neighbors of neighbors (second hop) when direct neighbors are filtered out.

This improves search accuracy at the cost of performance.

Enable it as follows: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "acorn": { "enable": true, "max_selectivity": 0.4 } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( acorn = models .

AcornSearchParams ( enable = True , max_selectivity = 0.4 , ) ), limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { acorn : { enable : true , max_selectivity : 0.4 , }, }, limit : 10 , }); use qdrant_client :: qdrant :: { AcornSearchParamsBuilder , QueryPointsBuilder , SearchParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 10 ) . params ( SearchParamsBuilder :: default (). acorn ( AcornSearchParamsBuilder :: new ( true ) . max_selectivity ( 0.4 ), ), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.AcornSearchParams ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder () . setAcorn ( AcornSearchParams . newBuilder () . setEnable ( true ) . setMaxSelectivity ( 0 .

4 ) . build ()) . build ()) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { Acorn = new AcornSearchParams { Enable = true , MaxSelectivity = 0.4 } }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { Acorn : & qdrant .

AcornSearchParams { Enable : qdrant .

PtrOf ( true ), MaxSelectivity : qdrant .

PtrOf ( 0.4 ), }, }, }) ACORN is disabled by default.

Once enabled via the enable flag, it activates conditionally when estimated filter selectivity is below the threshold.

The optional max_selectivity value controls this threshold;

0.0 means ACORN will never be used, 1.0 means it will always be used. The default value is 0.4 .

Selectivity is estimated as: $$ \text{Estimated filter selectivity} = \frac{\text{Estimated number of points satisfying the filters}} {\text{Total number of points}} $$ Since ACORN is significantly slower (approximately 2-10x in typical scenarios) but improves recall for restrictive filters, tuning this parameter is about deciding when the accuracy improvement justifies the performance cost.

Batch search API The batch search API enables to perform multiple search requests via a single request.

Its semantic is straightforward, n batched search requests are equivalent to n singular search requests.

This approach has several advantages. Logically, fewer network connections are required which can be very beneficial on its own.

More importantly, batched requests will be efficiently processed via the query planner which can detect and optimize requests if they have the same filter .

This can have a great effect on latency for non trivial filters as the intermediary results can be shared among the request.

In order to use it, simply pack together your search requests. All the regular attributes of a search request are of course available.

POST /collections/{collection_name}/points/query/batch { "searches": [ { "query": [0.2, 0.1, 0.9, 0.7], "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "limit": 3 }, { "query": [0.5, 0.3, 0.2, 0.3], "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "limit": 3 } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) filter_ = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" , ), ) ] ) search_queries = [ models .

QueryRequest ( query = [ 0.2 , 0.1 , 0.9 , 0.7 ], filter = filter_ , limit = 3 ), models .

QueryRequest ( query = [ 0.5 , 0.3 , 0.2 , 0.3 ], filter = filter_ , limit = 3 ), ] client . query_batch_points ( collection_name = " {collection_name} " , requests = search_queries ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const filter = { must : [ { key : "city" , match : { value : "London" , }, }, ], }; const searches = [ { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], filter , limit : 3 , }, { query : [ 0.5 , 0.3 , 0.2 , 0.3 ], filter , limit : 3 , }, ]; client . queryBatch ( "{collection_name}" , { searches , }); use qdrant_client :: qdrant :: { Condition , Filter , QueryBatchPointsBuilder , QueryPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let filter = Filter :: must ([ Condition :: matches ( "city" , "London" . to_string ())]); let searches = vec!

[ QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.1 , 0.2 , 0.3 , 0.4 ]) . limit ( 3 ) . filter ( filter . clone ()) . build (), QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.5 , 0.3 , 0.2 , 0.3 ]) . limit ( 3 ) . filter ( filter ) . build (), ]; client . query_batch ( QueryBatchPointsBuilder :: new ( "{collection_name}" , searches )) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ());

Filter filter = Filter . newBuilder (). addMust ( matchKeyword ( "city" , "London" )). build ();

List < QueryPoints > searches = List . of ( QueryPoints . newBuilder () . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setFilter ( filter ) . setLimit ( 3 ) . build (), QueryPoints . newBuilder () . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setFilter ( filter ) . setLimit ( 3 ) . build ()); client . queryBatchAsync ( "{collection_name}" , searches ). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); var filter = MatchKeyword ( "city" , "London" ); var queries = new List < QueryPoints > { new () { CollectionName = "{collection_name}" , Query = new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, Filter = filter , Limit = 3 }, new () { CollectionName = "{collection_name}" , Query = new float [] { 0.5f , 0.3f , 0.2f , 0.3f }, Filter = filter , Limit = 3 } }; await client .

QueryBatchAsync ( collectionName : "{collection_name}" , queries : queries ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) filter := qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, } client .

QueryBatch ( context .

Background (), & qdrant .

QueryBatchPoints { CollectionName : "{collection_name}" , QueryPoints : [] * qdrant .

QueryPoints { { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Filter : & filter , }, { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.5 , 0.3 , 0.2 , 0.3 ), Filter : & filter , }, }, }) The result of this API contains one array per search requests.

{ "result" : [ [ { "id" : 10 , "score" : 0.81 }, { "id" : 14 , "score" : 0.75 }, { "id" : 11 , "score" : 0.73 } ], [ { "id" : 1 , "score" : 0.92 }, { "id" : 3 , "score" : 0.89 }, { "id" : 9 , "score" : 0.75 } ] ], "status" : "ok" , "time" : 0.001 } Query by ID Whenever you need to use a vector as an input, you can always use a point ID instead.

POST /collections/{collection_name}/points/query { "query": "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" // <--- point id } client . query_points ( collection_name = " {collection_name} " , query = "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" , # <--- point id ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : '43cf51e2-8777-4f52-bc74-c2cbde0c8b04' , // <--- point id }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PointId , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( PointId :: from ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ))) ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.UUID ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collectionName}" ) . setQuery ( nearest ( UUID . fromString ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ))) . build ()). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : Guid .

Parse ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryID ( qdrant .

NewID ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" )), }) The above example will fetch the default vector from the point with this id, and use it as the query vector.

If the using parameter is also specified, Qdrant will use the vector with that name.

It is also possible to reference an ID from a different collection, by setting the lookup_from parameter.

POST /collections/{collection_name}/points/query { "query": "43cf51e2-8777-4f52-bc74-c2cbde0c8b04", // <--- point id "using": "512d-vector" "lookup_from": { "collection": "another_collection", // <--- other collection name "vector": "image-512" // <--- vector name in the other collection } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" , # <--- point id using = "512d-vector" , lookup_from = models .

LookupLocation ( collection = "another_collection" , # <--- other collection name vector = "image-512" , # <--- vector name in the other collection ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : '43cf51e2-8777-4f52-bc74-c2cbde0c8b04' , // <--- point id using : '512d-vector' , lookup_from : { collection : 'another_collection' , // <--- other collection name vector : 'image-512' , // <--- vector name in the other collection } }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { LookupLocationBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" )) . using ( "512d-vector" ) . lookup_from ( LookupLocationBuilder :: new ( "another_collection" ) . vector_name ( "image-512" ) ) ). await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.LookupLocation ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.UUID ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( UUID . fromString ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ))) . setUsing ( "512d-vector" ) . setLookupFrom ( LookupLocation . newBuilder () . setCollectionName ( "another_collection" ) . setVectorName ( "image-512" ) . build ()) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : Guid .

Parse ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" ), // <--- point id usingVector : "512d-vector" , lookupFrom : new () { CollectionName = "another_collection" , // <--- other collection name VectorName = "image-512" // <--- vector name in the other collection } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryID ( qdrant .

NewID ( "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" )), Using : qdrant .

PtrOf ( "512d-vector" ), LookupFrom : & qdrant .

LookupLocation { CollectionName : "another_collection" , VectorName : qdrant .

PtrOf ( "image-512" ), }, }) In the case above, Qdrant will fetch the "image-512" vector from the specified point id in the collection another_collection .

Pagination Search and recommendation APIs allow to skip first results of the search and return only the result starting from some specified offset: Example: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "with_vectors": true, "with_payload": true, "limit": 10, "offset": 100 } from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], with_vectors = True , with_payload = True , limit = 10 , offset = 100 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], with_vector : true , with_payload : true , limit : 10 , offset : 100 , }); use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . with_payload ( true ) . with_vectors ( true ) . limit ( 10 ) . offset ( 100 ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.WithPayloadSelectorFactory.enable ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.WithVectorsSelectorFactory ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setWithPayload ( enable ( true )) . setWithVectors ( WithVectorsSelectorFactory . enable ( true )) . setLimit ( 10 ) . setOffset ( 100 ) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, payloadSelector : true , vectorsSelector : true , limit : 10 , offset : 100 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), WithPayload : qdrant .

NewWithPayload ( true ), WithVectors : qdrant .

NewWithVectors ( true ), Offset : qdrant .

PtrOf ( uint64 ( 100 )), }) Is equivalent to retrieving the 11th page with 10 records per page.

Vector-based retrieval in general and HNSW index in particular, are not designed to be paginated.

It is impossible to retrieve Nth closest vector without retrieving the first N vectors first.

However, using the offset parameter saves the resources by reducing network traffic and the number of times the storage is accessed.

Using an offset parameter, will require to internally retrieve offset + limit points, but only access payload and vector from the storage those points which are going to be actually returned.

Grouping API It is possible to group results by a certain field. This is useful when you have multiple points for the same item, and you want to avoid redundancy of the same item in the results.

For example, if you have a large document split into multiple chunks, and you want to search or recommend on a per-document basis, you can group the results by the document ID.

Consider having points with the following payloads: [ { "id" : 0 , "payload" : { "chunk_part" : 0 , "document_id" : "a" }, "vector" : [ 0.91 ] }, { "id" : 1 , "payload" : { "chunk_part" : 1 , "document_id" : [ "a" , "b" ] }, "vector" : [ 0.8 ] }, { "id" : 2 , "payload" : { "chunk_part" : 2 , "document_id" : "a" }, "vector" : [ 0.2 ] }, { "id" : 3 , "payload" : { "chunk_part" : 0 , "document_id" : 123 }, "vector" : [ 0.79 ] }, { "id" : 4 , "payload" : { "chunk_part" : 1 , "document_id" : 123 }, "vector" : [ 0.75 ] }, { "id" : 5 , "payload" : { "chunk_part" : 0 , "document_id" : -10 }, "vector" : [ 0.6 ] } ] With the groups API, you will be able to get the best N points for each document, assuming that the payload of the points contains the document ID. Of course there will be times where the best N points cannot be fulfilled due to lack of points or a big distance with respect to the query. In every case, the group_size is a best-effort parameter, akin to the limit parameter.

Search groups REST API ( Schema ): POST /collections/{collection_name}/points/query/groups { // Same as in the regular query API "query": [1.1], // Grouping parameters "group_by": "document_id",  // Path of the field to group by "limit": 4,                 // Max amount of groups "group_size": 2            // Max amount of points per group } client . query_points_groups ( collection_name = " {collection_name} " , # Same as in the regular query_points() API query = [ 1.1 ], # Grouping parameters group_by = "document_id" , # Path of the field to group by limit = 4 , # Max amount of groups group_size = 2 , # Max amount of points per group ) client . queryGroups ( "{collection_name}" , { query : [ 1.1 ], group_by : "document_id" , limit : 4 , group_size : 2 , }); use qdrant_client :: qdrant :: QueryPointGroupsBuilder ; client . query_groups ( QueryPointGroupsBuilder :: new ( "{collection_name}" , "document_id" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . group_size ( 2 u64 ) . with_payload ( true ) . with_vectors ( true ) . limit ( 4 u64 ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.grpc.Points.QueryPointGroups ; import io.qdrant.client.grpc.Points.SearchPointGroups ; import java.util.List ; client . queryGroupsAsync ( QueryPointGroups . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setGroupBy ( "document_id" ) . setLimit ( 4 ) . setGroupSize ( 2 ) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryGroupsAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, groupBy : "document_id" , limit : 4 , groupSize : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

QueryGroups ( context .

Background (), & qdrant .

QueryPointGroups { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), GroupBy : "document_id" , GroupSize : qdrant .

PtrOf ( uint64 ( 2 )), }) The output of a groups call looks like this: { "result" : { "groups" : [ { "id" : "a" , "hits" : [ { "id" : 0 , "score" : 0.91 }, { "id" : 1 , "score" : 0.85 } ] }, { "id" : "b" , "hits" : [ { "id" : 1 , "score" : 0.85 } ] }, { "id" : 123 , "hits" : [ { "id" : 3 , "score" : 0.79 }, { "id" : 4 , "score" : 0.75 } ] }, { "id" : -10 , "hits" : [ { "id" : 5 , "score" : 0.6 } ] } ] }, "status" : "ok" , "time" : 0.001 } The groups are ordered by the score of the top point in the group. Inside each group the points are sorted too.

If the group_by field of a point is an array (e.g.

"document_id": ["a", "b"] ), the point can be included in multiple groups (e.g.

"document_id": "a" and document_id: "b" ).

Limitations : Only keyword and integer payload values are supported for the group_by parameter. Payload values with other types will be ignored.

At the moment, pagination is not enabled when using groups , so the offset parameter is not allowed.

Lookup in groups Having multiple points for parts of the same item often introduces redundancy in the stored data. Which may be fine if the information shared by the points is small, but it can become a problem if the payload is large, because it multiplies the storage space needed to store the points by a factor of the amount of points we have per group.

One way of optimizing storage when using groups is to store the information shared by the points with the same group id in a single point in another collection. Then, when using the groups API , add the with_lookup parameter to bring the information from those points into each group.

This has the extra benefit of having a single point to update when the information shared by the points in a group changes.

For example, if you have a collection of documents, you may want to chunk them and store the points for the chunks in a separate collection, making sure that you store the point id from the document it belongs in the payload of the chunk point.

In this case, to bring the information from the documents into the chunks grouped by the document id, you can use the with_lookup parameter: POST /collections/chunks/points/query/groups { // Same as in the regular query API "query": [1.1], // Grouping parameters "group_by": "document_id", "limit": 2, "group_size": 2, // Lookup parameters "with_lookup": { // Name of the collection to look up points in "collection": "documents", // Options for specifying what to bring from the payload // of the looked up point, true by default "with_payload": ["title", "text"], // Options for specifying what to bring from the vector(s) // of the looked up point, true by default "with_vectors": false } } client . query_points_groups ( collection_name = "chunks" , # Same as in the regular search() API query = [ 1.1 ], # Grouping parameters group_by = "document_id" , # Path of the field to group by limit = 2 , # Max amount of groups group_size = 2 , # Max amount of points per group # Lookup parameters with_lookup = models .

WithLookup ( # Name of the collection to look up points in collection = "documents" , # Options for specifying what to bring from the payload # of the looked up point, True by default with_payload = [ "title" , "text" ], # Options for specifying what to bring from the vector(s) # of the looked up point, True by default with_vectors = False , ), ) client . queryGroups ( "{collection_name}" , { query : [ 1.1 ], group_by : "document_id" , limit : 2 , group_size : 2 , with_lookup : { collection : "documents" , with_payload : [ "title" , "text" ], with_vectors : false , }, }); use qdrant_client :: qdrant :: { with_payload_selector :: SelectorOptions , QueryPointGroupsBuilder , WithLookupBuilder }; client . query_groups ( QueryPointGroupsBuilder :: new ( "{collection_name}" , "document_id" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 2 u64 ) . limit ( 2 u64 ) . with_lookup ( WithLookupBuilder :: new ( "documents" ) . with_payload ( SelectorOptions :: Include ( vec!

[ "title" . to_string (), "text" . to_string ()]. into (), )) . with_vectors ( false ), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.WithPayloadSelectorFactory.include ; import static io.qdrant.client.WithVectorsSelectorFactory.enable ; import io.qdrant.client.grpc.Points.QueryPointGroups ; import io.qdrant.client.grpc.Points.WithLookup ; import java.util.List ; client . queryGroupsAsync ( QueryPointGroups . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setGroupBy ( "document_id" ) . setLimit ( 2 ) . setGroupSize ( 2 ) . setWithLookup ( WithLookup . newBuilder () . setCollection ( "documents" ) . setWithPayload ( include ( List . of ( "title" , "text" ))) . setWithVectors ( enable ( false )) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

SearchGroupsAsync ( collectionName : "{collection_name}" , vector : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, groupBy : "document_id" , limit : 2 , groupSize : 2 , withLookup : new WithLookup { Collection = "documents" , WithPayload = new WithPayloadSelector { Include = new PayloadIncludeSelector { Fields = { new string [] { "title" , "text" } } } }, WithVectors = false } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

QueryGroups ( context .

Background (), & qdrant .

QueryPointGroups { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), GroupBy : "document_id" , GroupSize : qdrant .

PtrOf ( uint64 ( 2 )), WithLookup : & qdrant .

WithLookup { Collection : "documents" , WithPayload : qdrant .

NewWithPayloadInclude ( "title" , "text" ), }, }) For the with_lookup parameter, you can also use the shorthand with_lookup="documents" to bring the whole payload and vector(s) without explicitly specifying it.

The looked up result will show up under lookup in each group.

{ "result" : { "groups" : [ { "id" : 1 , "hits" : [ { "id" : 0 , "score" : 0.91 }, { "id" : 1 , "score" : 0.85 } ], "lookup" : { "id" : 1 , "payload" : { "title" : "Document A" , "text" : "This is document A" } } }, { "id" : 2 , "hits" : [ { "id" : 1 , "score" : 0.85 } ], "lookup" : { "id" : 2 , "payload" : { "title" : "Document B" , "text" : "This is document B" } } } ] }, "status" : "ok" , "time" : 0.001 } Since the lookup is done by matching directly with the point id, the lookup collection must be pre-populated with points where the id matches the group_by value (e.g., document_id) from your primary collection.

Any group id that is not an existing (and valid) point id in the lookup collection will be ignored, and the lookup field will be empty.

Random Sampling Available as of v1.11.0 In some cases it might be useful to retrieve a random sample of points from the collection. This can be useful for debugging, testing, or for providing entry points for exploration.

Random sampling API is a part of Universal Query API and can be used in the same way as regular search API.

POST /collections/{collection_name}/points/query { "query": { "sample": "random" } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) sampled = client . query_points ( collection_name = " {collection_name} " , query = models .

SampleQuery ( sample = models .

Sample .

RANDOM ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const sampled = await client . query ( "{collection_name}" , { query : { sample : "random" , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { Query , QueryPointsBuilder , Sample }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let sampled = client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_sample ( Sample :: Random )) ) . await ? ; import static io.qdrant.client.QueryFactory.sample ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.Sample ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( sample ( Sample .

Random )) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : Sample .

Random ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

QueryGroups ( context .

Background (), & qdrant .

QueryPointGroups { CollectionName : "{collection_name}" , Query : qdrant .

NewQuerySample ( qdrant .

Sample_Random ), }) Query planning Depending on the filter used in the search - there are several possible scenarios for query execution.

Qdrant chooses one of the query execution options depending on the available indexes, the complexity of the conditions and the cardinality of the filtering result.

This process is called query planning.

The strategy selection process relies heavily on heuristics and can vary from release to release.

However, the general principles are: planning is performed for each segment independently (see storage for more information about segments) prefer a full scan if the amount of points is below a threshold estimate the cardinality of a filtered result before selecting a strategy retrieve points using payload index (see indexing ) if cardinality is below threshold use filterable vector index if the cardinality is above a threshold use ACORN when the selectivity (ratio) is low, but the cardinality (an amount) is still high You can adjust the threshold using a configuration file , as well as independently for each collection.

================================================================================
PAGE 9/39
================================================================================
Title: Explore the data
URL: https://qdrant.tech/documentation/concepts/explore/
--------------------------------------------------------------------------------

Explore the data After mastering the concepts in search , you can start exploring your data in other ways. Qdrant provides a stack of APIs that allow you to find similar vectors in a different fashion, as well as to find the most dissimilar ones. These are useful tools for recommendation systems, data exploration, and data cleaning.

Recommendation API In addition to the regular search, Qdrant also allows you to search based on multiple positive and negative examples. The API is called recommend , and the examples can be point IDs, so that you can leverage the already encoded objects; and, as of v1.6, you can also use raw vectors as input, so that you can create your vectors on the fly without uploading them as points.

REST API - API Schema definition is available here POST /collections/{collection_name}/points/query { "query": { "recommend": { "positive": [100, 231], "negative": [718, [0.2, 0.3, 0.4, 0.5]], "strategy": "average_vector" } }, "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = models .

RecommendQuery ( recommend = models .

RecommendInput ( positive = [ 100 , 231 ], negative = [ 718 , [ 0.2 , 0.3 , 0.4 , 0.5 ]], strategy = models .

RecommendStrategy .

AVERAGE_VECTOR , ) ), query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" , ), ) ] ), limit = 3 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { recommend : { positive : [ 100 , 231 ], negative : [ 718 , [ 0.2 , 0.3 , 0.4 , 0.5 ]], strategy : "average_vector" } }, filter : { must : [ { key : "city" , match : { value : "London" , }, }, ], }, limit : 3 }); use qdrant_client :: qdrant :: { Condition , Filter , QueryPointsBuilder , RecommendInputBuilder , RecommendStrategy , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( RecommendInputBuilder :: default () . add_positive ( 100 ) . add_positive ( 231 ) . add_positive ( vec!

[ 0.2 , 0.3 , 0.4 , 0.5 ]) . add_negative ( 718 ) . strategy ( RecommendStrategy :: AverageVector ) . build (), ) . limit ( 3 ) . filter ( Filter :: must ([ Condition :: matches ( "city" , "London" . to_string (), )])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.recommend ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.RecommendInput ; import io.qdrant.client.grpc.Points.RecommendStrategy ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( recommend ( RecommendInput . newBuilder () . addAllPositive ( List . of ( vectorInput ( 100 ), vectorInput ( 200 ), vectorInput ( 100 .

0f , 231 .

0f ))) . addAllNegative ( List . of ( vectorInput ( 718 ), vectorInput ( 0 .

2f , 0 .

3f , 0 .

4f , 0 .

5f ))) . setStrategy ( RecommendStrategy .

AverageVector ) . build ())) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "city" , "London" ))) . setLimit ( 3 ) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new RecommendInput { Positive = { 100 , 231 }, Negative = { 718 } }, filter : MatchKeyword ( "city" , "London" ), limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryRecommend ( & qdrant .

RecommendInput { Positive : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 231 )), }, Negative : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, }), Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, }, }) Example result of this API would be { "result" : [ { "id" : 10 , "score" : 0.81 }, { "id" : 14 , "score" : 0.75 }, { "id" : 11 , "score" : 0.73 } ], "status" : "ok" , "time" : 0.001 } The algorithm used to get the recommendations is selected from the available strategy options. Each of them has its own strengths and weaknesses, so experiment and choose the one that works best for your case.

Average vector strategy The default and first strategy added to Qdrant is called average_vector . It preprocesses the input examples to create a single vector that is used for the search. Since the preprocessing step happens very fast, the performance of this strategy is on-par with regular search. The intuition behind this kind of recommendation is that each vector component represents an independent feature of the data, so, by averaging the examples, we should get a good recommendation.

The way to produce the searching vector is by first averaging all the positive and negative examples separately, and then combining them into a single vector using the following formula: avg_positive + avg_positive - avg_negative In the case of not having any negative examples, the search vector will simply be equal to avg_positive .

This is the default strategy that‚Äôs going to be set implicitly, but you can explicitly define it by setting "strategy": "average_vector" in the recommendation request.

Best score strategy Available as of v1.6.0 A new strategy introduced in v1.6, is called best_score . It is based on the idea that the best way to find similar vectors is to find the ones that are closer to a positive example, while avoiding the ones that are closer to a negative one.

The way it works is that each candidate is measured against every example, then we select the best positive and best negative scores. The final score is chosen with this step formula: // Sigmoid function to normalize the score between 0 and 1 let sigmoid = | x | 0.5 * ( 1.0 + ( x / ( 1.0 + x . abs ()))); let score = if best_positive_score > best_negative_score { sigmoid ( best_positive_score ) } else { - sigmoid ( best_negative_score ) };

Since we are computing similarities to every example at each step of the search, the performance of this strategy will be linearly impacted by the amount of examples. This means that the more examples you provide, the slower the search will be. However, this strategy can be very powerful and should be more embedding-agnostic.

To use this algorithm, you need to set "strategy": "best_score" in the recommendation request.

Using only negative examples A beneficial side-effect of best_score strategy is that you can use it with only negative examples. This will allow you to find the most dissimilar vectors to the ones you provide. This can be useful for finding outliers in your data, or for finding the most dissimilar vectors to a given one.

Combining negative-only examples with filtering can be a powerful tool for data exploration and cleaning.

Sum scores strategy Another strategy for using multiple query vectors simultaneously is to just sum their scores against the candidates. In qdrant, this is called sum_scores strategy.

This strategy was used in this paper by UKP Lab , hessian.ai and cohere.ai to incorporate relevance feedback into a subsequent search. In the paper this boosted the nDCG@20 performance by 5.6% points when using 2-8 positive feedback documents.

The formula that this strategy implements is $$ s_i = \sum_{v_q\in Q^+}s(v_q, v_i) - \sum_{v_q\in Q^-}s(v_q, v_i) $$ where $Q^+$ is the set of positive examples, $Q^-$ is the set of negative examples, and $s(v_q, v_i)$ is the score of the vector $v_q$ against the vector $v_i$ As with best_score , this strategy also allows using only negative examples.

Multiple vectors Available as of v0.10.0 If the collection was created with multiple vectors, the name of the vector should be specified in the recommendation request: POST /collections/{collection_name}/points/query { "query": { "recommend": { "positive": [100, 231], "negative": [718] } }, "using": "image", "limit": 10 } client . query_points ( collection_name = " {collection_name} " , query = models .

RecommendQuery ( recommend = models .

RecommendInput ( positive = [ 100 , 231 ], negative = [ 718 ], ) ), using = "image" , limit = 10 , ) client . query ( "{collection_name}" , { query : { recommend : { positive : [ 100 , 231 ], negative : [ 718 ], } }, using : "image" , limit : 10 }); use qdrant_client :: qdrant :: { QueryPointsBuilder , RecommendInputBuilder }; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( RecommendInputBuilder :: default () . add_positive ( 100 ) . add_positive ( 231 ) . add_negative ( 718 ) . build (), ) . limit ( 10 ) . using ( "image" ), ) . await ? ; import static io.qdrant.client.QueryFactory.recommend ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.RecommendInput ; import java.util.List ; client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( recommend ( RecommendInput . newBuilder () . addAllPositive ( List . of ( vectorInput ( 100 ), vectorInput ( 231 ))) . addAllNegative ( List . of ( vectorInput ( 718 ))) . build ())) . setUsing ( "image" ) . setLimit ( 10 ) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new RecommendInput { Positive = { 100 , 231 }, Negative = { 718 } }, usingVector : "image" , limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryRecommend ( & qdrant .

RecommendInput { Positive : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 231 )), }, Negative : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, }), Using : qdrant .

PtrOf ( "image" ), }) Parameter using specifies which stored vectors to use for the recommendation.

Lookup vectors from another collection Available as of v0.11.6 If you have collections with vectors of the same dimensionality, and you want to look for recommendations in one collection based on the vectors of another collection, you can use the lookup_from parameter.

It might be useful, e.g. in the item-to-user recommendations scenario.

Where user and item embeddings, although having the same vector parameters (distance type and dimensionality), are usually stored in different collections.

POST /collections/{collection_name}/points/query { "query": { "recommend": { "positive": [100, 231], "negative": [718] } }, "limit": 10, "lookup_from": { "collection": "{external_collection_name}", "vector": "{external_vector_name}" } } client . query_points ( collection_name = " {collection_name} " , query = models .

RecommendQuery ( recommend = models .

RecommendInput ( positive = [ 100 , 231 ], negative = [ 718 ], ) ), using = "image" , limit = 10 , lookup_from = models .

LookupLocation ( collection = " {external_collection_name} " , vector = " {external_vector_name} " ), ) client . query ( "{collection_name}" , { query : { recommend : { positive : [ 100 , 231 ], negative : [ 718 ], } }, using : "image" , limit : 10 , lookup_from : { collection : "{external_collection_name}" , vector : "{external_vector_name}" } }); use qdrant_client :: qdrant :: { LookupLocationBuilder , QueryPointsBuilder , RecommendInputBuilder }; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( RecommendInputBuilder :: default () . add_positive ( 100 ) . add_positive ( 231 ) . add_negative ( 718 ) . build (), ) . limit ( 10 ) . using ( "image" ) . lookup_from ( LookupLocationBuilder :: new ( "{external_collection_name}" ) . vector_name ( "{external_vector_name}" ), ), ) . await ? ; import static io.qdrant.client.QueryFactory.recommend ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.grpc.Points.LookupLocation ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.RecommendInput ; import java.util.List ; client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( recommend ( RecommendInput . newBuilder () . addAllPositive ( List . of ( vectorInput ( 100 ), vectorInput ( 231 ))) . addAllNegative ( List . of ( vectorInput ( 718 ))) . build ())) . setUsing ( "image" ) . setLimit ( 10 ) . setLookupFrom ( LookupLocation . newBuilder () . setCollectionName ( "{external_collection_name}" ) . setVectorName ( "{external_vector_name}" ) . build ()) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new RecommendInput { Positive = { 100 , 231 }, Negative = { 718 } }, usingVector : "image" , limit : 10 , lookupFrom : new LookupLocation { CollectionName = "{external_collection_name}" , VectorName = "{external_vector_name}" , } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryRecommend ( & qdrant .

RecommendInput { Positive : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 231 )), }, Negative : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, }), Using : qdrant .

PtrOf ( "image" ), LookupFrom : & qdrant .

LookupLocation { CollectionName : "{external_collection_name}" , VectorName : qdrant .

PtrOf ( "{external_vector_name}" ), }, }) Vectors are retrieved from the external collection by ids provided in the positive and negative lists.

These vectors then used to perform the recommendation in the current collection, comparing against the ‚Äúusing‚Äù or default vector.

Batch recommendation API Available as of v0.10.0 Similar to the batch search API in terms of usage and advantages, it enables the batching of recommendation requests.

POST /collections/{collection_name}/query/batch { "searches": [ { "query": { "recommend": { "positive": [100, 231], "negative": [718] } }, "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "limit": 10 }, { "query": { "recommend": { "positive": [200, 67], "negative": [300] } }, "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "limit": 10 } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) filter_ = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" , ), ) ] ) recommend_queries = [ models .

QueryRequest ( query = models .

RecommendQuery ( recommend = models .

RecommendInput ( positive = [ 100 , 231 ], negative = [ 718 ]) ), filter = filter_ , limit = 3 , ), models .

QueryRequest ( query = models .

RecommendQuery ( recommend = models .

RecommendInput ( positive = [ 200 , 67 ], negative = [ 300 ]) ), filter = filter_ , limit = 3 , ), ] client . query_batch_points ( collection_name = " {collection_name} " , requests = recommend_queries ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const filter = { must : [ { key : "city" , match : { value : "London" , }, }, ], }; const searches = [ { query : { recommend : { positive : [ 100 , 231 ], negative : [ 718 ] } }, filter , limit : 3 , }, { query : { recommend : { positive : [ 200 , 67 ], negative : [ 300 ] } }, filter , limit : 3 , }, ]; client . queryBatch ( "{collection_name}" , { searches , }); use qdrant_client :: qdrant :: { Condition , Filter , QueryBatchPointsBuilder , QueryPointsBuilder , RecommendInputBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let filter = Filter :: must ([ Condition :: matches ( "city" , "London" . to_string ())]); let recommend_queries = vec!

[ QueryPointsBuilder :: new ( "{collection_name}" ) . query ( RecommendInputBuilder :: default () . add_positive ( 100 ) . add_positive ( 231 ) . add_negative ( 718 ) . build (), ) . filter ( filter . clone ()) . build (), QueryPointsBuilder :: new ( "{collection_name}" ) . query ( RecommendInputBuilder :: default () . add_positive ( 200 ) . add_positive ( 67 ) . add_negative ( 300 ) . build (), ) . filter ( filter ) . build (), ]; client . query_batch ( QueryBatchPointsBuilder :: new ( "{collection_name}" , recommend_queries , )) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.recommend ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.RecommendInput ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ());

Filter filter = Filter . newBuilder (). addMust ( matchKeyword ( "city" , "London" )). build ();

List < QueryPoints > recommendQueries = List . of ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( recommend ( RecommendInput . newBuilder () . addAllPositive ( List . of ( vectorInput ( 100 ), vectorInput ( 231 ))) . addAllNegative ( List . of ( vectorInput ( 731 ))) . build ())) . setFilter ( filter ) . setLimit ( 3 ) . build (), QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( recommend ( RecommendInput . newBuilder () . addAllPositive ( List . of ( vectorInput ( 200 ), vectorInput ( 67 ))) . addAllNegative ( List . of ( vectorInput ( 300 ))) . build ())) . setFilter ( filter ) . setLimit ( 3 ) . build ()); client . queryBatchAsync ( "{collection_name}" , recommendQueries ). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); var filter = MatchKeyword ( "city" , "london" ); await client .

QueryBatchAsync ( collectionName : "{collection_name}" , queries : [ new QueryPoints() { CollectionName = "{collection_name}", Query = new RecommendInput { Positive = { 100, 231 }, Negative = { 718 }, }, Limit = 3, Filter = filter, }, new QueryPoints() { CollectionName = "{collection_name}", Query = new RecommendInput { Positive = { 200, 67 }, Negative = { 300 }, }, Limit = 3, Filter = filter, } ] ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) filter := qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, } client .

QueryBatch ( context .

Background (), & qdrant .

QueryBatchPoints { CollectionName : "{collection_name}" , QueryPoints : [] * qdrant .

QueryPoints { { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryRecommend ( & qdrant .

RecommendInput { Positive : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 231 )), }, Negative : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, }, ), Filter : & filter , }, { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryRecommend ( & qdrant .

RecommendInput { Positive : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 200 )), qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 67 )), }, Negative : [] * qdrant .

VectorInput { qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 300 )), }, }, ), Filter : & filter , }, }, }, ) The result of this API contains one array per recommendation requests.

{ "result" : [ [ { "id" : 10 , "score" : 0.81 }, { "id" : 14 , "score" : 0.75 }, { "id" : 11 , "score" : 0.73 } ], [ { "id" : 1 , "score" : 0.92 }, { "id" : 3 , "score" : 0.89 }, { "id" : 9 , "score" : 0.75 } ] ], "status" : "ok" , "time" : 0.001 } Discovery API Available as of v1.7 REST API Schema definition available here In this API, Qdrant introduces the concept of context , which is used for splitting the space. Context is a set of positive-negative pairs, and each pair divides the space into positive and negative zones. In that mode, the search operation prefers points based on how many positive zones they belong to (or how much they avoid negative zones).

The interface for providing context is similar to the recommendation API (ids or raw vectors). Still, in this case, they need to be provided in the form of positive-negative pairs.

Discovery API lets you do two new types of search: Discovery search : Uses the context (the pairs of positive-negative vectors) and a target to return the points more similar to the target, but constrained by the context.

Context search : Using only the context pairs, get the points that live in the best zone, where loss is minimized The way positive and negative examples should be arranged in the context pairs is completely up to you. So you can have the flexibility of trying out different permutation techniques based on your model and data.

Discovery search This type of search works specially well for combining multimodal, vector-constrained searches. Qdrant already has extensive support for filters, which constrain the search based on its payload, but using discovery search, you can also constrain the vector space in which the search is performed.

The formula for the discovery score can be expressed as: $$ \text{rank}(v^+, v^-) = \begin{cases} 1, &\quad s(v^+) \geq s(v^-) \\ -1, &\quad s(v^+) < s(v^-) \end{cases} $$ where $v^+$ represents a positive example, $v^-$ represents a negative example, and $s(v)$ is the similarity score of a vector $v$ to the target vector. The discovery score is then computed as: $$ \text{discovery score} = \text{sigmoid}(s(v_t))+ \sum \text{rank}(v_i^+, v_i^-), $$ where $s(v)$ is the similarity function, $v_t$ is the target vector, and again $v_i^+$ and $v_i^-$ are the positive and negative examples, respectively. The sigmoid function is used to normalize the score between 0 and 1 and the sum of ranks is used to penalize vectors that are closer to the negative examples than to the positive ones. In other words, the sum of individual ranks determines how many positive zones a point is in, while the closeness hierarchy comes second.

Example: POST /collections/{collection_name}/points/query { "query": { "discover": { "target": [0.2, 0.1, 0.9, 0.7], "context": [ { "positive": 100, "negative": 718 }, { "positive": 200, "negative": 300 } ] } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) discover_queries = [ models .

QueryRequest ( query = models .

DiscoverQuery ( discover = models .

DiscoverInput ( target = [ 0.2 , 0.1 , 0.9 , 0.7 ], context = [ models .

ContextPair ( positive = 100 , negative = 718 , ), models .

ContextPair ( positive = 200 , negative = 300 , ), ], ) ), limit = 10 , ), ] client . query_batch_points ( collection_name = " {collection_name} " , requests = discover_queries ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { discover : { target : [ 0.2 , 0.1 , 0.9 , 0.7 ], context : [ { positive : 100 , negative : 718 , }, { positive : 200 , negative : 300 , }, ], } }, limit : 10 , }); use qdrant_client :: qdrant :: { ContextInputBuilder , DiscoverInputBuilder , QueryPointsBuilder }; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ). query ( DiscoverInputBuilder :: new ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ], ContextInputBuilder :: default () . add_pair ( 100 , 718 ) . add_pair ( 200 , 300 ), ) . build (), ), ) . await ? ; import static io.qdrant.client.QueryFactory.discover ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.ContextInput ; import io.qdrant.client.grpc.Points.ContextInputPair ; import io.qdrant.client.grpc.Points.DiscoverInput ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( discover ( DiscoverInput . newBuilder () . setTarget ( vectorInput ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setContext ( ContextInput . newBuilder () . addAllPairs ( List . of ( ContextInputPair . newBuilder () . setPositive ( vectorInput ( 100 )) . setNegative ( vectorInput ( 718 )) . build (), ContextInputPair . newBuilder () . setPositive ( vectorInput ( 200 )) . setNegative ( vectorInput ( 300 )) . build ())) . build ()) . build ())) . setLimit ( 10 ) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new DiscoverInput { Target = new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, Context = new ContextInput { Pairs = { new ContextInputPair { Positive = 100 , Negative = 718 }, new ContextInputPair { Positive = 200 , Negative = 300 }, } }, }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryDiscover ( & qdrant .

DiscoverInput { Target : qdrant .

NewVectorInput ( 0.2 , 0.1 , 0.9 , 0.7 ), Context : & qdrant .

ContextInput { Pairs : [] * qdrant .

ContextInputPair { { Positive : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), Negative : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, { Positive : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 200 )), Negative : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 300 )), }, }, }, }), }) Context search Conversely, in the absence of a target, a rigid integer-by-integer function doesn‚Äôt provide much guidance for the search when utilizing a proximity graph like HNSW. Instead, context search employs a function derived from the triplet-loss concept, which is usually applied during model training. For context search, this function is adapted to steer the search towards areas with fewer negative examples.

We can directly associate the score function to a loss function, where 0.0 is the maximum score a point can have, which means it is only in positive areas. As soon as a point exists closer to a negative example, its loss will simply be the difference of the positive and negative similarities.

$$ \text{context score} = \sum \min(s(v^+_i) - s(v^-_i), 0.0) $$ Where $v^+_i$ and $v^-_i$ are the positive and negative examples of each pair, and $s(v)$ is the similarity function.

Using this kind of search, you can expect the output to not necessarily be around a single point, but rather, to be any point that isn‚Äôt closer to a negative example, which creates a constrained diverse result. So, even when the API is not called recommend , recommendation systems can also use this approach and adapt it for their specific use-cases.

Example: POST /collections/{collection_name}/points/query { "query": { "context": [ { "positive": 100, "negative": 718 }, { "positive": 200, "negative": 300 } ] }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) discover_queries = [ models .

QueryRequest ( query = models .

ContextQuery ( context = [ models .

ContextPair ( positive = 100 , negative = 718 , ), models .

ContextPair ( positive = 200 , negative = 300 , ), ], ), limit = 10 , ), ] client . query_batch_points ( collection_name = " {collection_name} " , requests = discover_queries ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { context : [ { positive : 100 , negative : 718 , }, { positive : 200 , negative : 300 , }, ] }, limit : 10 , }); use qdrant_client :: qdrant :: { ContextInputBuilder , QueryPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ). query ( ContextInputBuilder :: default () . add_pair ( 100 , 718 ) . add_pair ( 200 , 300 ) . build (), ), ) . await ? ; import static io.qdrant.client.QueryFactory.context ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.ContextInput ; import io.qdrant.client.grpc.Points.ContextInputPair ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( context ( ContextInput . newBuilder () . addAllPairs ( List . of ( ContextInputPair . newBuilder () . setPositive ( vectorInput ( 100 )) . setNegative ( vectorInput ( 718 )) . build (), ContextInputPair . newBuilder () . setPositive ( vectorInput ( 200 )) . setNegative ( vectorInput ( 300 )) . build ())) . build ())) . setLimit ( 10 ) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new ContextInput { Pairs = { new ContextInputPair { Positive = 100 , Negative = 718 }, new ContextInputPair { Positive = 200 , Negative = 300 }, } }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryContext ( & qdrant .

ContextInput { Pairs : [] * qdrant .

ContextInputPair { { Positive : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 100 )), Negative : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 718 )), }, { Positive : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 200 )), Negative : qdrant .

NewVectorInputID ( qdrant .

NewIDNum ( 300 )), }, }, }), }) Distance Matrix Available as of v1.12.0 The distance matrix API allows to calculate the distance between sampled pairs of vectors and to return the result as a sparse matrix.

Such API enables new data exploration use cases such as clustering similar vectors, visualization of connections or dimension reduction.

The API input request consists of the following parameters: sample : the number of vectors to sample limit : the number of scores to return per sample filter : the filter to apply to constraint the samples Let‚Äôs have a look at a basic example with sample=100 , limit=10 : The engine starts by selecting 100 random points from the collection, then for each of the selected points, it will compute the top 10 closest points within the samples.

This will results in a total of 1000 scores represented as a sparse matrix for efficient processing.

The distance matrix API offers two output formats to ease the integration with different tools.

Pairwise format Returns the distance matrix as a list of pairs of point ids with their respective score.

POST /collections/{collection_name}/points/search/matrix/pairs { "sample": 10, "limit": 2, "filter": { "must": { "key": "color", "match": { "value": "red" } } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . search_matrix_pairs ( collection_name = " {collection_name} " , sample = 10 , limit = 2 , query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ) ), ] ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . searchMatrixPairs ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, sample : 10 , limit : 2 , }); use qdrant_client :: qdrant :: { Condition , Filter , SearchMatrixPointsBuilder }; client . search_matrix_pairs ( SearchMatrixPointsBuilder :: new ( "collection_name" ) . filter ( Filter :: must ( vec!

[ Condition :: matches ( "color" , "red" . to_string (), )])) . sample ( 10 ) . limit ( 2 ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.SearchMatrixPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . searchMatrixPairsAsync ( SearchMatrixPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build ()) . setSample ( 10 ) . setLimit ( 2 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

SearchMatrixPairsAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "color" , "red" ), sample : 10 , limit : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) sample := uint64 ( 10 ) limit := uint64 ( 2 ) res , err := client .

SearchMatrixPairs ( context .

Background (), & qdrant .

SearchMatrixPoints { CollectionName : "{collection_name}" , Sample : & sample , Limit : & limit , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, }) Returns { "result" : { "pairs" : [ { "a" : 1 , "b" : 3 , "score" : 1.4063001 }, { "a" : 1 , "b" : 4 , "score" : 1.2531 }, { "a" : 2 , "b" : 1 , "score" : 1.1550001 }, { "a" : 2 , "b" : 8 , "score" : 1.1359 }, { "a" : 3 , "b" : 1 , "score" : 1.4063001 }, { "a" : 3 , "b" : 4 , "score" : 1.2218001 }, { "a" : 4 , "b" : 1 , "score" : 1.2531 }, { "a" : 4 , "b" : 3 , "score" : 1.2218001 }, { "a" : 5 , "b" : 3 , "score" : 0.70239997 }, { "a" : 5 , "b" : 1 , "score" : 0.6146 }, { "a" : 6 , "b" : 3 , "score" : 0.6353 }, { "a" : 6 , "b" : 4 , "score" : 0.5093 }, { "a" : 7 , "b" : 3 , "score" : 1.0990001 }, { "a" : 7 , "b" : 1 , "score" : 1.0349001 }, { "a" : 8 , "b" : 2 , "score" : 1.1359 }, { "a" : 8 , "b" : 3 , "score" : 1.0553 } ] } } Offset format Returns the distance matrix as a four arrays: offsets_row and offsets_col , represent the positions of non-zero distance values in the matrix. scores contains the distance values. ids contains the point ids corresponding to the distance values.

POST /collections/{collection_name}/points/search/matrix/offsets { "sample": 10, "limit": 2, "filter": { "must": { "key": "color", "match": { "value": "red" } } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . search_matrix_offsets ( collection_name = " {collection_name} " , sample = 10 , limit = 2 , query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ) ), ] ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . searchMatrixOffsets ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, sample : 10 , limit : 2 , }); use qdrant_client :: qdrant :: { Condition , Filter , SearchMatrixPointsBuilder }; client . search_matrix_offsets ( SearchMatrixPointsBuilder :: new ( "collection_name" ) . filter ( Filter :: must ( vec!

[ Condition :: matches ( "color" , "red" . to_string (), )])) . sample ( 10 ) . limit ( 2 ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.SearchMatrixPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . searchMatrixOffsetsAsync ( SearchMatrixPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build ()) . setSample ( 10 ) . setLimit ( 2 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

SearchMatrixOffsetsAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "color" , "red" ), sample : 10 , limit : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) sample := uint64 ( 10 ) limit := uint64 ( 2 ) res , err := client .

SearchMatrixOffsets ( context .

Background (), & qdrant .

SearchMatrixPoints { CollectionName : "{collection_name}" , Sample : & sample , Limit : & limit , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, }) Returns { "result" : { "offsets_row" : [ 0 , 0 , 1 , 1 , 2 , 2 , 3 , 3 , 4 , 4 , 5 , 5 , 6 , 6 , 7 , 7 ], "offsets_col" : [ 2 , 3 , 0 , 7 , 0 , 3 , 0 , 2 , 2 , 0 , 2 , 3 , 2 , 0 , 1 , 2 ], "scores" : [ 1.4063001 , 1.2531 , 1.1550001 , 1.1359 , 1.4063001 , 1.2218001 , 1.2531 , 1.2218001 , 0.70239997 , 0.6146 , 0.6353 , 0.5093 , 1.0990001 , 1.0349001 , 1.1359 , 1.0553 ], "ids" : [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ] } }
================================================================================
PAGE 10/39
================================================================================
Title: Hybrid and Multi-Stage Queries
URL: https://qdrant.tech/documentation/concepts/hybrid-queries/
--------------------------------------------------------------------------------

Hybrid and Multi-Stage Queries Available as of v1.10.0 With the introduction of multiple named vectors per point , there are use-cases when the best search is obtained by combining multiple queries, or by performing the search in more than one stage.

Qdrant has a flexible and universal interface to make this possible, called Query API ( API reference ).

The main component for making the combinations of queries possible is the prefetch parameter, which enables making sub-requests.

Specifically, whenever a query has at least one prefetch, Qdrant will: Perform the prefetch query (or queries), Apply the main query over the results of its prefetch(es).

Additionally, prefetches can have prefetches themselves, so you can have nested prefetches.

Hybrid Search One of the most common problems when you have different representations of the same data is to combine the queried points for each representation into a single result.

Fusing results from multiple queries For example, in text search, it is often useful to combine dense and sparse vectors to get the best of both worlds: semantic understanding from dense vectors and precise word matching from sparse vectors.

Qdrant has a few ways of fusing the results from different queries: rrf and dbsf Reciprocal Rank Fusion (RRF) RRF considers the positions of results within each query, and boosts the ones that appear closer to the top in multiple sets of results.

The formula is simple, but needs access to the rank of each result in each query.

$$ score(d\in D) = \sum_{r_d\in R(d)} \frac{1}{k + r_d} $$ Where $D$ the set of points across all results, $R(d)$ is the set of rankings for a particular document, and $k$ is a constant (set to 2 by default).

Here is an example of RRF for a query containing two prefetches against different named vectors configured to hold sparse and dense vectors, respectively.

POST /collections/{collection_name}/points/query { "prefetch": [ { "query": { "indices": [1, 42],    // <‚îê "values": [0.22, 0.8]  // <‚î¥‚îÄsparse vector }, "using": "sparse", "limit": 20 }, { "query": [0.01, 0.45, 0.67, ...], // <-- dense vector "using": "dense", "limit": 20 } ], "query": { "fusion": "rrf" }, // <--- reciprocal rank fusion "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , prefetch = [ models .

Prefetch ( query = models .

SparseVector ( indices = [ 1 , 42 ], values = [ 0.22 , 0.8 ]), using = "sparse" , limit = 20 , ), models .

Prefetch ( query = [ 0.01 , 0.45 , 0.67 ], # <-- dense vector using = "dense" , limit = 20 , ), ], query = models .

FusionQuery ( fusion = models .

Fusion .

RRF ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : [ { query : { values : [ 0.22 , 0.8 ], indices : [ 1 , 42 ], }, using : 'sparse' , limit : 20 , }, { query : [ 0.01 , 0.45 , 0.67 ], using : 'dense' , limit : 20 , }, ], query : { fusion : 'rrf' , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { Fusion , PrefetchQueryBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ([( 1 , 0.22 ), ( 42 , 0.8 )]. as_slice ())) . using ( "sparse" ) . limit ( 20 u64 ) ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ( vec!

[ 0.01 , 0.45 , 0.67 ])) . using ( "dense" ) . limit ( 20 u64 ) ) . query ( Query :: new_fusion ( Fusion :: Rrf )) ). await ? ; import static io.qdrant.client.QueryFactory.fusion ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Fusion ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( List . of ( 0 .

22f , 0 .

8f ), List . of ( 1 , 42 ))) . setUsing ( "sparse" ) . setLimit ( 20 ) . build ()) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( List . of ( 0 .

01f , 0 .

45f , 0 .

67f ))) . setUsing ( "dense" ) . setLimit ( 20 ) . build ()) . setQuery ( fusion ( Fusion .

RRF )) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : new List < PrefetchQuery > { new () { Query = new ( float , uint )[] { ( 0.22f , 1 ), ( 0.8f , 42 ), }, Using = "sparse" , Limit = 20 }, new () { Query = new float [] { 0.01f , 0.45f , 0.67f }, Using = "dense" , Limit = 20 } }, query : Fusion .

Rrf ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQuerySparse ([] uint32 { 1 , 42 }, [] float32 { 0.22 , 0.8 }), Using : qdrant .

PtrOf ( "sparse" ), }, { Query : qdrant .

NewQueryDense ([] float32 { 0.01 , 0.45 , 0.67 }), Using : qdrant .

PtrOf ( "dense" ), }, }, Query : qdrant .

NewQueryFusion ( qdrant .

Fusion_RRF ), }) Parametrized RRF Available as of v1.16.0 To change the value of constant $k$ in the formula, use the dedicated rrf query variant.

POST /collections/{collection_name}/points/query { "prefetch": [ // 2+ prefetches here ], "query": { "rrf": {"k": 60 } }, // <--- parameterized reciprocal rank fusion "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , prefetch = [ # 2+ prefetches here ], query = models .

RrfQuery ( rrf = models .

Rrf ( k = 60 )), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : [ // 2+ prefetches here ], query : { rrf : { k : 60 } }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { RrfBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) // .add_prefetch(...)  <‚îê // .add_prefetch(...)  <‚î¥‚îÄ 2+ prefetches here . query ( Query :: new_rrf ( RrfBuilder :: with_k ( 60 ))) ). await ? ; import static io.qdrant.client.QueryFactory.rrf ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.Rrf ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) // .addPrefetch(...) <‚îê // .addPrefetch(...) <‚î¥‚îÄ 2+ prefetches here . setQuery ( rrf ( Rrf . newBuilder (). setK ( 60 ). build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : new List < PrefetchQuery > { // 2+ prefetches here }, query : new Rrf { K = 60 , } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { // 2+ prefetches here }, Query : qdrant .

NewQueryRRF ( & qdrant .

Rrf { K : qdrant .

PtrOf ( uint32 ( 60 )), }), }) Distribution-Based Score Fusion (DBSF) Available as of v1.11.0 DBSF normalizes the scores of the points in each query, using the mean +/- the 3rd standard deviation as limits, and then sums the scores of the same point across different queries.

Multi-stage queries In general, larger vector representations give more accurate search results, but makes them more expensive to compute.

Splitting the search into two stages is a known technique to mitigate this effect: First, use a smaller and cheaper representation to get a large list of candidates.

Then, re-score the candidates using the larger and more accurate representation.

There are a few ways to build search architectures around this idea: The quantized vectors as a first stage, and the full-precision vectors as a second stage.

Leverage Matryoshka Representation Learning ( MRL ) to generate candidate vectors with a shorter vector, and then refine them with a longer one.

Use regular dense vectors to pre-fetch the candidates, and then re-score them with a multi-vector model like ColBERT .

To get the best of all worlds, Qdrant has a convenient interface to perform the queries in stages, such that the coarse results are fetched first, and then they are refined later with larger vectors.

Re-scoring examples Fetch 1000 results using a shorter MRL byte vector, then re-score them using the full vector and get the top 10.

POST /collections/{collection_name}/points/query { "prefetch": {
"query": [1, 23, 45, 67], // <------------- small byte vector

"using": "mrl_byte" "limit": 1000 }, "query": [0.01, 0.299, 0.45, 0.67, ...], // <-- full vector "using": "full", "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( query = [ 1 , 23 , 45 , 67 ],
# <------------- small byte vector

using = "mrl_byte" , limit = 1000 , ), query = [ 0.01 , 0.299 , 0.45 , 0.67 ], # <-- full vector using = "full" , limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : { query : [ 1 , 23 , 45 , 67 ],
// <------------- small byte vector

using : 'mrl_byte' , limit : 1000 , }, query : [ 0.01 , 0.299 , 0.45 , 0.67 ], // <-- full vector, using : 'full' , limit : 10 , }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PrefetchQueryBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ( vec!

[ 1.0 , 23.0 , 45.0 , 67.0 ])) . using ( "mlr_byte" ) . limit ( 1000 u64 ) ) . query ( Query :: new_nearest ( vec!

[ 0.01 , 0.299 , 0.45 , 0.67 ])) . using ( "full" ) . limit ( 10 u64 ) ). await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 1 , 23 , 45 , 67 ))
// <------------- small byte vector

. setLimit ( 1000 ) . setUsing ( "mrl_byte" ) . build ()) . setQuery ( nearest ( 0 .

01f , 0 .

299f , 0 .

45f , 0 .

67f )) // <-- full vector . setUsing ( "full" ) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : new List < PrefetchQuery > { new () { Query = new float [] { 1 , 23 , 45 , 67 },
// <------------- small byte vector

Using = "mrl_byte" , Limit = 1000 } }, query : new float [] { 0.01f , 0.299f , 0.45f , 0.67f }, // <-- full vector usingVector : "full" , limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQueryDense ([] float32 { 1 , 23 , 45 , 67 }), Using : qdrant .

PtrOf ( "mrl_byte" ), Limit : qdrant .

PtrOf ( uint64 ( 1000 )), }, }, Query : qdrant .

NewQueryDense ([] float32 { 0.01 , 0.299 , 0.45 , 0.67 }), Using : qdrant .

PtrOf ( "full" ), }) Fetch 100 results using the default vector, then re-score them using a multi-vector to get the top 10.

POST /collections/{collection_name}/points/query { "prefetch": { "query": [0.01, 0.45, 0.67, ...], // <-- dense vector "limit": 100 }, "query": [           // <‚îÄ‚îê [0.1, 0.2, ...], // < ‚îÇ [0.2, 0.1, ...], // < ‚îú‚îÄ multi-vector [0.8, 0.9, ...]  // < ‚îÇ ],                   // <‚îÄ‚îò "using": "colbert", "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( query = [ 0.01 , 0.45 , 0.67 , 0.53 ], # <-- dense vector limit = 100 , ), query = [ [ 0.1 , 0.2 , 0.32 ], # <‚îÄ‚îê [ 0.2 , 0.1 , 0.52 ], # < ‚îú‚îÄ multi-vector [ 0.8 , 0.9 , 0.93 ], # < ‚îò ], using = "colbert" , limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : { query : [ 1 , 23 , 45 , 67 ],
// <------------- small byte vector

limit : 100 , }, query : [ [ 0.1 , 0.2 ], // <‚îÄ‚îê [ 0.2 , 0.1 ], // < ‚îú‚îÄ multi-vector [ 0.8 , 0.9 ], // < ‚îò ], using : 'colbert' , limit : 10 , }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PrefetchQueryBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ( vec!

[ 0.01 , 0.45 , 0.67 ])) . limit ( 100 u64 ) ) . query ( Query :: new_nearest ( vec!

[ vec!

[ 0.1 , 0.2 ], vec!

[ 0.2 , 0.1 ], vec!

[ 0.8 , 0.9 ], ])) . using ( "colbert" ) . limit ( 10 u64 ) ). await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 0 .

01f , 0 .

45f , 0 .

67f )) // <-- dense vector . setLimit ( 100 ) . build ()) . setQuery ( nearest ( new float [][] { { 0 .

1f , 0 .

2f }, // <‚îÄ‚îê { 0 .

2f , 0 .

1f }, // < ‚îú‚îÄ multi-vector { 0 .

8f , 0 .

9f } // < ‚îò })) . setUsing ( "colbert" ) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : new List < PrefetchQuery > { new () { Query = new float [] { 0.01f , 0.45f , 0.67f }, // <-- dense vector**** Limit = 100 } }, query : new float [][] { [0.1f, 0.2f] , // <‚îÄ‚îê [0.2f, 0.1f] , // < ‚îú‚îÄ multi-vector [0.8f, 0.9f] // < ‚îò }, usingVector : "colbert" , limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQueryDense ([] float32 { 0.01 , 0.45 , 0.67 }), Limit : qdrant .

PtrOf ( uint64 ( 100 )), }, }, Query : qdrant .

NewQueryMulti ([][] float32 { { 0.1 , 0.2 }, { 0.2 , 0.1 }, { 0.8 , 0.9 }, }), Using : qdrant .

PtrOf ( "colbert" ), }) It is possible to combine all the above techniques in a single query: POST /collections/{collection_name}/points/query { "prefetch": { "prefetch": {
"query": [1, 23, 45, 67], // <------ small byte vector

"using": "mrl_byte" "limit": 1000 }, "query": [0.01, 0.45, 0.67, ...], // <-- full dense vector "using": "full" "limit": 100 }, "query": [           // <‚îÄ‚îê [0.1, 0.2, ...], // < ‚îÇ [0.2, 0.1, ...], // < ‚îú‚îÄ multi-vector [0.8, 0.9, ...]  // < ‚îÇ ],                   // <‚îÄ‚îò "using": "colbert", "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( prefetch = models .

Prefetch ( query = [ 1 , 23 , 45 , 67 ],
# <------ small byte vector

using = "mrl_byte" , limit = 1000 , ), query = [ 0.01 , 0.45 , 0.67 ], # <-- full dense vector using = "full" , limit = 100 , ), query = [ [ 0.17 , 0.23 , 0.52 ], # <‚îÄ‚îê [ 0.22 , 0.11 , 0.63 ], # < ‚îú‚îÄ multi-vector [ 0.86 , 0.93 , 0.12 ], # < ‚îò ], using = "colbert" , limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : { prefetch : { query : [ 1 , 23 , 45 , 67 ],
// <------------- small byte vector

using : 'mrl_byte' , limit : 1000 , }, query : [ 0.01 , 0.45 , 0.67 ], // <-- full dense vector using : 'full' , limit : 100 , }, query : [ [ 0.1 , 0.2 ], // <‚îÄ‚îê [ 0.2 , 0.1 ], // < ‚îú‚îÄ multi-vector [ 0.8 , 0.9 ], // < ‚îò ], using : 'colbert' , limit : 10 , }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PrefetchQueryBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ( vec!

[ 1.0 , 23.0 , 45.0 , 67.0 ])) . using ( "mlr_byte" ) . limit ( 1000 u64 ) ) . query ( Query :: new_nearest ( vec!

[ 0.01 , 0.45 , 0.67 ])) . using ( "full" ) . limit ( 100 u64 ) ) . query ( Query :: new_nearest ( vec!

[ vec!

[ 0.1 , 0.2 ], vec!

[ 0.2 , 0.1 ], vec!

[ 0.8 , 0.9 ], ])) . using ( "colbert" ) . limit ( 10 u64 ) ). await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 1 , 23 , 45 , 67 ))
// <------------- small byte vector

. setUsing ( "mrl_byte" ) . setLimit ( 1000 ) . build ()) . setQuery ( nearest ( 0 .

01f , 0 .

45f , 0 .

67f )) // <-- dense vector . setUsing ( "full" ) . setLimit ( 100 ) . build ()) . setQuery ( nearest ( new float [][] { { 0 .

1f , 0 .

2f }, // <‚îÄ‚îê { 0 .

2f , 0 .

1f }, // < ‚îú‚îÄ multi-vector { 0 .

8f , 0 .

9f } // < ‚îò })) . setUsing ( "colbert" ) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : new List < PrefetchQuery > { new () { Prefetch = { new List < PrefetchQuery > { new () { Query = new float [] { 1 , 23 , 45 , 67 },
// <------------- small byte vector

Using = "mrl_byte" , Limit = 1000 }, } }, Query = new float [] { 0.01f , 0.45f , 0.67f }, // <-- dense vector Using = "full" , Limit = 100 } }, query : new float [][] { [0.1f, 0.2f] , // <‚îÄ‚îê [0.2f, 0.1f] , // < ‚îú‚îÄ multi-vector [0.8f, 0.9f] // < ‚îò }, usingVector : "colbert" , limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQueryDense ([] float32 { 1 , 23 , 45 , 67 }), Using : qdrant .

PtrOf ( "mrl_byte" ), Limit : qdrant .

PtrOf ( uint64 ( 1000 )), }, }, Query : qdrant .

NewQueryDense ([] float32 { 0.01 , 0.45 , 0.67 }), Limit : qdrant .

PtrOf ( uint64 ( 100 )), Using : qdrant .

PtrOf ( "full" ), }, }, Query : qdrant .

NewQueryMulti ([][] float32 { { 0.1 , 0.2 }, { 0.2 , 0.1 }, { 0.8 , 0.9 }, }), Using : qdrant .

PtrOf ( "colbert" ), }) Maximal Marginal Relevance (MMR) Available as of v1.15.0 A useful algorithm to improve the diversity of the results is Maximal Marginal Relevance (MMR) . It excels when the dataset has many redundant or very similar points for a query.

MMR selects candidates iteratively, starting with the most relevant point (higher similarity to the query). For each next point, it selects the one that hasn‚Äôt been chosen yet which has the best combination of relevance and higher separation to the already selected points.

$$ MMR = \arg \max_{D_i \in R\setminus S}[\lambda sim(D_i, Q) - (1 - \lambda)\max_{D_j \in S}sim(D_i, D_j)] $$ Where $R$ is the candidates set, $S$ is the selected set, $Q$ is the query vector, $sim$ is the similarity function, and $\lambda = 1 - diversity$.

This is implemented in Qdrant as a parameter of a nearest neighbors query. You define the vector to get the nearest candidates, and a diversity parameter which controls the balance between relevance (0.0) and diversity (1.0).

POST /collections/{collection_name}/points/query { "query": { "nearest": [0.01, 0.45, 0.67, ...], // search vector "mmr": { "diversity": 0.5, // 0.0 - relevance; 1.0 - diversity "candidates_limit": 100 // num of candidates to preselect } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = models .

NearestQuery ( nearest = [ 0.01 , 0.45 , 0.67 ], # search vector mmr = models .

Mmr ( diversity = 0.5 , # 0.0 - relevance; 1.0 - diversity candidates_limit = 100 , # num of candidates to preselect ) ), limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { nearest : [ 0.01 , 0.45 , 0.67 ], // search vector mmr : { diversity : 0.5 , // 0.0 - relevance; 1.0 - diversity candidates_limit : 100 // num of candidates to preselect } }, limit : 10 , }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { MmrBuilder , Query , QueryPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest_with_mmr ( vec!

[ 0.01 , 0.45 , 0.67 ], // search vector MmrBuilder :: new () . diversity ( 0.5 ) // 0.0 - relevance; 1.0 - diversity . candidates_limit ( 100 ) // num of candidates to preselect )) . limit ( 10 ) ). await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.VectorInputFactory.vectorInput ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Mmr ; import io.qdrant.client.grpc.Points.QueryPoints ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( vectorInput ( 0 .

01f , 0 .

45f , 0 .

67f ), // <-- search vector Mmr . newBuilder () . setDiversity ( 0 .

5f ) // 0.0 - relevance; 1.0 - diversity . setCandidatesLimit ( 100 ) // num of candidates to preselect . build ())) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : ( new float [] { 0.01f , 0.45f , 0.67f }, new Mmr { Diversity = 0.5f , // 0.0 - relevance; 1.0 - diversity CandidatesLimit = 100 // Number of candidates to preselect } ), limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryMMR ( qdrant .

NewVectorInput ( 0.01 , 0.45 , 0.67 ), & qdrant .

Mmr { Diversity : qdrant .

PtrOf ( float32 ( 0.5 )), // 0.0 - relevance; 1.0 - diversity CandidatesLimit : qdrant .

PtrOf ( uint32 ( 100 )), // num of candidates to preselect }), Limit : qdrant .

PtrOf ( uint64 ( 10 )), }) Caveat: Since MMR ranks one point at a time, the scores produced by MMR in Qdrant refer to the similarity to the query vector. This means that the response will not be ordered by score, but rather by the order of selection of MMR.

Score boosting Available as of v1.14.0 When introducing vector search to specific applications, sometimes business logic needs to be considered for ranking the final list of results.

A quick example is our own documentation search bar .

It has vectors for every part of the documentation site. If one were to perform a search by ‚Äújust‚Äù using the vectors, all kinds of elements would be equally considered good results.

However, when searching for documentation, we can establish a hierarchy of importance: title > content > snippets One way to solve this is to weight the results based on the kind of element.

For example, we can assign a higher weight to titles and content, and keep snippets unboosted.

Pseudocode would be something like: score = score + (is_title * 0.5) + (is_content * 0.25) Query API can rescore points with custom formulas. They can be based on: Dynamic payload values Conditions Scores of prefetches To express the formula, the syntax uses objects to identify each element.

Taking the documentation example, the request would look like this: POST /collections/{collection_name}/points/query { "prefetch": { "query": [0.2, 0.8, ...],  // <-- dense vector "limit": 50 } "query": { "formula": { "sum": [ "$score", { "mult": [ 0.5, { "key": "tag", "match": { "any": ["h1", "h2", "h3", "h4"] } } ] }, { "mult": [ 0.25, { "key": "tag", "match": { "any": ["p", "li"] } } ] } ] } } } from qdrant_client import QdrantClient , models tag_boosted = client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( query = [ 0.1 , 0.45 , 0.67 ], # <-- dense vector limit = 50 ), query = models .

FormulaQuery ( formula = models .

SumExpression ( sum = [ "$score" , models .

MultExpression ( mult = [ 0.5 , models .

FieldCondition ( key = "tag" , match = models .

MatchAny ( any = [ "h1" , "h2" , "h3" , "h4" ]))]), models .

MultExpression ( mult = [ 0.25 , models .

FieldCondition ( key = "tag" , match = models .

MatchAny ( any = [ "p" , "li" ]))]) ] )) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const tag_boosted = await client . query ( "{collection_name}" , { prefetch : { query : [ 0.2 , 0.8 , 0.1 , 0.9 ], limit : 50 }, query : { formula : { sum : [ "$score" , { mult : [ 0.5 , { key : "tag" , match : { any : [ "h1" , "h2" , "h3" , "h4" ] }} ] }, { mult : [ 0.25 , { key : "tag" , match : { any : [ "p" , "li" ] }} ] } ] } } }); use qdrant_client :: qdrant :: { Condition , Expression , FormulaBuilder , PrefetchQueryBuilder , QueryPointsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let _tag_boosted = client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( vec!

[ 0.01 , 0.45 , 0.67 ]) . limit ( 100 u64 ) ) . query ( FormulaBuilder :: new ( Expression :: sum_with ([ Expression :: score (), Expression :: mult_with ([ Expression :: constant ( 0.5 ), Expression :: condition ( Condition :: matches ( "tag" , [ "h1" , "h2" , "h3" , "h4" ])), ]), Expression :: mult_with ([ Expression :: constant ( 0.25 ), Expression :: condition ( Condition :: matches ( "tag" , [ "p" , "li" ])), ]), ]))) . limit ( 10 ) ). await ? ; import static io.qdrant.client.ConditionFactory.matchKeywords ; import static io.qdrant.client.ExpressionFactory.condition ; import static io.qdrant.client.ExpressionFactory.constant ; import static io.qdrant.client.ExpressionFactory.mult ; import static io.qdrant.client.ExpressionFactory.sum ; import static io.qdrant.client.ExpressionFactory.variable ; import static io.qdrant.client.QueryFactory.formula ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Formula ; import io.qdrant.client.grpc.Points.MultExpression ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SumExpression ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 0 .

01f , 0 .

45f , 0 .

67f )) . setLimit ( 100 ) . build ()) . setQuery ( formula ( Formula . newBuilder () . setExpression ( sum ( SumExpression . newBuilder () . addSum ( variable ( "$score" )) . addSum ( mult ( MultExpression . newBuilder () . addMult ( constant ( 0 .

5f )) . addMult ( condition ( matchKeywords ( "tag" , List . of ( "h1" , "h2" , "h3" , "h4" )))) . build ())) . addSum ( mult ( MultExpression . newBuilder () . addMult ( constant ( 0 .

25f )) . addMult ( condition ( matchKeywords ( "tag" , List . of ( "p" , "li" )))) . build ())) . build ())) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : [ new PrefetchQuery { Query = new float[] { 0.01f , 0.45f , 0.67f }, Limit = 100 }, ], query : new Formula { Expression = new SumExpression { Sum = { "$score" , new MultExpression { Mult = { 0.5f , Match ( "tag" , [ "h1" , "h2" , "h3" , "h4" ]) }, }, new MultExpression { Mult = { 0.25f , Match ( "tag" , [ "p" , "li" ]) } }, }, }, }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQuery ( 0.01 , 0.45 , 0.67 ), }, }, Query : qdrant .

NewQueryFormula ( & qdrant .

Formula { Expression : qdrant .

NewExpressionSum ( & qdrant .

SumExpression { Sum : [] * qdrant .

Expression { qdrant .

NewExpressionVariable ( "$score" ), qdrant .

NewExpressionMult ( & qdrant .

MultExpression { Mult : [] * qdrant .

Expression { qdrant .

NewExpressionConstant ( 0.5 ), qdrant .

NewExpressionCondition ( qdrant .

NewMatchKeywords ( "tag" , "h1" , "h2" , "h3" , "h4" )), }, }), qdrant .

NewExpressionMult ( & qdrant .

MultExpression { Mult : [] * qdrant .

Expression { qdrant .

NewExpressionConstant ( 0.25 ), qdrant .

NewExpressionCondition ( qdrant .

NewMatchKeywords ( "tag" , "p" , "li" )), }, }), }, }), }), }) There are multiple expressions available, check the API docs for specific details . constant - A floating point number. e.g.

0.5 .

"$score" - Reference to the score of the point in the prefetch. This is the same as "$score[0]" .

"$score[0]" , "$score[1]" , "$score[2]" , ‚Ä¶ - When using multiple prefetches, you can reference specific prefetch with the index within the array of prefetches. payload key - Any plain string will refer to a payload key. This uses the jsonpath format used in every other place, e.g. key or key.subkey . It will try to extract a number from the given key. condition - A filtering condition. If the condition is met, it becomes 1.0 , otherwise 0.0 . mult - Multiply an array of expressions. sum - Sum an array of expressions. div - Divide an expression by another expression. abs - Absolute value of an expression. pow - Raise an expression to the power of another expression. sqrt - Square root of an expression. log10 - Base 10 logarithm of an expression. ln - Natural logarithm of an expression. exp - Exponential function of an expression ( e^x ). geo distance - Haversine distance between two geographic points. Values need to be { "lat": 0.0, "lon": 0.0 } objects. decay - Apply a decay function to an expression, which clamps the output between 0 and 1. Available decay functions are linear , exponential , and gaussian .

See more . datetime - Parse a datetime string (see formats here ), and use it as a POSIX timestamp, in seconds. datetime key - Specify that a payload key contains a datetime string to be parsed into POSIX seconds.

It is possible to define a default for when the variable (either from payload or prefetch score) is not found. This is given in the form of a mapping from variable to value.

If there is no variable, and no defined default, a default value of 0.0 is used.

Boost points closer to user Another example. Combine the score with how close the result is to a user.

Considering each point has an associated geo location, we can calculate the distance between the point and the request‚Äôs location.

Assuming we have cosine scores in the prefetch, we can use a helper function to clamp the geographical distance between 0 and 1, by using a decay function. Once clamped, we can sum the score and the distance together. Pseudocode: score = score + gauss_decay(distance) In this case we use a gauss_decay function.

POST /collections/{collection_name}/points/query { "prefetch": { "query": [0.2, 0.8, ...], "limit": 50 }, "query": { "formula": { "sum": [ "$score", { "gauss_decay": { "x": { "geo_distance": { "origin": { "lat": 52.504043, "lon": 13.393236 } "to": "geo.location" } }, "scale": 5000 // 5km } } ] }, "defaults": { "geo.location": {"lat": 48.137154, "lon": 11.576124} } } } from qdrant_client import QdrantClient , models geo_boosted = client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( query = [ 0.1 , 0.45 , 0.67 ], # <-- dense vector limit = 50 ), query = models .

FormulaQuery ( formula = models .

SumExpression ( sum = [ "$score" , models .

GaussDecayExpression ( gauss_decay = models .

DecayParamsExpression ( x = models .

GeoDistance ( geo_distance = models .

GeoDistanceParams ( origin = models .

GeoPoint ( lat = 52.504043 , lon = 13.393236 ), # Berlin to = "geo.location" ) ), scale = 5000 # 5km ) ) ]), defaults = { "geo.location" : models .

GeoPoint ( lat = 48.137154 , lon = 11.576124 )} # Munich ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const distance_boosted = await client . query ( "{collection_name}" , { prefetch : { query : [ 0.1 , 0.45 , 0.67 ], limit : 50 }, query : { formula : { sum : [ "$score" , { gauss_decay : { x : { geo_distance : { origin : { lat : 52.504043 , lon : 13.393236 }, // Berlin to : "geo.location" } }, scale : 5000 // 5km } } ] }, defaults : { "geo.location" : { lat : 48.137154 , lon : 11.576124 } } // Munich } }); use qdrant_client :: qdrant :: { GeoPoint , DecayParamsExpressionBuilder , Expression , FormulaBuilder , PrefetchQueryBuilder , QueryPointsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let _geo_boosted = client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( vec!

[ 0.01 , 0.45 , 0.67 ]) . limit ( 100 u64 ), ) . query ( FormulaBuilder :: new ( Expression :: sum_with ([ Expression :: score (), Expression :: exp_decay ( DecayParamsExpressionBuilder :: new ( Expression :: geo_distance_with ( // Berlin GeoPoint { lat : 52.504043 , lon : 13.393236 }, "geo.location" , )) . scale ( 5_000.0 ), ), ])) // Munich . add_default ( "geo.location" , GeoPoint { lat : 48.137154 , lon : 11.576124 }), ) . limit ( 10 ), ) . await ? ; import static io.qdrant.client.ExpressionFactory.expDecay ; import static io.qdrant.client.ExpressionFactory.geoDistance ; import static io.qdrant.client.ExpressionFactory.sum ; import static io.qdrant.client.ExpressionFactory.variable ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.QueryFactory.formula ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.GeoPoint ; import io.qdrant.client.grpc.Points.DecayParamsExpression ; import io.qdrant.client.grpc.Points.Formula ; import io.qdrant.client.grpc.Points.GeoDistance ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SumExpression ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 0 .

01f , 0 .

45f , 0 .

67f )) . setLimit ( 100 ) . build ()) . setQuery ( formula ( Formula . newBuilder () . setExpression ( sum ( SumExpression . newBuilder () . addSum ( variable ( "$score" )) . addSum ( expDecay ( DecayParamsExpression . newBuilder () . setX ( geoDistance ( GeoDistance . newBuilder () . setOrigin ( GeoPoint . newBuilder () . setLat ( 52 .

504043 ) . setLon ( 13 .

393236 ) . build ()) . setTo ( "geo.location" ) . build ())) . setScale ( 5000 ) . build ())) . build ())) . putDefaults ( "geo.location" , value ( Map . of ( "lat" , value ( 48 .

137154 ), "lon" , value ( 11 .

576124 )))) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Expression ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : [ new PrefetchQuery { Query = new float[] { 0.01f , 0.45f , 0.67f }, Limit = 100 }, ], query : new Formula { Expression = new SumExpression { Sum = { "$score" , FromExpDecay ( new () { X = new GeoDistance { Origin = new GeoPoint { Lat = 52.504043 , Lon = 13.393236 }, To = "geo.location" , }, Scale = 5000 , } ), }, }, Defaults = { ["geo.location"] = new Dictionary < string , Value > { ["lat"] = 48.137154 , ["lon"] = 11.576124 , }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQuery ( 0.2 , 0.8 ), }, }, Query : qdrant .

NewQueryFormula ( & qdrant .

Formula { Expression : qdrant .

NewExpressionSum ( & qdrant .

SumExpression { Sum : [] * qdrant .

Expression { qdrant .

NewExpressionVariable ( "$score" ), qdrant .

NewExpressionExpDecay ( & qdrant .

DecayParamsExpression { X : qdrant .

NewExpressionGeoDistance ( & qdrant .

GeoDistance { Origin : & qdrant .

GeoPoint { Lat : 52.504043 , Lon : 13.393236 , }, To : "geo.location" , }), }), }, }), Defaults : qdrant .

NewValueMap ( map [ string ] any { "geo.location" : map [ string ] any { "lat" : 48.137154 , "lon" : 11.576124 , }, }), }), }) Time-based score boosting Or combine the score with the information on how ‚Äúfresh‚Äù the result is. It‚Äôs applicable to (news) articles and in general many other different types of searches (think of the ‚Äúnewest‚Äù filter you use in applications).

To implement time-based score boosting, you‚Äôll need each point to have a datetime field in its payload, e.g., when the item was uploaded or last updated. Then we can calculate the time difference in seconds between this payload value and the current time, our target .

With an exponential decay function, perfect for use cases with time, as freshness is a very quickly lost quality, we can convert this time difference into a value between 0 and 1, then add it to the original score to prioritise fresh results. score = score + exp_decay(current_time - point_time) That‚Äôs how it will look for an application where, after 1 day, results start being only half-relevant (so get a score of 0.5): POST /collections/{collection_name}/points/query { "prefetch": { "query": [0.2, 0.8, ...],  // <-- dense vector "limit": 50 }, "query": { "formula": { "sum": [ "$score", // the final score = score + exp_decay(target_time - x_time) { "exp_decay": { "x": { "datetime_key": "update_time" // payload key }, "target": { "datetime": "YYYY-MM-DDT00:00:00Z" // current datetime }, "scale": 86400, // 1 day in seconds "midpoint": 0.5 // if item's "update_time" is more than 1 day apart from current datetime, relevance score is less than 0.5 } } ] } } } from qdrant_client import QdrantClient , models time_boosted = client . query_points ( collection_name = " {collection_name} " , prefetch = models .

Prefetch ( query = [ 0.1 , 0.45 , 0.67 ], # <-- dense vector limit = 50 ), query = models .

FormulaQuery ( formula = models .

SumExpression ( sum = [ "$score" , # the final score = score + exp_decay(target_time - x_time) models .

ExpDecayExpression ( exp_decay = models .

DecayParamsExpression ( x = models .

DatetimeKeyExpression ( datetime_key = "upload_time" # payload key ), target = models .

DatetimeExpression ( datetime = "YYYY-MM-DDT00:00:00Z" # current datetime ), scale = 86400 , # 1 day in seconds midpoint = 0.5 # if item's "update_time" is more than 1 day apart from current datetime, relevance score is less than 0.5 ) ) ] ) ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); const time_boosted = await client . query ( 'collectionName' , { prefetch : { query : [ 0.1 , 0.45 , 0.67 ], // <-- dense vector limit : 50 }, query : { formula : { sum : [ //  the final score = score + exp_decay(target_time - x_time) "$score" , { exp_decay : { x : { datetime_key : "update_time" // payload key }, target : { datetime : "YYYY-MM-DDT00:00:00Z" // current datetime }, midpoint : 0.5 , scale : 86400 // 1 day in seconds } } ] } } }); use qdrant_client :: qdrant :: { DecayParamsExpressionBuilder , Expression , FormulaBuilder , PrefetchQueryBuilder , QueryPointsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let _geo_boosted = client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( vec!

[ 0.1 , 0.45 , 0.67 ]) // <-- dense vector . limit ( 50 u64 ), ) . query ( FormulaBuilder :: new ( Expression :: sum_with ([ //  the final score = score + exp_decay(target_time - x_time) Expression :: score (), Expression :: exp_decay ( DecayParamsExpressionBuilder :: new ( Expression :: datetime_key ( "update_time" )) // payload key . target ( Expression :: datetime ( "YYYY-MM-DDT00:00:00Z" )) . midpoint ( 0.5 ) . scale ( 86400.0 ), // 1 day in seconds ), ])) ) ) . await ? ; import static io.qdrant.client.ExpressionFactory.datetime ; import static io.qdrant.client.ExpressionFactory.datetimeKey ; import static io.qdrant.client.ExpressionFactory.expDecay ; import static io.qdrant.client.ExpressionFactory.sum ; import static io.qdrant.client.ExpressionFactory.variable ; import static io.qdrant.client.QueryFactory.formula ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.DecayParamsExpression ; import io.qdrant.client.grpc.Points.Formula ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.ScoredPoint ; import io.qdrant.client.grpc.Points.SumExpression ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ());

List < ScoredPoint > time_boosted = client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( 0 .

1f , 0 .

45f , 0 .

67f )) // <-- dense vector . setLimit ( 50 ) . build ()) . setQuery ( formula ( Formula . newBuilder () . setExpression ( sum ( //  the final score = score + exp_decay(target_time - x_time) SumExpression . newBuilder () . addSum ( variable ( "$score" )) . addSum ( expDecay ( DecayParamsExpression . newBuilder () . setX ( datetimeKey ( "update_time" )) // payload key . setTarget ( datetime ( "YYYY-MM-DDT00:00:00Z" )) // current datetime . setMidpoint ( 0 .

5f ) . setScale ( 86400 ) // 1 day in seconds . build ())) . build ())) . build ())) . build () ). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : [ new PrefetchQuery { Query = new float[] { 0.1f , 0.45f , 0.67f }, // <-- dense vector Limit = 50 }, ], query : new Formula { Expression = new SumExpression { Sum = //  the final score = score + exp_decay(target_time - x_time) { "$score" , Expression .

FromExpDecay ( new () { X = Expression .

FromDateTimeKey ( "update_time" ), // payload key Target = Expression .

FromDateTime ( "YYYY-MM-DDT00:00:00Z" ), // current datetime Midpoint = 0.5f , Scale = 86400 // 1 day in seconds } ) } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQuery ( 0.1 , 0.45 , 0.67 ), // <-- dense vector Limit : qdrant .

PtrOf ( uint64 ( 50 )), }, }, Query : qdrant .

NewQueryFormula ( & qdrant .

Formula { Expression : qdrant .

NewExpressionSum ( & qdrant .

SumExpression { Sum : [] * qdrant .

Expression { //  the final score = score + exp_decay(target_time - x_time) qdrant .

NewExpressionVariable ( "$score" ), qdrant .

NewExpressionExpDecay ( & qdrant .

DecayParamsExpression { X : qdrant .

NewExpressionDatetimeKey ( "update_time" ), // payload key Target : qdrant .

NewExpressionDatetime ( "YYYY-MM-DDT00:00:00Z" ), // current datetime Scale : qdrant .

PtrOf ( float32 ( 86400 )), // 1 day in seconds Midpoint : qdrant .

PtrOf ( float32 ( 0.5 )), }), }, }), }), }) For all decay functions, there are these parameters available Parameter Default Description x N/A The value to decay target 0.0 The value at which the decay will be at its peak. For distances it is usually set at 0.0, but can be set to any value. scale 1.0 The value at which the decay function will be equal to midpoint . This is in terms of x units, for example, if x is in meters, scale of 5000 means 5km. Must be a non-zero positive number midpoint 0.5 Output is midpoint when x equals target ¬± scale . Must be in the range (0.0, 1.0), exclusive The formulas for each decay function are as follows: Decay Function Color Range Formula lin_decay green [0, 1] $\text{lin_decay}(x) = \max\left(0,\ -\frac{(1-m_{idpoint})}{s_{cale}}\cdot {abs}(x-t_{arget})+1\right)$ exp_decay red (0, 1] $\text{exp_decay}(x) = \exp\left(\frac{\ln(m_{idpoint})}{s_{cale}}\cdot {abs}(x-t_{arget})\right)$ gauss_decay purple (0, 1] $\text{gauss_decay}(x) = \exp\left(\frac{\ln(m_{idpoint})}{s_{cale}^{2}}\cdot (x-t_{arget})^{2}\right)$ Grouping Available as of v1.11.0 It is possible to group results by a certain field. This is useful when you have multiple points for the same item, and you want to avoid redundancy of the same item in the results.

REST API ( Schema ): POST /collections/{collection_name}/points/query/groups { // Same as in the regular query API "query": [1.1], // Grouping parameters "group_by": "document_id",  // Path of the field to group by "limit": 4,                 // Max amount of groups "group_size": 2            // Max amount of points per group } client . query_points_groups ( collection_name = " {collection_name} " , # Same as in the regular query_points() API query = [ 1.1 ], # Grouping parameters group_by = "document_id" , # Path of the field to group by limit = 4 , # Max amount of groups group_size = 2 , # Max amount of points per group ) client . queryGroups ( "{collection_name}" , { query : [ 1.1 ], group_by : "document_id" , limit : 4 , group_size : 2 , }); use qdrant_client :: qdrant :: QueryPointGroupsBuilder ; client . query_groups ( QueryPointGroupsBuilder :: new ( "{collection_name}" , "document_id" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . group_size ( 2 u64 ) . with_payload ( true ) . with_vectors ( true ) . limit ( 4 u64 ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.grpc.Points.QueryPointGroups ; import io.qdrant.client.grpc.Points.SearchPointGroups ; import java.util.List ; client . queryGroupsAsync ( QueryPointGroups . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setGroupBy ( "document_id" ) . setLimit ( 4 ) . setGroupSize ( 2 ) . build ()) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryGroupsAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, groupBy : "document_id" , limit : 4 , groupSize : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

QueryGroups ( context .

Background (), & qdrant .

QueryPointGroups { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), GroupBy : "document_id" , GroupSize : qdrant .

PtrOf ( uint64 ( 2 )), }) For more information on the grouping capabilities refer to the reference documentation for search with grouping and lookup .

================================================================================
PAGE 11/39
================================================================================
Title: Filtering
URL: https://qdrant.tech/documentation/concepts/filtering/
--------------------------------------------------------------------------------

Filtering With Qdrant, you can set conditions when searching or retrieving points.

For example, you can impose conditions on both the payload and the id of the point.

Setting additional conditions is important when it is impossible to express all the features of the object in the embedding.

Examples include a variety of business requirements: stock availability, user location, or desired price range.

Related Content A Complete Guide to Filtering in Vector Search Developer advice on proper usage and advanced practices.

Filtering clauses Qdrant allows you to combine conditions in clauses.

Clauses are different logical operations, such as OR , AND , and NOT .

Clauses can be recursively nested into each other so that you can reproduce an arbitrary boolean expression.

Let‚Äôs take a look at the clauses implemented in Qdrant.

Suppose we have a set of points with the following payload: [ { "id" : 1 , "city" : "London" , "color" : "green" }, { "id" : 2 , "city" : "London" , "color" : "red" }, { "id" : 3 , "city" : "London" , "color" : "blue" }, { "id" : 4 , "city" : "Berlin" , "color" : "red" }, { "id" : 5 , "city" : "Moscow" , "color" : "green" }, { "id" : 6 , "city" : "Moscow" , "color" : "blue" } ] Must Example: POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "key": "city", "match": { "value": "London" } }, { "key": "color", "match": { "value": "red" } } ] } ...

} from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" ), ), models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ), ] ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . scroll ( "{collection_name}" , { filter : { must : [ { key : "city" , match : { value : "London" }, }, { key : "color" , match : { value : "red" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must ([ Condition :: matches ( "city" , "london" . to_string ()), Condition :: matches ( "color" , "red" . to_string ()), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addAllMust ( List . of ( matchKeyword ( "city" , "London" ), matchKeyword ( "color" , "red" ))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 );

// & operator combines two conditions in an AND conjunction(must) await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "city" , "London" ) & MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), qdrant .

NewMatch ( "color" , "red" ), }, }, }) Filtered points would be: [{ "id" : 2 , "city" : "London" , "color" : "red" }] When using must , the clause becomes true only if every condition listed inside must is satisfied.

In this sense, must is equivalent to the operator AND .

Should Example: POST /collections/{collection_name}/points/scroll { "filter": { "should": [ { "key": "city", "match": { "value": "London" } }, { "key": "color", "match": { "value": "red" } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( should = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" ), ), models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ), ] ), ) client . scroll ( "{collection_name}" , { filter : { should : [ { key : "city" , match : { value : "London" }, }, { key : "color" , match : { value : "red" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: should ([ Condition :: matches ( "city" , "london" . to_string ()), Condition :: matches ( "color" , "red" . to_string ()), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addAllShould ( List . of ( matchKeyword ( "city" , "London" ), matchKeyword ( "color" , "red" ))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 );

// | operator combines two conditions in an OR disjunction(should) await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "city" , "London" ) | MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Should : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), qdrant .

NewMatch ( "color" , "red" ), }, }, }) Filtered points would be: [ { "id" : 1 , "city" : "London" , "color" : "green" }, { "id" : 2 , "city" : "London" , "color" : "red" }, { "id" : 3 , "city" : "London" , "color" : "blue" }, { "id" : 4 , "city" : "Berlin" , "color" : "red" } ] When using should , the clause becomes true if at least one condition listed inside should is satisfied.

In this sense, should is equivalent to the operator OR .

Must Not Example: POST /collections/{collection_name}/points/scroll { "filter": { "must_not": [ { "key": "city", "match": { "value": "London" } }, { "key": "color", "match": { "value": "red" } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must_not = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" )), models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" )), ] ), ) client . scroll ( "{collection_name}" , { filter : { must_not : [ { key : "city" , match : { value : "London" }, }, { key : "color" , match : { value : "red" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must_not ([ Condition :: matches ( "city" , "london" . to_string ()), Condition :: matches ( "color" , "red" . to_string ()), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addAllMustNot ( List . of ( matchKeyword ( "city" , "London" ), matchKeyword ( "color" , "red" ))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 );

// The ! operator negates the condition(must not) await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : !( MatchKeyword ( "city" , "London" ) & MatchKeyword ( "color" , "red" )) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { MustNot : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), qdrant .

NewMatch ( "color" , "red" ), }, }, }) Filtered points would be: [ { "id" : 5 , "city" : "Moscow" , "color" : "green" }, { "id" : 6 , "city" : "Moscow" , "color" : "blue" } ] When using must_not , the clause becomes true if none of the conditions listed inside must_not is satisfied.

In this sense, must_not is equivalent to the expression (NOT A) AND (NOT B) AND (NOT C) .

Clauses combination It is also possible to use several clauses simultaneously: POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ], "must_not": [ { "key": "color", "match": { "value": "red" } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" )), ], must_not = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" )), ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { key : "city" , match : { value : "London" }, }, ], must_not : [ { key : "color" , match : { value : "red" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter { must : vec !

[ Condition :: matches ( "city" , "London" . to_string ())], must_not : vec !

[ Condition :: matches ( "color" , "red" . to_string ())], ..

Default :: default () }), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMust ( matchKeyword ( "city" , "London" )) . addMustNot ( matchKeyword ( "color" , "red" )) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "city" , "London" ) & !

MatchKeyword ( "color" , "red" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, MustNot : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, }) Filtered points would be: [ { "id" : 1 , "city" : "London" , "color" : "green" }, { "id" : 3 , "city" : "London" , "color" : "blue" } ] In this case, the conditions are combined by AND .

Also, the conditions could be recursively nested. Example: POST /collections/{collection_name}/points/scroll { "filter": { "must_not": [ { "must": [ { "key": "city", "match": { "value": "London" } }, { "key": "color", "match": { "value": "red" } } ] } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must_not = [ models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" ) ), models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ) ), ], ), ], ), ) client . scroll ( "{collection_name}" , { filter : { must_not : [ { must : [ { key : "city" , match : { value : "London" }, }, { key : "color" , match : { value : "red" }, }, ], }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must_not ([ Filter :: must ( [ Condition :: matches ( "city" , "London" . to_string ()), Condition :: matches ( "color" , "red" . to_string ()), ], ) . into ()])), ) . await ? ; import static io.qdrant.client.ConditionFactory.filter ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMustNot ( filter ( Filter . newBuilder () . addAllMust ( List . of ( matchKeyword ( "city" , "London" ), matchKeyword ( "color" , "red" ))) . build ())) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : new Filter { MustNot = { MatchKeyword ( "city" , "London" ) & MatchKeyword ( "color" , "red" ) } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { MustNot : [] * qdrant .

Condition { qdrant .

NewFilterAsCondition ( & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), qdrant .

NewMatch ( "color" , "red" ), }, }), }, }, }) Filtered points would be: [ { "id" : 1 , "city" : "London" , "color" : "green" }, { "id" : 3 , "city" : "London" , "color" : "blue" }, { "id" : 4 , "city" : "Berlin" , "color" : "red" }, { "id" : 5 , "city" : "Moscow" , "color" : "green" }, { "id" : 6 , "city" : "Moscow" , "color" : "blue" } ] Filtering conditions Different types of values in payload correspond to different kinds of queries that we can apply to them.

Let‚Äôs look at the existing condition variants and what types of data they apply to.

Match { "key" : "color" , "match" : { "value" : "red" } } models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ) { key : 'color' , match : { value : 'red' } } Condition :: matches ( "color" , "red" . to_string ()) import static io.qdrant.client.ConditionFactory.matchKeyword ; matchKeyword ( "color" , "red" ); using static Qdrant .

Client .

Grpc .

Conditions ;

MatchKeyword ( "color" , "red" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatch ( "color" , "red" ) For the other types, the match condition will look exactly the same, except for the type used: { "key" : "count" , "match" : { "value" : 0 } } models .

FieldCondition ( key = "count" , match = models .

MatchValue ( value = 0 ), ) { key : 'count' , match : { value : 0 } } Condition :: matches ( "count" , 0 ) import static io.qdrant.client.ConditionFactory.match ; match ( "count" , 0 ); using static Qdrant .

Client .

Grpc .

Conditions ;

Match ( "count" , 0 ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchInt ( "count" , 0 ) The simplest kind of condition is one that checks if the stored value equals the given one.

If several values are stored, at least one of them should match the condition.

You can apply it to keyword , integer and bool payloads.

Match Any Available as of v1.1.0 In case you want to check if the stored value is one of multiple values, you can use the Match Any condition.

Match Any works as a logical OR for the given values. It can also be described as a IN operator.

You can apply it to keyword and integer payloads.

Example: { "key" : "color" , "match" : { "any" : [ "black" , "yellow" ] } } models .

FieldCondition ( key = "color" , match = models .

MatchAny ( any = [ "black" , "yellow" ]), ) { key : 'color' , match : { any : [ 'black' , 'yellow' ]} } Condition :: matches ( "color" , vec!

[ "black" . to_string (), "yellow" . to_string ()]) import static io.qdrant.client.ConditionFactory.matchKeywords ; import java.util.List ; matchKeywords ( "color" , List . of ( "black" , "yellow" )); using static Qdrant .

Client .

Grpc .

Conditions ;

Match ( "color" , [ "black" , "yellow" ]); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchKeywords ( "color" , "black" , "yellow" ) In this example, the condition will be satisfied if the stored value is either black or yellow .

If the stored value is an array, it should have at least one value matching any of the given values. E.g. if the stored value is ["black", "green"] , the condition will be satisfied, because "black" is in ["black", "yellow"] .

Match Except Available as of v1.2.0 In case you want to check if the stored value is not one of multiple values, you can use the Match Except condition.

Match Except works as a logical NOR for the given values.

It can also be described as a NOT IN operator.

You can apply it to keyword and integer payloads.

Example: { "key" : "color" , "match" : { "except" : [ "black" , "yellow" ] } } models .

FieldCondition ( key = "color" , match = models .

MatchExcept ( ** { "except" : [ "black" , "yellow" ]}), ) { key : 'color' , match : { except : [ 'black' , 'yellow' ]} } use qdrant_client :: qdrant :: r#match :: MatchValue ;

Condition :: matches ( "color" , !

MatchValue :: from ( vec!

[ "black" . to_string (), "yellow" . to_string ()]), ) import static io.qdrant.client.ConditionFactory.matchExceptKeywords ; import java.util.List ; matchExceptKeywords ( "color" , List . of ( "black" , "yellow" )); using static Qdrant .

Client .

Grpc .

Conditions ;

Match ( "color" , [ "black" , "yellow" ]); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchExcept ( "color" , "black" , "yellow" ) In this example, the condition will be satisfied if the stored value is neither black nor yellow .

If the stored value is an array, it should have at least one value not matching any of the given values. E.g. if the stored value is ["black", "green"] , the condition will be satisfied, because "green" does not match "black" nor "yellow" .

Nested key Available as of v1.1.0 Payloads being arbitrary JSON object, it is likely that you will need to filter on a nested field.

For convenience, we use a syntax similar to what can be found in the Jq project.

Suppose we have a set of points with the following payload: [ { "id" : 1 , "country" : { "name" : "Germany" , "cities" : [ { "name" : "Berlin" , "population" : 3.7 , "sightseeing" : [ "Brandenburg Gate" , "Reichstag" ] }, { "name" : "Munich" , "population" : 1.5 , "sightseeing" : [ "Marienplatz" , "Olympiapark" ] } ] } }, { "id" : 2 , "country" : { "name" : "Japan" , "cities" : [ { "name" : "Tokyo" , "population" : 9.3 , "sightseeing" : [ "Tokyo Tower" , "Tokyo Skytree" ] }, { "name" : "Osaka" , "population" : 2.7 , "sightseeing" : [ "Osaka Castle" , "Universal Studios Japan" ] } ] } } ] You can search on a nested field using a dot notation.

POST /collections/{collection_name}/points/scroll { "filter": { "should": [ { "key": "country.name", "match": { "value": "Germany" } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( should = [ models .

FieldCondition ( key = "country.name" , match = models .

MatchValue ( value = "Germany" ) ), ], ), ) client . scroll ( "{collection_name}" , { filter : { should : [ { key : "country.name" , match : { value : "Germany" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: should ([ Condition :: matches ( "country.name" , "Germany" . to_string ()), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addShould ( matchKeyword ( "country.name" , "Germany" )) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "country.name" , "Germany" )); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Should : [] * qdrant .

Condition { qdrant .

NewMatch ( "country.name" , "Germany" ), }, }, }) You can also search through arrays by projecting inner values using the [] syntax.

POST /collections/{collection_name}/points/scroll { "filter": { "should": [ { "key": "country.cities[].population", "range": { "gte": 9.0, } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( should = [ models .

FieldCondition ( key = "country.cities[].population" , range = models .

Range ( gt = None , gte = 9.0 , lt = None , lte = None , ), ), ], ), ) client . scroll ( "{collection_name}" , { filter : { should : [ { key : "country.cities[].population" , range : { gt : null , gte : 9.0 , lt : null , lte : null , }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , Range , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: should ([ Condition :: range ( "country.cities[].population" , Range { gte : Some ( 9.0 ), ..

Default :: default () }, ), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.range ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Common.Range ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addShould ( range ( "country.cities[].population" , Range . newBuilder (). setGte ( 9 .

0 ). build ())) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : Range ( "country.cities[].population" , new Qdrant .

Client .

Grpc .

Range { Gte = 9.0 }) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Should : [] * qdrant .

Condition { qdrant .

NewRange ( "country.cities[].population" , & qdrant .

Range { Gte : qdrant .

PtrOf ( 9.0 ), }), }, }, }) This query would only output the point with id 2 as only Japan has a city with population greater than 9.0.

And the leaf nested field can also be an array.

POST /collections/{collection_name}/points/scroll { "filter": { "should": [ { "key": "country.cities[].sightseeing", "match": { "value": "Osaka Castle" } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( should = [ models .

FieldCondition ( key = "country.cities[].sightseeing" , match = models .

MatchValue ( value = "Osaka Castle" ), ), ], ), ) client . scroll ( "{collection_name}" , { filter : { should : [ { key : "country.cities[].sightseeing" , match : { value : "Osaka Castle" }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: should ([ Condition :: matches ( "country.cities[].sightseeing" , "Osaka Castle" . to_string ()), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addShould ( matchKeyword ( "country.cities[].sightseeing" , "Germany" )) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "country.cities[].sightseeing" , "Germany" ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Should : [] * qdrant .

Condition { qdrant .

NewMatch ( "country.cities[].sightseeing" , "Germany" ), }, }, }) This query would only output the point with id 2 as only Japan has a city with the ‚ÄúOsaka castke‚Äù as part of the sightseeing.

Nested object filter Available as of v1.2.0 By default, the conditions are taking into account the entire payload of a point.

For instance, given two points with the following payload: [ { "id" : 1 , "dinosaur" : "t-rex" , "diet" : [ { "food" : "leaves" , "likes" : false }, { "food" : "meat" , "likes" : true } ] }, { "id" : 2 , "dinosaur" : "diplodocus" , "diet" : [ { "food" : "leaves" , "likes" : true }, { "food" : "meat" , "likes" : false } ] } ] The following query would match both points: POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "key": "diet[].food", "match": { "value": "meat" } }, { "key": "diet[].likes", "match": { "value": true } } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "diet[].food" , match = models .

MatchValue ( value = "meat" ) ), models .

FieldCondition ( key = "diet[].likes" , match = models .

MatchValue ( value = True ) ), ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { key : "diet[].food" , match : { value : "meat" }, }, { key : "diet[].likes" , match : { value : true }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must ([ Condition :: matches ( "diet[].food" , "meat" . to_string ()), Condition :: matches ( "diet[].likes" , true ), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.match ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addAllMust ( List . of ( matchKeyword ( "diet[].food" , "meat" ), match ( "diet[].likes" , true ))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "diet[].food" , "meat" ) & Match ( "diet[].likes" , true ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "diet[].food" , "meat" ), qdrant .

NewMatchBool ( "diet[].likes" , true ), }, }, }) This happens because both points are matching the two conditions: the ‚Äút-rex‚Äù matches food=meat on diet[1].food and likes=true on diet[1].likes the ‚Äúdiplodocus‚Äù matches food=meat on diet[1].food and likes=true on diet[0].likes To retrieve only the points which are matching the conditions on an array element basis, that is the point with id 1 in this example, you would need to use a nested object filter.

Nested object filters allow arrays of objects to be queried independently of each other.

It is achieved by using the nested condition type formed by a payload key to focus on and a filter to apply.

The key should point to an array of objects and can be used with or without the bracket notation (‚Äúdata‚Äù or ‚Äúdata[]‚Äù).

POST /collections/{collection_name}/points/scroll { "filter": { "must": [{ "nested": { "key": "diet", "filter":{ "must": [ { "key": "food", "match": { "value": "meat" } }, { "key": "likes", "match": { "value": true } } ] } } }] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

NestedCondition ( nested = models .

Nested ( key = "diet" , filter = models .

Filter ( must = [ models .

FieldCondition ( key = "food" , match = models .

MatchValue ( value = "meat" ) ), models .

FieldCondition ( key = "likes" , match = models .

MatchValue ( value = True ) ), ] ), ) ) ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { nested : { key : "diet" , filter : { must : [ { key : "food" , match : { value : "meat" }, }, { key : "likes" , match : { value : true }, }, ], }, }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , NestedCondition , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must ([ NestedCondition { key : "diet" . to_string (), filter : Some ( Filter :: must ([ Condition :: matches ( "food" , "meat" . to_string ()), Condition :: matches ( "likes" , true ), ])), } . into ()])), ) . await ? ; import static io.qdrant.client.ConditionFactory.match ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.ConditionFactory.nested ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMust ( nested ( "diet" , Filter . newBuilder () . addAllMust ( List . of ( matchKeyword ( "food" , "meat" ), match ( "likes" , true ))) . build ())) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : Nested ( "diet" , MatchKeyword ( "food" , "meat" ) & Match ( "likes" , true )) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewNestedFilter ( "diet" , & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "food" , "meat" ), qdrant .

NewMatchBool ( "likes" , true ), }, }), }, }, }) The matching logic is modified to be applied at the level of an array element within the payload.

Nested filters work in the same way as if the nested filter was applied to a single element of the array at a time.

Parent document is considered to match the condition if at least one element of the array matches the nested filter.

Limitations The has_id condition is not supported within the nested object filter. If you need it, place it in an adjacent must clause.

POST /collections/{collection_name}/points/scroll { "filter":{ "must":[ { "nested":{ "key":"diet", "filter":{ "must":[ { "key":"food", "match":{ "value":"meat" } }, { "key":"likes", "match":{ "value":true } } ] } } }, { "has_id":[ 1 ] } ] } } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

NestedCondition ( nested = models .

Nested ( key = "diet" , filter = models .

Filter ( must = [ models .

FieldCondition ( key = "food" , match = models .

MatchValue ( value = "meat" ) ), models .

FieldCondition ( key = "likes" , match = models .

MatchValue ( value = True ) ), ] ), ) ), models .

HasIdCondition ( has_id = [ 1 ]), ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { nested : { key : "diet" , filter : { must : [ { key : "food" , match : { value : "meat" }, }, { key : "likes" , match : { value : true }, }, ], }, }, }, { has_id : [ 1 ], }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , NestedCondition , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ). filter ( Filter :: must ([ NestedCondition { key : "diet" . to_string (), filter : Some ( Filter :: must ([ Condition :: matches ( "food" , "meat" . to_string ()), Condition :: matches ( "likes" , true ), ])), } . into (), Condition :: has_id ([ 1 ]), ])), ) . await ? ; import static io.qdrant.client.ConditionFactory.hasId ; import static io.qdrant.client.ConditionFactory.match ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.ConditionFactory.nested ; import static io.qdrant.client.PointIdFactory.id ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMust ( nested ( "diet" , Filter . newBuilder () . addAllMust ( List . of ( matchKeyword ( "food" , "meat" ), match ( "likes" , true ))) . build ())) . addMust ( hasId ( id ( 1 ))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : Nested ( "diet" , MatchKeyword ( "food" , "meat" ) & Match ( "likes" , true )) & HasId ( 1 ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewNestedFilter ( "diet" , & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "food" , "meat" ), qdrant .

NewMatchBool ( "likes" , true ), }, }), qdrant .

NewHasID ( qdrant .

NewIDNum ( 1 )), }, }, }) Full Text Match Available as of v0.10.0 A special case of the match condition is the text match condition.

It allows you to search for a specific substring, token or phrase within the text field.

Exact texts that will match the condition depend on full-text index configuration.

Configuration is defined during the index creation and describe at full-text index .

If there is no full-text index for the field, the condition will work as exact substring match.

{ "key" : "description" , "match" : { "text" : "good cheap" } } models .

FieldCondition ( key = "description" , match = models .

MatchText ( text = "good cheap" ), ) { key : 'description' , match : { text : 'good cheap' } } use qdrant_client :: qdrant :: Condition ;

Condition :: matches_text ( "description" , "good cheap" ) import static io.qdrant.client.ConditionFactory.matchText ; matchText ( "description" , "good cheap" ); using static Qdrant .

Client .

Grpc .

Conditions ;

MatchText ( "description" , "good cheap" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchText ( "description" , "good cheap" ) If the query has several words, then the condition will be satisfied only if all of them are present in the text.

Full Text Any Available as of v1.16.0 The text_any full-text match condition is similar to the text condition, but with a key difference: while text only matches text fields that contain all the query terms, text_any matches fields that contain any of the query terms. In other words, even if a text field contains just one of the query terms, it is considered a match.

For example, a query for good cheap matches cheap hardware as well as good performance .

{ "key" : "description" , "match" : { "text_any" : "good cheap" } } models .

FieldCondition ( key = "description" , match = models .

MatchTextAny ( text_any = "good cheap" ), ) { key : 'description' , match : { text_any : 'good cheap' } } use qdrant_client :: qdrant :: Condition ;

Condition :: matches_text_any ( "description" , "good cheap" ) import static io.qdrant.client.ConditionFactory.matchTextAny ; matchTextAny ( "description" , "good cheap" ); using static Qdrant .

Client .

Grpc .

Conditions ;

MatchTextAny ( "description" , "good cheap" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchTextAny ( "description" , "good cheap" ) Phrase Match Available as of v1.15.0 A match phrase condition also leverages full-text index , to perform exact phrase comparisons.

It allows you to search for a specific token phrase within the text field.

For example, the text "quick brown fox" will be matched by the query "brown fox" , but not by "fox brown" .

If there is no full-text index for the field, the condition will work as exact substring match.

{ "key" : "description" , "match" : { "phrase" : "brown fox" } } models .

FieldCondition ( key = "description" , match = models .

MatchPhrase ( phrase = "brown fox" ), ) { key : 'description' , match : { phrase : 'brown fox' } } use qdrant_client :: qdrant :: Condition ;

Condition :: matches_phrase ( "description" , "brown fox" ) import static io.qdrant.client.ConditionFactory.matchPhrase ; matchPhrase ( "description" , "brown fox" ); using static Qdrant .

Client .

Grpc .

Conditions ;

MatchPhrase ( "description" , "brown fox" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatchPhrase ( "description" , "brown fox" ) Range { "key" : "price" , "range" : { "gt" : null , "gte" : 100.0 , "lt" : null , "lte" : 450.0 } } models .

FieldCondition ( key = "price" , range = models .

Range ( gt = None , gte = 100.0 , lt = None , lte = 450.0 , ), ) { key : 'price' , range : { gt : null , gte : 100.0 , lt : null , lte : 450.0 } } use qdrant_client :: qdrant :: { Condition , Range };

Condition :: range ( "price" , Range { gt : None , gte : Some ( 100.0 ), lt : None , lte : Some ( 450.0 ), }, ) import static io.qdrant.client.ConditionFactory.range ; import io.qdrant.client.grpc.Common.Range ; range ( "price" , Range . newBuilder (). setGte ( 100 .

0 ). setLte ( 450 ). build ()); using static Qdrant .

Client .

Grpc .

Conditions ;

Range ( "price" , new Qdrant .

Client .

Grpc .

Range { Gte = 100.0 , Lte = 450 }); import "github.com/qdrant/go-client/qdrant" qdrant .

NewRange ( "price" , & qdrant .

Range { Gte : qdrant .

PtrOf ( 100.0 ), Lte : qdrant .

PtrOf ( 450.0 ), }) The range condition sets the range of possible values for stored payload values.

If several values are stored, at least one of them should match the condition.

Comparisons that can be used: gt - greater than gte - greater than or equal lt - less than lte - less than or equal Can be applied to float and integer payloads.

Datetime Range The datetime range is a unique range condition, used for datetime payloads, which supports RFC 3339 formats.

You do not need to convert dates to UNIX timestaps. During comparison, timestamps are parsed and converted to UTC.

Available as of v1.8.0 { "key" : "date" , "range" : { "gt" : "2023-02-08T10:49:00Z" , "gte" : null , "lt" : null , "lte" : "2024-01-31 10:14:31Z" } } models .

FieldCondition ( key = "date" , range = models .

DatetimeRange ( gt = "2023-02-08T10:49:00Z" , gte = None , lt = None , lte = "2024-01-31T10:14:31Z" , ), ) { key : 'date' , range : { gt : '2023-02-08T10:49:00Z' , gte : null , lt : null , lte : '2024-01-31T10:14:31Z' } } use qdrant_client :: qdrant :: { Condition , DatetimeRange , Timestamp };

Condition :: datetime_range ( "date" , DatetimeRange { gt : Some ( Timestamp :: date_time ( 2023 , 2 , 8 , 10 , 49 , 0 ). unwrap ()), gte : None , lt : None , lte : Some ( Timestamp :: date_time ( 2024 , 1 , 31 , 10 , 14 , 31 ). unwrap ()), }, ) import static io.qdrant.client.ConditionFactory.datetimeRange ; import com.google.protobuf.Timestamp ; import io.qdrant.client.grpc.Common.DatetimeRange ; import java.time.Instant ; long gt = Instant . parse ( "2023-02-08T10:49:00Z" ). getEpochSecond (); long lte = Instant . parse ( "2024-01-31T10:14:31Z" ). getEpochSecond (); datetimeRange ( "date" , DatetimeRange . newBuilder () . setGt ( Timestamp . newBuilder (). setSeconds ( gt )) . setLte ( Timestamp . newBuilder (). setSeconds ( lte )) . build ()); using Qdrant.Client.Grpc ;

Conditions .

DatetimeRange ( field : "date" , gt : new DateTime ( 2023 , 2 , 8 , 10 , 49 , 0 , DateTimeKind .

Utc ), lte : new DateTime ( 2024 , 1 , 31 , 10 , 14 , 31 , DateTimeKind .

Utc ) ); import ( "time" "github.com/qdrant/go-client/qdrant" "google.golang.org/protobuf/types/known/timestamppb" ) qdrant .

NewDatetimeRange ( "date" , & qdrant .

DatetimeRange { Gt : timestamppb .

New ( time .

Date ( 2023 , 2 , 8 , 10 , 49 , 0 , 0 , time .

UTC )), Lte : timestamppb .

New ( time .

Date ( 2024 , 1 , 31 , 10 , 14 , 31 , 0 , time .

UTC )), }) UUID Match Available as of v1.11.0 Matching of UUID values works similarly to the regular match condition for strings.

Functionally, it will work with keyword and uuid indexes exactly the same, but uuid index is more memory efficient.

{ "key" : "uuid" , "match" : { "value" : "f47ac10b-58cc-4372-a567-0e02b2c3d479" } } models .

FieldCondition ( key = "uuid" , match = models .

MatchValue ( value = "f47ac10b-58cc-4372-a567-0e02b2c3d479" ), ) { key : 'uuid' , match : { value : 'f47ac10b-58cc-4372-a567-0e02b2c3d479' } } Condition :: matches ( "uuid" , "f47ac10b-58cc-4372-a567-0e02b2c3d479" . to_string ()) import static io.qdrant.client.ConditionFactory.matchKeyword ; matchKeyword ( "uuid" , "f47ac10b-58cc-4372-a567-0e02b2c3d479" ); using static Qdrant .

Client .

Grpc .

Conditions ;

MatchKeyword ( "uuid" , "f47ac10b-58cc-4372-a567-0e02b2c3d479" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewMatch ( "uuid" , "f47ac10b-58cc-4372-a567-0e02b2c3d479" ) Geo Geo Bounding Box { "key" : "location" , "geo_bounding_box" : { "bottom_right" : { "lon" : 13.455868 , "lat" : 52.495862 }, "top_left" : { "lon" : 13.403683 , "lat" : 52.520711 } } } models .

FieldCondition ( key = "location" , geo_bounding_box = models .

GeoBoundingBox ( bottom_right = models .

GeoPoint ( lon = 13.455868 , lat = 52.495862 , ), top_left = models .

GeoPoint ( lon = 13.403683 , lat = 52.520711 , ), ), ) { key : 'location' , geo_bounding_box : { bottom_right : { lon : 13.455868 , lat : 52.495862 }, top_left : { lon : 13.403683 , lat : 52.520711 } } } use qdrant_client :: qdrant :: { Condition , GeoBoundingBox , GeoPoint };

Condition :: geo_bounding_box ( "location" , GeoBoundingBox { bottom_right : Some ( GeoPoint { lon : 13.455868 , lat : 52.495862 , }), top_left : Some ( GeoPoint { lon : 13.403683 , lat : 52.520711 , }), }, ) import static io.qdrant.client.ConditionFactory.geoBoundingBox ; geoBoundingBox ( "location" , 52 .

520711 , 13 .

403683 , 52 .

495862 , 13 .

455868 ); using static Qdrant .

Client .

Grpc .

Conditions ;

GeoBoundingBox ( "location" , 52.520711 , 13.403683 , 52.495862 , 13.455868 ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewGeoBoundingBox ( "location" , 52.520711 , 13.403683 , 52.495862 , 13.455868 ) It matches with location s inside a rectangle with the coordinates of the upper left corner in top_left and the coordinates of the lower right corner in bottom_right .

Geo Radius { "key" : "location" , "geo_radius" : { "center" : { "lon" : 13.403683 , "lat" : 52.520711 }, "radius" : 1000.0 } } models .

FieldCondition ( key = "location" , geo_radius = models .

GeoRadius ( center = models .

GeoPoint ( lon = 13.403683 , lat = 52.520711 , ), radius = 1000.0 , ), ) { key : 'location' , geo_radius : { center : { lon : 13.403683 , lat : 52.520711 }, radius : 1000.0 } } use qdrant_client :: qdrant :: { Condition , GeoPoint , GeoRadius };

Condition :: geo_radius ( "location" , GeoRadius { center : Some ( GeoPoint { lon : 13.403683 , lat : 52.520711 , }), radius : 1000.0 , }, ) import static io.qdrant.client.ConditionFactory.geoRadius ; geoRadius ( "location" , 52 .

520711 , 13 .

403683 , 1000 .

0f ); using static Qdrant .

Client .

Grpc .

Conditions ;

GeoRadius ( "location" , 52.520711 , 13.403683 , 1000.0f ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewGeoRadius ( "location" , 52.520711 , 13.403683 , 1000.0 ) It matches with location s inside a circle with the center at the center and a radius of radius meters.

If several values are stored, at least one of them should match the condition.

These conditions can only be applied to payloads that match the geo-data format .

Geo Polygon Geo Polygons search is useful for when you want to find points inside an irregularly shaped area, for example a country boundary or a forest boundary. A polygon always has an exterior ring and may optionally include interior rings. A lake with an island would be an example of an interior ring. If you wanted to find points in the water but not on the island, you would make an interior ring for the island.

When defining a ring, you must pick either a clockwise or counterclockwise ordering for your points. The first and last point of the polygon must be the same.

Currently, we only support unprojected global coordinates (decimal degrees longitude and latitude) and we are datum agnostic.

{ "key" : "location" , "geo_polygon" : { "exterior" : { "points" : [ { "lon" : -70.0 , "lat" : -70.0 }, { "lon" : 60.0 , "lat" : -70.0 }, { "lon" : 60.0 , "lat" : 60.0 }, { "lon" : -70.0 , "lat" : 60.0 }, { "lon" : -70.0 , "lat" : -70.0 } ] }, "interiors" : [ { "points" : [ { "lon" : -65.0 , "lat" : -65.0 }, { "lon" : 0.0 , "lat" : -65.0 }, { "lon" : 0.0 , "lat" : 0.0 }, { "lon" : -65.0 , "lat" : 0.0 }, { "lon" : -65.0 , "lat" : -65.0 } ] } ] } } models .

FieldCondition ( key = "location" , geo_polygon = models .

GeoPolygon ( exterior = models .

GeoLineString ( points = [ models .

GeoPoint ( lon =- 70.0 , lat =- 70.0 , ), models .

GeoPoint ( lon = 60.0 , lat =- 70.0 , ), models .

GeoPoint ( lon = 60.0 , lat = 60.0 , ), models .

GeoPoint ( lon =- 70.0 , lat = 60.0 , ), models .

GeoPoint ( lon =- 70.0 , lat =- 70.0 , ), ] ), interiors = [ models .

GeoLineString ( points = [ models .

GeoPoint ( lon =- 65.0 , lat =- 65.0 , ), models .

GeoPoint ( lon = 0.0 , lat =- 65.0 , ), models .

GeoPoint ( lon = 0.0 , lat = 0.0 , ), models .

GeoPoint ( lon =- 65.0 , lat = 0.0 , ), models .

GeoPoint ( lon =- 65.0 , lat =- 65.0 , ), ] ) ], ), ) { key : "location" , geo_polygon : { exterior : { points : [ { lon : - 70.0 , lat : - 70.0 }, { lon : 60.0 , lat : - 70.0 }, { lon : 60.0 , lat : 60.0 }, { lon : - 70.0 , lat : 60.0 }, { lon : - 70.0 , lat : - 70.0 } ] }, interiors : [ { points : [ { lon : - 65.0 , lat : - 65.0 }, { lon : 0 , lat : - 65.0 }, { lon : 0 , lat : 0 }, { lon : - 65.0 , lat : 0 }, { lon : - 65.0 , lat : - 65.0 } ] } ] } } use qdrant_client :: qdrant :: { Condition , GeoLineString , GeoPoint , GeoPolygon };

Condition :: geo_polygon ( "location" , GeoPolygon { exterior : Some ( GeoLineString { points : vec !

[ GeoPoint { lon : - 70.0 , lat : - 70.0 , }, GeoPoint { lon : 60.0 , lat : - 70.0 , }, GeoPoint { lon : 60.0 , lat : 60.0 , }, GeoPoint { lon : - 70.0 , lat : 60.0 , }, GeoPoint { lon : - 70.0 , lat : - 70.0 , }, ], }), interiors : vec !

[ GeoLineString { points : vec !

[ GeoPoint { lon : - 65.0 , lat : - 65.0 , }, GeoPoint { lon : 0.0 , lat : - 65.0 , }, GeoPoint { lon : 0.0 , lat : 0.0 }, GeoPoint { lon : - 65.0 , lat : 0.0 , }, GeoPoint { lon : - 65.0 , lat : - 65.0 , }, ], }], }, ) import static io.qdrant.client.ConditionFactory.geoPolygon ; import io.qdrant.client.grpc.Common.GeoLineString ; import io.qdrant.client.grpc.Common.GeoPoint ; import java.util.List ; geoPolygon ( "location" , GeoLineString . newBuilder () . addAllPoints ( List . of ( GeoPoint . newBuilder (). setLon ( - 70 .

0 ). setLat ( - 70 .

0 ). build (), GeoPoint . newBuilder (). setLon ( 60 .

0 ). setLat ( - 70 .

0 ). build (), GeoPoint . newBuilder (). setLon ( 60 .

0 ). setLat ( 60 .

0 ). build (), GeoPoint . newBuilder (). setLon ( - 70 .

0 ). setLat ( 60 .

0 ). build (), GeoPoint . newBuilder (). setLon ( - 70 .

0 ). setLat ( - 70 .

0 ). build ())) . build (), List . of ( GeoLineString . newBuilder () . addAllPoints ( List . of ( GeoPoint . newBuilder (). setLon ( - 65 .

0 ). setLat ( - 65 .

0 ). build (), GeoPoint . newBuilder (). setLon ( 0 .

0 ). setLat ( - 65 .

0 ). build (), GeoPoint . newBuilder (). setLon ( 0 .

0 ). setLat ( 0 .

0 ). build (), GeoPoint . newBuilder (). setLon ( - 65 .

0 ). setLat ( 0 .

0 ). build (), GeoPoint . newBuilder (). setLon ( - 65 .

0 ). setLat ( - 65 .

0 ). build ())) . build ())); using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ;

GeoPolygon ( field : "location" , exterior : new GeoLineString { Points = { new GeoPoint { Lat = - 70.0 , Lon = - 70.0 }, new GeoPoint { Lat = 60.0 , Lon = - 70.0 }, new GeoPoint { Lat = 60.0 , Lon = 60.0 }, new GeoPoint { Lat = - 70.0 , Lon = 60.0 }, new GeoPoint { Lat = - 70.0 , Lon = - 70.0 } } }, interiors : [ new () { Points = { new GeoPoint { Lat = - 65.0 , Lon = - 65.0 }, new GeoPoint { Lat = 0.0 , Lon = - 65.0 }, new GeoPoint { Lat = 0.0 , Lon = 0.0 }, new GeoPoint { Lat = - 65.0 , Lon = 0.0 }, new GeoPoint { Lat = - 65.0 , Lon = - 65.0 } } } ] ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewGeoPolygon ( "location" , & qdrant .

GeoLineString { Points : [] * qdrant .

GeoPoint { { Lat : - 70 , Lon : - 70 }, { Lat : 60 , Lon : - 70 }, { Lat : 60 , Lon : 60 }, { Lat : - 70 , Lon : 60 }, { Lat : - 70 , Lon : - 70 }, }, }, & qdrant .

GeoLineString { Points : [] * qdrant .

GeoPoint { { Lat : - 65 , Lon : - 65 }, { Lat : 0 , Lon : - 65 }, { Lat : 0 , Lon : 0 }, { Lat : - 65 , Lon : 0 }, { Lat : - 65 , Lon : - 65 }, }, }) A match is considered any point location inside or on the boundaries of the given polygon‚Äôs exterior but not inside any interiors.

If several location values are stored for a point, then any of them matching will include that point as a candidate in the resultset.

These conditions can only be applied to payloads that match the geo-data format .

Values count In addition to the direct value comparison, it is also possible to filter by the amount of values.

For example, given the data: [ { "id" : 1 , "name" : "product A" , "comments" : [ "Very good!" , "Excellent" ] }, { "id" : 2 , "name" : "product B" , "comments" : [ "meh" , "expected more" , "ok" ] } ] We can perform the search only among the items with more than two comments: { "key" : "comments" , "values_count" : { "gt" : 2 } } models .

FieldCondition ( key = "comments" , values_count = models .

ValuesCount ( gt = 2 ), ) { key : 'comments' , values_count : { gt : 2 } } use qdrant_client :: qdrant :: { Condition , ValuesCount };

Condition :: values_count ( "comments" , ValuesCount { gt : Some ( 2 ), ..

Default :: default () }, ) import static io.qdrant.client.ConditionFactory.valuesCount ; import io.qdrant.client.grpc.Common.ValuesCount ; valuesCount ( "comments" , ValuesCount . newBuilder (). setGt ( 2 ). build ()); using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ;

ValuesCount ( "comments" , new ValuesCount { Gt = 2 }); import "github.com/qdrant/go-client/qdrant" qdrant .

NewValuesCount ( "comments" , & qdrant .

ValuesCount { Gt : qdrant .

PtrOf ( uint64 ( 2 )), }) The result would be: [{ "id" : 2 , "name" : "product B" , "comments" : [ "meh" , "expected more" , "ok" ] }] If stored value is not an array - it is assumed that the amount of values is equals to 1.

Is Empty Sometimes it is also useful to filter out records that are missing some value.

The IsEmpty condition may help you with that: { "is_empty" : { "key" : "reports" } } models .

IsEmptyCondition ( is_empty = models .

PayloadField ( key = "reports" ), ) { is_empty : { key : "reports" } } use qdrant_client :: qdrant :: Condition ;

Condition :: is_empty ( "reports" ) import static io.qdrant.client.ConditionFactory.isEmpty ; isEmpty ( "reports" ); using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ;

IsEmpty ( "reports" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewIsEmpty ( "reports" ) This condition will match all records where the field reports either does not exist, or has null or [] value.

Is Null It is not possible to test for NULL values with the match condition.

We have to use IsNull condition instead: { "is_null" : { "key" : "reports" } } models .

IsNullCondition ( is_null = models .

PayloadField ( key = "reports" ), ) { is_null : { key : "reports" } } use qdrant_client :: qdrant :: Condition ;

Condition :: is_null ( "reports" ) import static io.qdrant.client.ConditionFactory.isNull ; isNull ( "reports" ); using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ;

IsNull ( "reports" ); import "github.com/qdrant/go-client/qdrant" qdrant .

NewIsNull ( "reports" ) This condition will match all records where the field reports exists and has NULL value.

Has id This type of query is not related to payload, but can be very useful in some situations.

For example, the user could mark some specific search results as irrelevant, or we want to search only among the specified points.

POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "has_id": [1,3,5,7,9,11] } ] } ...

} client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

HasIdCondition ( has_id = [ 1 , 3 , 5 , 7 , 9 , 11 ]), ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { has_id : [ 1 , 3 , 5 , 7 , 9 , 11 ], }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ) . filter ( Filter :: must ([ Condition :: has_id ([ 1 , 3 , 5 , 7 , 9 , 11 ])])), ) . await ? ; import static io.qdrant.client.ConditionFactory.hasId ; import static io.qdrant.client.PointIdFactory.id ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMust ( hasId ( List . of ( id ( 1 ), id ( 3 ), id ( 5 ), id ( 7 ), id ( 9 ), id ( 11 )))) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : HasId ([ 1 , 3 , 5 , 7 , 9 , 11 ])); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewHasID ( qdrant .

NewIDNum ( 1 ), qdrant .

NewIDNum ( 3 ), qdrant .

NewIDNum ( 5 ), qdrant .

NewIDNum ( 7 ), qdrant .

NewIDNum ( 9 ), qdrant .

NewIDNum ( 11 ), ), }, }, }) Filtered points would be: [ { "id" : 1 , "city" : "London" , "color" : "green" }, { "id" : 3 , "city" : "London" , "color" : "blue" }, { "id" : 5 , "city" : "Moscow" , "color" : "green" } ] Has vector Available as of v1.13.0 This condition enables filtering by the presence of a given named vector on a point.

For example, if we have two named vector in our collection.

PUT /collections/{collection_name} { "vectors": { "image": { "size": 4, "distance": "Dot" }, "text": { "size": 8, "distance": "Cosine" } }, "sparse_vectors": { "sparse-image": {}, "sparse-text": {}, }, } Some points in the collection might have all vectors, some might have only a subset of them.

This is how you can search for points which have the dense image vector defined: POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "has_vector": "image" } ] } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

HasVectorCondition ( has_vector = "image" ), ], ), ) client . scroll ( "{collection_name}" , { filter : { must : [ { has_vector : "image" , }, ], }, }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ) . filter ( Filter :: must ([ Condition :: has_vector ( "image" )])), ) . await ? ; import static io.qdrant.client.ConditionFactory.hasVector ; import static io.qdrant.client.PointIdFactory.id ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; import java.util.List ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder () . addMust ( hasVector ( "image" )) . build ()) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : HasVector ( "image" )); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewHasVector ( "image" , ), }, }, })
================================================================================
PAGE 12/39
================================================================================
Title: Inference
URL: https://qdrant.tech/documentation/concepts/inference/
--------------------------------------------------------------------------------

Inference Inference is the process of using a machine learning model to create vector embeddings from text, images, or other data types. While you can create embeddings on the client side, you can also let Qdrant generate them while storing or querying data.

There are several advantages to generating embeddings with Qdrant: No need for external pipelines or separate model servers.

Work with a single unified API instead of a different API per model provider.

No external network calls, minimizing delays or data transfer overhead.

Depending on the model you want to use, inference can be executed: on the client side, using the FastEmbed library by the Qdrant cluster (only supported for the BM25 model) in Qdrant Cloud, using Cloud Inference (for clusters on Qdrant Managed Cloud) externally (models by OpenAI, Cohere, and Jina AI; for clusters on Qdrant Managed Cloud) Inference API You can use inference in the API wherever you can use regular vectors. Instead of a vector, you can use special Inference Objects : Document object, used for text inference // Document { // Text input text : "Your text" , // Name of the model, to do inference with model : "<the-model-to-use>" , // Extra parameters for the model, Optional options : {} } Image object, used for image inference // Image { // Image input image : "<url>" , // Or base64 encoded image // Name of the model, to do inference with model : "<the-model-to-use>" , // Extra parameters for the model, Optional options : {} } Object object, reserved for other types of input, which might be implemented in the future.

The Qdrant API supports the usage of these Inference Objects in all places where regular vectors can be used. For example: POST /collections/<your-collection>/points/query { "query": { "nearest": [0.12, 0.34, 0.56, 0.78, ...] } } Can be replaced with POST /collections/<your-collection>/points/query { "query": { "nearest": { "text": "My Query Text", "model": "<the-model-to-use>" } } } In this case, Qdrant uses the configured embedding model to automatically create a vector from the Inference Object and then perform the search query with it. All of this happens within a low-latency network.

Server-side Inference: BM25 BM25 (Best Matching 25) is a ranking function for text search. BM25 uses sparse vectors that represent documents, where each dimension corresponds to a word. Qdrant can generate these sparse embeddings from input text directly on the server.

While upserting points, provide the text and the qdrant/bm25 embedding model: PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": { "my-bm25-vector": { "text": "Recipe for baking chocolate chip cookies", "model": "qdrant/bm25" } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "my-bm25-vector" : models .

Document ( text = "Recipe for baking chocolate chip cookies" , model = "Qdrant/bm25" , ) }, ) ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { 'my-bm25-vector' : { text : 'Recipe for baking chocolate chip cookies' , model : 'Qdrant/bm25' , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { DocumentBuilder , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , HashMap :: from ([( "my-bm25-vector" . to_string (), DocumentBuilder :: new ( "Recipe for baking chocolate chip cookies" , "qdrant/bm25" ) . build (), )]), Payload :: default (), )], )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "my-bm25-vector" , vector ( Document . newBuilder () . setModel ( "qdrant/bm25" ) . setText ( "Recipe for baking chocolate chip cookies" ) . build ())))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , Vector > { ["my-bm25-vector"] = new Document () { Model = "qdrant/bm25" , Text = "Recipe for baking chocolate chip cookies" , }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "my-bm25-vector" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "qdrant/bm25" , Text : "Recipe for baking chocolate chip cookies" , }), }), }, }, }) Qdrant uses the model to generate the embeddings and stores the point with the resulting vector. Retrieving the point shows the embeddings that were generated: ....

"my-bm25-vector" : { "indices" : [ 112174620 , 177304315 , 662344706 , 771857363 , 1617337648 ], "values" : [ 1.6697302 , 1.6697302 , 1.6697302 , 1.6697302 , 1.6697302 ] } .... ] Similarly, you can use inference at query time by providing the text to query with as well as the embedding model: POST /collections/{collection_name}/points/query { "query": { "text": "How to bake cookies?", "model": "qdrant/bm25" }, "using": "my-bm25-vector" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . query_points ( collection_name = " {collection_name} " , query = models .

Document ( text = "How to bake cookies?" , model = "Qdrant/bm25" , ), using = "my-bm25-vector" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { text : 'How to bake cookies?' , model : 'qdrant/bm25' , }, using : 'my-bm25-vector' , }); use qdrant_client :: { Qdrant , qdrant :: { Document , Query , QueryPointsBuilder }, }; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build (). unwrap (); client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( Document { text : "How to bake cookies?" . into (), model : "qdrant/bm25" . into (), ..

Default :: default () })) . using ( "my-bm25-vector" ) . build (), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . queryAsync ( Points .

QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( Document . newBuilder () . setModel ( "qdrant/bm25" ) . setText ( "How to bake cookies?" ) . build ())) . setUsing ( "my-bm25-vector" ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new Document () { Model = "qdrant/bm25" , Text = "How to bake cookies?" }, usingVector : "my-bm25-vector" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Model : "qdrant/bm25" , Text : "How to bake cookies?" , }), ), Using : qdrant .

PtrOf ( "my-bm25-vector" ), }) Qdrant Cloud Inference Clusters on Qdrant Managed Cloud can access embedding models that are hosted on Qdrant Cloud . For a list of available models, visit the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. Here, you can also enable Cloud Inference for a cluster if it‚Äôs not already enabled.

Before using a Cloud-hosted embedding model, ensure that your collection has been configured for vectors with the correct dimensionality. The Inference tab of the Cluster Detail page in the Qdrant Cloud Console lists the dimensionality for each supported embedding model.

Text Inference Let‚Äôs consider an example of using Cloud Inference with a text model that produces dense vectors. This example creates one point and uses a simple search query with a Document Inference Object.

# Insert new points with cloud-side inference PUT /collections/<your-collection>/points?wait=true { "points": [ { "id": 1, "payload": { "topic": "cooking", "type": "dessert" }, "vector": { "text": "Recipe for baking chocolate chip cookies", "model": "<the-model-to-use>" } } ] } # Search in the collection using cloud-side inference POST /collections/<your-collection>/points/query { "query": { "text": "How to bake cookies?", "model": "<the-model-to-use>" } } # Create a new vector curl -X PUT "https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true" \ -H "Content-Type: application/json" \ -H "api-key: <paste-your-api-key-here>" \ -d '{ "points": [ { "id": 1, "payload": { "topic": "cooking", "type": "dessert" }, "vector": { "text": "Recipe for baking chocolate chip cookies", "model": "<the-model-to-use>" } } ] }' # Perform a search query curl -X POST "https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query" \ -H "Content-Type: application/json" \ -H "api-key: <paste-your-api-key-here>" \ -d '{ "query": { "text": "How to bake cookies?", "model": "<the-model-to-use>" } }' from qdrant_client import QdrantClient from qdrant_client.models import PointStruct , Document client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<paste-your-api-key-here>" , # IMPORTANT # If not enabled, inference will be performed locally cloud_inference = True , ) points = [ PointStruct ( id = 1 , payload = { "topic" : "cooking" , "type" : "dessert" }, vector = Document ( text = "Recipe for baking chocolate chip cookies" , model = "<the-model-to-use>" ) ) ] client . upsert ( collection_name = "<your-collection>" , points = points ) result = client . query_points ( collection_name = "<your-collection>" , query = Document ( text = "How to bake cookies?" , model = "<the-model-to-use>" ) ) print ( result ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ url : 'https://xyz-example.qdrant.io:6333' , apiKey : '<paste-your-api-key-here>' , }); const points = [ { id : 1 , payload : { topic : "cooking" , type : "dessert" }, vector : { text : "Recipe for baking chocolate chip cookies" , model : "<the-model-to-use>" } } ]; await client . upsert ( "<your-collection>" , { wait : true , points }); const result = await client . query ( "<your-collection>" , { query : { text : "How to bake cookies?" , model : "<the-model-to-use>" }, } ) console . log ( result ); use qdrant_client :: qdrant :: Query ; use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Payload ; use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { Document }; use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder };

#[tokio::main] async fn main () { let client = Qdrant :: from_url ( "https://xyz-example.qdrant.io:6334" ) . api_key ( "<paste-your-api-key-here>" ) . build () . unwrap (); let points = vec!

[ PointStruct :: new ( 1 , Document :: new ( "Recipe for baking chocolate chip cookies" , "<the-model-to-use>" ), Payload :: try_from ( serde_json :: json!

( { "topic" : "cooking" , "type" : "dessert" } )). unwrap (), ) ]; let upsert_request = UpsertPointsBuilder :: new ( "<your-collection>" , points ). wait ( true ); let _ = client . upsert_points ( upsert_request ). await ; let query_document = Document :: new ( "How to bake cookies?" , "<the-model-to-use>" ); let query_request = QueryPointsBuilder :: new ( "<your-collection>" ) . query ( Query :: new_nearest ( query_document )); let result = client . query ( query_request ). await . unwrap (); println!

( "Result: {:?} " , result );

} package org.example ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.grpc.Points ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ; import java.util.concurrent.ExecutionException ; public class Main { public static void main ( String [] args ) throws ExecutionException , InterruptedException { QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<paste-your-api-key-here>" ) . build ()); client . upsertAsync ( "<your-collection>" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( Document . newBuilder () . setText ( "Recipe for baking chocolate chip cookies" ) . setModel ( "<the-model-to-use>" ) . build ())) . putAllPayload ( Map . of ( "topic" , value ( "cooking" ), "type" , value ( "dessert" ))) . build ())) . get ();

List < Points .

ScoredPoint > points = client . queryAsync ( Points .

QueryPoints . newBuilder () . setCollectionName ( "<your-collection>" ) . setQuery ( nearest ( Document . newBuilder () . setText ( "How to bake cookies?" ) . setModel ( "<the-model-to-use>" ) . build ())) . build ()) . get ();

System . out . printf ( points . toString ());

} } using Qdrant.Client ; using Qdrant.Client.Grpc ; using Value = Qdrant .

Client .

Grpc .

Value ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<paste-your-api-key-here>" ); await client .

UpsertAsync ( collectionName : "<your-collection>" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Document () { Text = "Recipe for baking chocolate chip cookies" , Model = "<the-model-to-use>" , }, Payload = { ["topic"] = "cooking" , ["type"] = "dessert" }, }, } ); var points = await client .

QueryAsync ( collectionName : "<your-collection>" , query : new Document () { Text = "How to bake cookies?" , Model = "<the-model-to-use>" } ); foreach ( var point in points ) { Console .

WriteLine ( point );

} package main import ( "context" "log" "time" "github.com/qdrant/go-client/qdrant" ) func main () { ctx , cancel := context .

WithTimeout ( context .

Background (), time .

Second ) defer cancel () client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) if err != nil { log .

Fatalf ( "did not connect: %v" , err ) } defer client .

Close () _ , err = client .

Upsert ( ctx , & qdrant .

UpsertPoints { CollectionName : "<your-collection>" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectorsDocument ( & qdrant .

Document { Text : "Recipe for baking chocolate chip cookies" , Model : "<the-model-to-use>" , }), Payload : qdrant .

NewValueMap ( map [ string ] any { "topic" : "cooking" , "type" : "dessert" , }), }, }, }) if err != nil { log .

Fatalf ( "error creating point: %v" , err ) } points , err := client .

Query ( ctx , & qdrant .

QueryPoints { CollectionName : "<your-collection>" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Text : "How to bake cookies?" , Model : "<the-model-to-use>" , }), ), }) log .

Printf ( "List of points: %s" , points ) } Usage examples, specific to each cluster and model, can also be found in the Inference tab of the Cluster Detail page in the Qdrant Cloud Console.

Note that each model has a context window, which is the maximum number of tokens that can be processed by the model in a single request. If the input text exceeds the context window, it is truncated to fit within the limit. The context window size is displayed in the Inference tab of the Cluster Detail page.

For dense vector models, you also have to ensure that the vector size configured in the collection matches the output size of the model. If the vector size does not match, the upsert will fail with an error.

Image Inference Here is another example of using Cloud Inference with an image model. This example uses the CLIP model to encode an image and then uses a text query to search for it.

Since the CLIP model is multimodal, we can use both image and text inputs on the same vector field.

# Insert new points with cloud-side inference PUT /collections/<your-collection>/points?wait=true { "points": [ { "id": 1, "vector": { "image": "https://qdrant.tech/example.png", "model": "qdrant/clip-vit-b-32-vision" }, "payload": { "title": "Example Image" } } ] } # Search in the collection using cloud-side inference POST /collections/<your-collection>/points/query { "query": { "text": "Mission to Mars", "model": "qdrant/clip-vit-b-32-text" } } # Create a new vector curl -X PUT "https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true" \ -H "Content-Type: application/json" \ -H "api-key: <paste-your-api-key-here>" \ -d '{ "points": [ { "id": 1, "vector": { "image": "https://qdrant.tech/example.png", "model": "qdrant/clip-vit-b-32-vision" }, "payload": { "title": "Example Image" } } ] }' # Perform a search query curl -X POST "https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query" \ -H "Content-Type: application/json" \ -H "api-key: <paste-your-api-key-here>" \ -d '{ "query": { "text": "Mission to Mars", "model": "qdrant/clip-vit-b-32-text" } }' from qdrant_client import QdrantClient from qdrant_client.models import PointStruct , Image , Document client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<paste-your-api-key-here>" , # IMPORTANT # If not enabled, inference will be performed locally cloud_inference = True , ) points = [ PointStruct ( id = 1 , vector = Image ( image = "https://qdrant.tech/example.png" , model = "qdrant/clip-vit-b-32-vision" ), payload = { "title" : "Example Image" } ) ] client . upsert ( collection_name = "<your-collection>" , points = points ) result = client . query_points ( collection_name = "<your-collection>" , query = Document ( text = "Mission to Mars" , model = "qdrant/clip-vit-b-32-text" ) ) print ( result ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ url : 'https://xyz-example.qdrant.io:6333' , apiKey : '<paste-your-api-key-here>' , }); const points = [ { id : 1 , vector : { image : "https://qdrant.tech/example.png" , model : "qdrant/clip-vit-b-32-vision" }, payload : { title : "Example Image" } } ]; await client . upsert ( "<your-collection>" , { wait : true , points }); const result = await client . query ( "<your-collection>" , { query : { text : "Mission to Mars" , model : "qdrant/clip-vit-b-32-text" }, } ) console . log ( result ); use qdrant_client :: qdrant :: Query ; use qdrant_client :: qdrant :: QueryPointsBuilder ; use qdrant_client :: Payload ; use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { Document , Image }; use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder };

#[tokio::main] async fn main () { let client = Qdrant :: from_url ( "https://xyz-example.qdrant.io:6334" ) . api_key ( "<paste-your-api-key-here>" ) . build () . unwrap (); let points = vec!

[ PointStruct :: new ( 1 , Image :: new_from_url ( "https://qdrant.tech/example.png" , "qdrant/clip-vit-b-32-vision" ), Payload :: try_from ( serde_json :: json!

({ "title" : "Example Image" })). unwrap (), ) ]; let upsert_request = UpsertPointsBuilder :: new ( "<your-collection>" , points ). wait ( true ); let _ = client . upsert_points ( upsert_request ). await ; let query_document = Document :: new ( "Mission to Mars" , "qdrant/clip-vit-b-32-text" ); let query_request = QueryPointsBuilder :: new ( "<your-collection>" ) . query ( Query :: new_nearest ( query_document )); let result = client . query ( query_request ). await . unwrap (); println!

( "Result: {:?} " , result );

} package org.example ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.grpc.Points ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ; import java.util.concurrent.ExecutionException ; public class Main { public static void main ( String [] args ) throws ExecutionException , InterruptedException { QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<paste-your-api-key-here>" ) . build ()); client . upsertAsync ( "<your-collection>" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( Image . newBuilder () . setImage ( value ( "https://qdrant.tech/example.png" )) . setModel ( "qdrant/clip-vit-b-32-vision" ) . build ())) . putAllPayload ( Map . of ( "title" , value ( "Example Image" ))) . build ())) . get ();

List < Points .

ScoredPoint > points = client . queryAsync ( Points .

QueryPoints . newBuilder () . setCollectionName ( "<your-collection>" ) . setQuery ( nearest ( Document . newBuilder () . setText ( "Mission to Mars" ) . setModel ( "qdrant/clip-vit-b-32-text" ) . build ())) . build ()) . get ();

System . out . printf ( points . toString ());

} } using Qdrant.Client ; using Qdrant.Client.Grpc ; using Value = Qdrant .

Client .

Grpc .

Value ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<paste-your-api-key-here>" ); await client .

UpsertAsync ( collectionName : "<your-collection>" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Image () { Image_ = "https://qdrant.tech/example.png" , Model = "qdrant/clip-vit-b-32-vision" , }, Payload = { ["title"] = "Example Image" }, }, } ); var points = await client .

QueryAsync ( collectionName : "<your-collection>" , query : new Document () { Text = "Mission to Mars" , Model = "qdrant/clip-vit-b-32-text" } ); foreach ( var point in points ) { Console .

WriteLine ( point );

} package main import ( "context" "log" "time" "github.com/qdrant/go-client/qdrant" ) func main () { ctx , cancel := context .

WithTimeout ( context .

Background (), time .

Second ) defer cancel () client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) if err != nil { log .

Fatalf ( "did not connect: %v" , err ) } defer client .

Close () _ , err = client .

Upsert ( ctx , & qdrant .

UpsertPoints { CollectionName : "<your-collection>" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectorsImage ( & qdrant .

Image { Model : "qdrant/clip-vit-b-32-vision" , Image : qdrant .

NewValueString ( "https://qdrant.tech/example.png" ), }), Payload : qdrant .

NewValueMap ( map [ string ] any { "title" : "Example image" , }), }, }, }) if err != nil { log .

Fatalf ( "error creating point: %v" , err ) } points , err := client .

Query ( ctx , & qdrant .

QueryPoints { CollectionName : "<your-collection>" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Text : "Mission to Mars" , Model : "qdrant/clip-vit-b-32-text" , }), ), }) log .

Printf ( "List of points: %s" , points ) } The Qdrant Cloud Inference server will download the images using the provided URL. Alternatively, you can provide the image as a base64-encoded string. Each model has limitations on the file size and extensions it can work with. Refer to the model card for details.

Local Inference Compatibility The Python SDK offers a unique capability: it supports both local and cloud inference through an identical interface.

You can easily switch between local and cloud inference by setting the cloud_inference flag when initializing the QdrantClient. For example: client = QdrantClient ( url = "https://your-cluster.qdrant.io" , api_key = "<your-api-key>" , cloud_inference = True , # Set to False to use local inference ) This flexibility allows you to develop and test your applications locally or in continuous integration (CI) environments without requiring access to cloud inference resources.

When cloud_inference is set to False , inference is performed locally using fastembed .

When set to True , inference requests are handled by Qdrant Cloud.

External Embedding Model Providers Qdrant Cloud can act as a proxy for the APIs of three external embedding model providers: OpenAI Cohere Jina AI This enables you to access any of the embedding models provided by these providers through the Qdrant API.

To use an external provider‚Äôs embedding model, you need an API key from that provider. For example, to access OpenAI models, you need an OpenAI API key. Qdrant does not store or cache your API keys; they must be provided with each inference request.

When using an external embedding model, ensure that your collection has been configured for vectors with the correct dimensionality. Refer to the model‚Äôs documentation for details on the output dimensions.

OpenAI When you prepend a model name with openai/ , the embedding request is automatically routed to the OpenAI Embeddings API .

For example, to use OpenAI‚Äôs text-embedding-3-large model when ingesting data, prepend the model name with openai/ and provide your OpenAI API key in the options object. Any OpenAI-specific API parameters can be passed using the options object. This example uses the OpenAI-specific API dimensions parameter to reduce the dimensionality to 512: PUT /collections/{collection_name}/points?wait=true { "points": [ { "id": 1, "vector": { "text": "Recipe for baking chocolate chip cookies", "model": "openai/text-embedding-3-large", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>", "dimensions": 512 } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = models .

Document ( text = "Recipe for baking chocolate chip cookies" , model = "openai/text-embedding-3-large" , options = { "openai-api-key" : "<your_openai_api_key>" , "dimensions" : 512 } ) ) ] ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { text : 'Recipe for baking chocolate chip cookies' , model : 'openai/text-embedding-3-large' , options : { 'openai-api-key' : '<your_openai_api_key>' , dimensions : 512 , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { Document , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; let mut options = HashMap :: new (); options . insert ( "openai-api-key" . to_string (), "<YOUR_OPENAI_API_KEY>" . into ()); options . insert ( "dimensions" . to_string (), 512. into ()); client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , Document { text : "Recipe for baking chocolate chip cookies" . into (), model : "openai/text-embedding-3-large" . into (), options , }, Payload :: default ()) ]). wait ( true )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( Document . newBuilder () . setModel ( "openai/text-embedding-3-large" ) . setText ( "Recipe for baking chocolate chip cookies" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ), "dimensions" , value ( 512 ))) . build ())) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Document () { Model = "openai/text-embedding-3-large" , Text = "Recipe for baking chocolate chip cookies" , Options = { [ "openai-api-key" ] = "<YOUR_OPENAI_API_KEY>" , [ "dimensions" ] = 512 }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-large" , Text : "Recipe for baking chocolate chip cookies" , Options : qdrant .

NewValueMap ( map [ string ] any { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , "dimensions" : 512 , }), }), }, }, }) At query time, you can use the same model by prepending the model name with openai/ and providing your OpenAI API key in the options object. This example again uses the OpenAI-specific API dimensions parameter to reduce the dimensionality to 512: POST /collections/{collection_name}/points/query { "query": { "text": "How to bake cookies?", "model": "openai/text-embedding-3-large", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>", "dimensions": 512 } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . query_points ( collection_name = " {collection_name} " , query = models .

Document ( text = "How to bake cookies?" , model = "openai/text-embedding-3-large" , options = { "openai-api-key" : "<your_openai_api_key>" , "dimensions" : 512 } ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { text : 'How to bake cookies?' , model : 'openai/text-embedding-3-large' , options : { 'openai-api-key' : '<your_openai_api_key>' , dimensions : 512 , }, }, }); use qdrant_client :: { Qdrant , qdrant :: { Document , Query , QueryPointsBuilder , Value }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build (). unwrap (); let mut options = HashMap :: < String , Value > :: new (); options . insert ( "openai-api-key" . to_string (), "<YOUR_OPENAI_API_KEY>" . into ()); options . insert ( "dimensions" . to_string (), 512. into ()); client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( Document { text : "How to bake cookies?" . into (), model : "openai/text-embedding-3-large" . into (), options , })) . build (), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( Document . newBuilder () . setModel ( "openai/text-embedding-3-large" ) . setText ( "How to bake cookies?" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ), "dimensions" , value ( 512 ))) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new Document () { Model = "openai/text-embedding-3-large" , Text = "How to bake cookies?" , Options = { [ "openai-api-key" ] = "<YOUR_OPENAI_API_KEY>" , [ "dimensions" ] = 512 }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-large" , Text : "How to bake cookies?" , Options : qdrant .

NewValueMap ( map [ string ] any { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , "dimensions" : 512 , }), }), ), }) Note that, because Qdrant does not store or cache your OpenAI API key, you need to provide it with each inference request.

Cohere When you prepend a model name with cohere/ , the embedding request is automatically routed to the Cohere Embed API .

For example, to use Cohere‚Äôs multimodal embed-v4.0 model when ingesting data, prepend the model name with cohere/ and provide your Cohere API key in the options object. This example uses the Cohere-specific API output_dimension parameter to reduce the dimensionality to 512: PUT /collections/{collection_name}/points?wait=true { "points": [ { "id": 1, "vector": { "image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFUlEQVR42mNk+M9Qz0AEYBxVSF+FAAhKDveksOjmAAAAAElFTkSuQmCC", "model": "cohere/embed-v4.0", "options": { "cohere-api-key": "<YOUR_COHERE_API_KEY>", "output_dimension": 512 } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = models .

Document ( text = "a green square" , model = "cohere/embed-v4.0" , options = { "cohere-api-key" : "<your_cohere_api_key>" , "output_dimension" : 512 } ) ) ] ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { text : 'a green square' , model : 'cohere/embed-v4.0' , options : { 'cohere-api-key' : '<your_cohere_api_key>' , output_dimension : 512 , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { Document , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; let mut options = HashMap :: new (); options . insert ( "cohere-api-key" . to_string (), "<YOUR_COHERE_API_KEY>" . into ()); options . insert ( "output_dimension" . to_string (), 512. into ()); client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , Document { text : "Recipe for baking chocolate chip cookies requires flour, sugar, eggs, and chocolate chips." . into (), model : "openai/text-embedding-3-small" . into (), options , }, Payload :: default ()) ]). wait ( true )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( Image . newBuilder () . setModel ( "cohere/embed-v4.0" ) . setImage ( value ( "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFUlEQVR42mNk+M9Qz0AEYBxVSF+FAAhKDveksOjmAAAAAElFTkSuQmCC" )) . putAllOptions ( Map . of ( "cohere-api-key" , value ( "<YOUR_COHERE_API_KEY>" ), "output_dimension" , value ( 512 ))) . build ())) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Image () { Model = "cohere/embed-v4.0" , Image_ = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFUlEQVR42mNk+M9Qz0AEYBxVSF+FAAhKDveksOjmAAAAAElFTkSuQmCC" , Options = { ["cohere-api-key"] = "<YOUR_COHERE_API_KEY>" , ["output_dimension"] = 512 , }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsImage ( & qdrant .

Image { Model : "cohere/embed-v4.0" , Image : qdrant .

NewValueString ( "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFUlEQVR42mNk+M9Qz0AEYBxVSF+FAAhKDveksOjmAAAAAElFTkSuQmCC" ), Options : qdrant .

NewValueMap ( map [ string ] any { "cohere-api-key" : "<YOUR_COHERE_API_KEY>" , "output_dimension" : 512 , }), }), }, }, }) Note that the Cohere embed-v4.0 model does not support passing an image as a URL. You need to provide a base64-encoded image as a Data URL.

At query time, you can use the same model by prepending the model name with cohere/ and providing your Cohere API key in the options object. This example again uses the Cohere-specific API output_dimension parameter to reduce the dimensionality to 512: POST /collections/{collection_name}/points/query { "query": { "text": "a green square", "model": "cohere/embed-v4.0", "options": { "cohere-api-key": "<YOUR_COHERE_API_KEY>", "output_dimension": 512 } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . query_points ( collection_name = " {collection_name} " , query = models .

Document ( text = "a green square" , model = "cohere/embed-v4.0" , options = { "cohere-api-key" : "<your_cohere_api_key>" , "output_dimension" : 512 } ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { text : 'a green square' , model : 'cohere/embed-v4.0' , options : { 'cohere-api-key' : '<your_cohere_api_key>' , output_dimension : 512 , }, }, }); use qdrant_client :: { Qdrant , qdrant :: { Document , Query , QueryPointsBuilder , Value }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "http://localhost:6333" ). build (). unwrap (); let mut options = HashMap :: < String , Value > :: new (); options . insert ( "cohere-api-key" . to_string (), "<YOUR_COHERE_API_KEY>" . into ()); options . insert ( "output_dimension" . to_string (), 512. into ()); client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( Document { text : "a green square" . into (), model : "cohere/embed-v4.0" . into (), options , })) . build (), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( Document . newBuilder () . setModel ( "cohere/embed-v4.0" ) . setText ( "a green square" ) . putAllOptions ( Map . of ( "cohere-api-key" , value ( "<YOUR_COHERE_API_KEY>" ), "output_dimension" , value ( 512 ))) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new Document () { Model = "cohere/embed-v4.0" , Text = "a green square" , Options = { [ "cohere-api-key" ] = "<YOUR_COHERE_API_KEY>" , [ "output_dimension" ] = 512 }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Text : "a green square" , Model : "cohere/embed-v4.0" , Options : qdrant .

NewValueMap ( map [ string ] any { "cohere-api-key" : "<YOUR_COHERE_API_KEY>" , "output_dimension" : 512 , }), }), ), }) Note that, because Qdrant does not store or cache your Cohere API key, you need to provide it with each inference request.

Jina AI When you prepend a model name with jinaai/ , the embedding request is automatically routed to the Jina AI Embedding API .

For example, to use Jina AI‚Äôs multimodal jina-clip-v2 model when ingesting data, prepend the model name with jinaai/ and provide your Jina AI API key in the options object. This example uses the Jina AI-specific API dimensions parameter to reduce the dimensionality to 512: PUT /collections/{collection_name}/points?wait=true { "points": [ { "id": 1, "vector": { "image": "https://qdrant.tech/example.png", "model": "jinaai/jina-clip-v2", "options": { "jina-api-key": "<YOUR_JINAAI_API_KEY>", "dimensions": 512 } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = models .

Image ( image = "https://qdrant.tech/example.png" , model = "jinaai/jina-clip-v2" , options = { "jina-api-key" : "<your_jinaai_api_key>" , "dimensions" : 512 } ) ) ] ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { image : 'https://qdrant.tech/example.png' , model : 'jinaai/jina-clip-v2' , options : { 'jina-api-key' : '<your_jinaai_api_key>' , dimensions : 512 , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { Image , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; let mut options = HashMap :: new (); options . insert ( "jina-api-key" . to_string (), "<YOUR_JINAAI_API_KEY>" . into ()); options . insert ( "dimensions" . to_string (), 512. into ()); client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , Image { image : Some ( "https://qdrant.tech/example.png" . into ()), model : "jinaai/jina-clip-v2" . into (), options , }, Payload :: default ()) ]). wait ( true )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( Image . newBuilder () . setModel ( "jinaai/jina-clip-v2" ) . setImage ( value ( "https://qdrant.tech/example.png" )) . putAllOptions ( Map . of ( "jina-api-key" , value ( "<YOUR_JINAAI_API_KEY>" ), "dimensions" , value ( 512 ))) . build ())) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Document () { Model = "jinaai/jina-clip-v2" , Text = "Mission to Mars" , Options = { [ "jina-api-key" ] = "<YOUR_JINAAI_API_KEY>" , [ "dimensions" ] = 512 }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsImage ( & qdrant .

Image { Model : "jinaai/jina-clip-v2" , Image : qdrant .

NewValueString ( "https://qdrant.tech/example.png" ), Options : qdrant .

NewValueMap ( map [ string ] any { "jina-api-key" : "<YOUR_JINAAI_API_KEY>" , "dimensions" : 512 , }), }), }, }, }) At query time, you can use the same model by prepending the model name with jinaai/ and providing your Jina AI API key in the options object. This example again uses the Jina AI-specific API dimensions parameter to reduce the dimensionality to 512: POST /collections/{collection_name}/points/query { "query": { "text": "Mission to Mars", "model": "jinaai/jina-clip-v2", "options": { "jina-api-key": "<YOUR_JINAAI_API_KEY>", "dimensions": 512 } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . query_points ( collection_name = " {collection_name} " , query = models .

Document ( text = "Mission to Mars" , model = "jinaai/jina-clip-v2" , options = { "jina-api-key" : "<your_jinaai_api_key>" , "dimensions" : 512 } ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : { text : 'Mission to Mars' , model : 'jinaai/jina-clip-v2' , options : { 'jina-api-key' : '<your_jinaai_api_key>' , dimensions : 512 , }, }, }); use qdrant_client :: { Qdrant , qdrant :: { Document , Query , QueryPointsBuilder , Value }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build (). unwrap (); let mut options = HashMap :: < String , Value > :: new (); options . insert ( "jina-api-key" . to_string (), "<YOUR_JINAAI_API_KEY>" . into ()); options . insert ( "dimensions" . to_string (), 512. into ()); client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( Query :: new_nearest ( Document { text : "Mission to Mars" . into (), model : "jinaai/jina-clip-v2" . into (), options , })) . build (), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( Document . newBuilder () . setModel ( "jinaai/jina-clip-v2" ) . setText ( "Mission to Mars" ) . putAllOptions ( Map . of ( "jina-api-key" , value ( "<YOUR_JINAAI_API_KEY>" ), "dimensions" , value ( 512 ))) . build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new Document () { Model = "jinaai/jina-clip-v2" , Text = "Mission to Mars" , Options = { [ "jina-api-key" ] = "<YOUR_JINAAI_API_KEY>" , [ "dimensions" ] = 512 }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Text : "Mission to Mars" , Model : "jinaai/jina-clip-v2" , Options : qdrant .

NewValueMap ( map [ string ] any { "jina-api-key" : "<YOUR_JINAAI_API_KEY>" , "dimensions" : 512 , }), }), ), }) Note that, because Qdrant does not store or cache your Jina AI API key, you need to provide it with each inference request Multiple Inference Operations You can run multiple inference operations within a single request, even when models are hosted in different locations. This example generates three different named vectors for a single point: image embeddings using jina-clip-v2 hosted by Jina AI, text embeddings using all-minilm-l6-v2 hosted by Qdrant Cloud, and BM25 embeddings using the bm25 model executed locally by the Qdrant cluster: PUT /collections/{collection_name}/points?wait=true { "points": [ { "id": 1, "vector": { "image": { "image": "https://qdrant.tech/example.png", "model": "jinaai/jina-clip-v2", "options": { "jina-api-key": "<YOUR_JINAAI_API_KEY>", "dimensions": 512 } }, "text": { "text": "Mars, the red planet", "model": "sentence-transformers/all-minilm-l6-v2" }, "bm25": { "text": "Mars, the red planet", "model": "qdrant/bm25" } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "image" : models .

Image ( image = "https://qdrant.tech/example.png" , model = "jinaai/jina-clip-v2" , options = { "jina-api-key" : "<your_jinaai_api_key>" , "dimensions" : 512 }, ), "text" : models .

Document ( text = "Mars, the red planet" , model = "sentence-transformers/all-minilm-l6-v2" , ), "bm25" : models .

Document ( text = "Mars, the red planet" , model = "Qdrant/bm25" , ), }, ) ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { image : { image : 'https://qdrant.tech/example.png' , model : 'jinaai/jina-clip-v2' , options : { 'jina-api-key' : '<your_jinaai_api_key>' , dimensions : 512 , }, }, text : { text : 'Mars, the red planet' , model : 'sentence-transformers/all-minilm-l6-v2' , }, bm25 : { text : 'Mars, the red planet' , model : 'Qdrant/bm25' , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { Document , Image , NamedVectors , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; let mut jina_options = HashMap :: new (); jina_options . insert ( "jina-api-key" . to_string (), "<YOUR_JINAAI_API_KEY>" . into ()); jina_options . insert ( "dimensions" . to_string (), 512. into ()); client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , NamedVectors :: default () . add_vector ( "image" , Image { image : Some ( "https://qdrant.tech/example.png" . into ()), model : "jinaai/jina-clip-v2" . into (), options : jina_options , }, ) . add_vector ( "text" , Document { text : "Mars, the red planet" . into (), model : "sentence-transformers/all-minilm-l6-v2" . into (), ..

Default :: default () }, ) . add_vector ( "bm25" , Document { text : "How to bake cookies?" . into (), model : "qdrant/bm25" . into (), ..

Default :: default () }, ), Payload :: default (), )], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "image" , vector ( Image . newBuilder () . setModel ( "jinaai/jina-clip-v2" ) . setImage ( value ( "https://qdrant.tech/example.png" )) . putAllOptions ( Map . of ( "jina-api-key" , value ( "<YOUR_JINAAI_API_KEY>" ), "dimensions" , value ( 512 ))) . build ()), "text" , vector ( Document . newBuilder () . setModel ( "sentence-transformers/all-minilm-l6-v2" ) . setText ( "Mars, the red planet" ) . build ()), "bm25" , vector ( Document . newBuilder () . setModel ( "qdrant/bm25" ) . setText ( "Mars, the red planet" ) . build ())))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , Vector > { ["image"] = new Image () { Model = "jinaai/jina-clip-v2" , Image_ = "https://qdrant.tech/example.png" , Options = { [ "jina-api-key" ] = "<YOUR_JINAAI_API_KEY>" , [ "dimensions" ] = 512 }, }, ["text"] = new Document () { Model = "sentence-transformers/all-minilm-l6-v2" , Text = "Mars, the red planet" , }, ["bm25"] = new Document () { Model = "qdrant/bm25" , Text = "Mars, the red planet" }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "image" : qdrant .

NewVectorImage ( & qdrant .

Image { Model : "jinaai/jina-clip-v2" , Image : qdrant .

NewValueString ( "https://qdrant.tech/example.png" ), Options : qdrant .

NewValueMap ( map [ string ] any { "jina-api-key" : "<YOUR_JINAAI_API_KEY>" , "dimensions" : 512 , }), }), "text" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "sentence-transformers/all-minilm-l6-v2" , Text : "Mars, the red planet" , }), "my-bm25-vector" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "qdrant/bm25" , Text : "Recipe for baking chocolate chip cookies" , }), }), }, }, }) When specifying multiple identical inference objects in a single request, the inference service generates embeddings only once and reuses the resulting vectors. This optimization is particularly beneficial when working with external model providers, as it reduces both latency and cost.

Reduce Vector Dimensionality with Matryoshka Models Matryoshka Representation Learning (MRL) is a technique used to train embedding models to produce vectors that can be reduced in size with minimal loss of information. On Qdrant Cloud, for supported models, you can specify the mrl parameter in the options object to reduce the vector size to the desired dimension.

MRL on Qdrant Cloud helps minimize costs and latency when you need multiple sizes of the same vector. Instead of making several inference requests for each vector size, the inference service only generates embeddings for the full-sized vector and then reduces the vector to each requested smaller size.

The following example demonstrates how to insert a point into a collection with both the original full-size vector ( large ) and a reduced-size vector ( small ): PUT /collections/{collection_name}/points?wait=true { "points": [ { "id": 1, "vector": { "large": { "text": "Recipe for baking chocolate chip cookies", "model": "openai/text-embedding-3-small", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>" } }, "small": { "text": "Recipe for baking chocolate chip cookies", "model": "openai/text-embedding-3-small", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>", "mrl": 64 } } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "large" : models .

Document ( text = "Recipe for baking chocolate chip cookies" , model = "openai/text-embedding-3-small" , options = { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" } ), "small" : models .

Document ( text = "Recipe for baking chocolate chip cookies" , model = "openai/text-embedding-3-small" , options = { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , "mrl" : 64 }, ) }, ) ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { large : { text : 'Recipe for baking chocolate chip cookies' , model : 'openai/text-embedding-3-small' , options : { 'openai-api-key' : '<YOUR_OPENAI_API_KEY>' , }, }, small : { text : 'Recipe for baking chocolate chip cookies' , model : 'openai/text-embedding-3-small' , options : { 'openai-api-key' : '<YOUR_OPENAI_API_KEY>' , mrl : 64 , }, }, }, }, ], }); use std :: collections :: HashMap ; use qdrant_client :: { Payload , Qdrant , qdrant :: { Document , NamedVectors , PointStruct , UpsertPointsBuilder , Value }, }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , NamedVectors :: default () . add_vector ( "large" , Document { text : "Recipe for baking chocolate chip cookies" . into (), model : "openai/text-embedding-3-small" . into (), options : HashMap :: < String , Value > :: from_iter ( vec!

[( "openai-api-key" . into (), "<YOUR_OPENAI_API_KEY>" . into (), )]), }, ) . add_vector ( "small" , Document { text : "Recipe for baking chocolate chip cookies" . into (), model : "openai/text-embedding-3-small" . into (), options : HashMap :: < String , Value > :: from_iter ( vec!

[ ( "openai-api-key" . into (), Value :: from ( "<YOUR_OPENAI_API_KEY>" ), ), ( "mrl" . into (), Value :: from ( 64 )), ]), }, ), Payload :: default (), )], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "large" , vector ( Document . newBuilder () . setModel ( "openai/text-embedding-3-small" ) . setText ( "Recipe for baking chocolate chip cookies" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ))) . build ()), "small" , vector ( Document . newBuilder () . setModel ( "openai/text-embedding-3-small" ) . setText ( "Recipe for baking chocolate chip cookies" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ), "mrl" , value ( 64 ))) . build ())))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , Vector > { ["large"] = new Document () { Model = "openai/text-embedding-3-small" , Text = "Recipe for baking chocolate chip cookies" , Options = { [ "openai-api-key" ] = "<YOUR_OPENAI_API_KEY>" }, }, ["small"] = new Document () { Model = "openai/text-embedding-3-small" , Text = "Recipe for baking chocolate chip cookies" , Options = { [ "openai-api-key" ] = "<YOUR_OPENAI_API_KEY>" , [ "mrl" ] = 64 }, }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "large" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-small" , Text : "Recipe for baking chocolate chip cookies" , Options : qdrant .

NewValueMap ( map [ string ] any { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , }), }), "small" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-small" , Text : "Recipe for baking chocolate chip cookies" , Options : qdrant .

NewValueMap ( map [ string ] any { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , "mrl" : 64 , }), }), }), }, }, }) Note that, even though the request contains two inference objects, Qdrant Cloud‚Äôs inference service only makes one inference request to the OpenAI API, saving one round trip and reducing costs.

A good use case for MRL is prefetching with smaller vectors, followed by re-scoring with the original-sized vectors, effectively balancing speed and accuracy. This example first prefetches 1000 candidates using a 64-dimensional reduced vector ( small ) and then re-scores them using the original full-size vector ( large ) to return the top 10 most relevant results: POST /collections/{collection_name}/points/query { "prefetch": { "query": { "text": "How to bake cookies?", "model": "openai/text-embedding-3-small", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>", "mrl": 64 } }, "using": "small", "limit": 1000 }, "query": { "text": "How to bake cookies?", "model": "openai/text-embedding-3-small", "options": { "openai-api-key": "<YOUR_OPENAI_API_KEY>" } }, "using": "large", "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . query_points ( collection_name = " {collection_name} " , query = models .

Document ( text = "How to bake cookies?" , model = "openai/text-embedding-3-small" , options = { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" } ), using = "large" , limit = 10 , prefetch = models .

Prefetch ( query = models .

Document ( text = "How to bake cookies?" , model = "openai/text-embedding-3-small" , options = { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , "mrl" : 64 } ), using = "small" , limit = 1000 , ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { prefetch : { query : { text : "How to bake cookies?" , model : "openai/text-embedding-3-small" , options : { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , mrl : 64 , } }, using : 'small' , limit : 1000 , }, query : { text : "How to bake cookies?" , model : "openai/text-embedding-3-small" , options : { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" } }, using : 'large' , limit : 10 , }); use std :: collections :: HashMap ; use qdrant_client :: { Qdrant , qdrant :: { Document , PrefetchQueryBuilder , Query , QueryPointsBuilder , Value }, }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . add_prefetch ( PrefetchQueryBuilder :: default () . query ( Query :: new_nearest ( Document { text : "How to bake cookies?" . into (), model : "openai/text-embedding-3-small" . into (), options : HashMap :: < String , Value > :: from_iter ( vec!

[ ( "openai-api-key" . to_string (), Value :: from ( "<YOUR_OPENAI_API_KEY>" ), ), ( "mrl" . into (), Value :: from ( 64 )), ]), })) . using ( "small" ) . limit ( 1000_ u64 ), ) . query ( Query :: new_nearest ( Document { text : "How to bake cookies?" . into (), model : "openai/text-embedding-3-small" . into (), options : HashMap :: from_iter ( vec!

[( "openai-api-key" . into (), "<YOUR_OPENAI_API_KEY>" . into (), )]), })) . using ( "large" ) . limit ( 10_ u64 ) . build (), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ValueFactory.value ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.PrefetchQuery ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . queryAsync ( Points .

QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addPrefetch ( PrefetchQuery . newBuilder () . setQuery ( nearest ( Document . newBuilder () . setModel ( "openai/text-embedding-3-small" ) . setText ( "How to bake cookies?" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ), "mrl" , value ( 64 ))) . build ())) . setUsing ( "small" ) . setLimit ( 1000 ) . build ()) . setQuery ( nearest ( Document . newBuilder () . setModel ( "openai/text-embedding-3-small" ) . setText ( "How to bake cookies?" ) . putAllOptions ( Map . of ( "openai-api-key" , value ( "<YOUR_OPENAI_API_KEY>" ))) . build ())) . setUsing ( "large" ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

QueryAsync ( collectionName : "{collection_name}" , prefetch : [ new() { Query = new Document() { Model = "openai/text-embedding-3-small", Text = "How to bake cookies?", Options = { ["openai-api-key"] = "<YOUR_OPENAI_API_KEY>" , [ "mrl" ] = 64 }, }, Using = "small" , Limit = 1000 , }, ], query : new Document () { Model = "openai/text-embedding-3-small" , Text = "How to bake cookies?" , Options = { [ "openai-api-key" ] = "<YOUR_OPENAI_API_KEY>" }, }, usingVector : "large" , limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Prefetch : [] * qdrant .

PrefetchQuery { { Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-small" , Text : "How to bake cookies?" , Options : qdrant .

NewValueMap ( map [ string ] any { "mrl" : 64 , "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , }), }), ), Using : qdrant .

PtrOf ( "small" ), Limit : qdrant .

PtrOf ( uint64 ( 1000 )), }, }, Query : qdrant .

NewQueryNearest ( qdrant .

NewVectorInputDocument ( & qdrant .

Document { Model : "openai/text-embedding-3-small" , Text : "How to bake cookies?" , Options : qdrant .

NewValueMap ( map [ string ] any { "openai-api-key" : "<YOUR_OPENAI_API_KEY>" , }), }), ), Using : qdrant .

PtrOf ( "large" ), Limit : qdrant .

PtrOf ( uint64 ( 10 )), })
================================================================================
PAGE 13/39
================================================================================
Title: Optimizer
URL: https://qdrant.tech/documentation/concepts/optimizer/
--------------------------------------------------------------------------------

Optimizer It is much more efficient to apply changes in batches than perform each change individually, as many other databases do. Qdrant here is no exception. Since Qdrant operates with data structures that are not always easy to change, it is sometimes necessary to rebuild those structures completely.

Storage optimization in Qdrant occurs at the segment level (see storage ).

In this case, the segment to be optimized remains readable for the time of the rebuild.

The availability is achieved by wrapping the segment into a proxy that transparently handles data changes.

Changed data is placed in the copy-on-write segment, which has priority for retrieval and subsequent updates.

Vacuum Optimizer The simplest example of a case where you need to rebuild a segment repository is to remove points.

Like many other databases, Qdrant does not delete entries immediately after a query.

Instead, it marks records as deleted and ignores them for future queries.

This strategy allows us to minimize disk access - one of the slowest operations.

However, a side effect of this strategy is that, over time, deleted records accumulate, occupy memory and slow down the system.

To avoid these adverse effects, Vacuum Optimizer is used.

It is used if the segment has accumulated too many deleted records.

The criteria for starting the optimizer are defined in the configuration file.

Here is an example of parameter values: storage : optimizers : # The minimal fraction of deleted vectors in a segment, required to perform segment optimization deleted_threshold : 0.2 # The minimal number of vectors in a segment, required to perform segment optimization vacuum_min_vector_number : 1000 Merge Optimizer The service may require the creation of temporary segments.

Such segments, for example, are created as copy-on-write segments during optimization itself.

It is also essential to have at least one small segment that Qdrant will use to store frequently updated data.

On the other hand, too many small segments lead to suboptimal search performance.

The merge optimizer constantly tries to reduce the number of segments if there currently are too many. The desired number of segments is specified with default_segment_number and defaults to the number of CPUs. The optimizer may takes at least the three smallest segments and merges them into one.

Segments will not be merged if they‚Äôll exceed the maximum configured segment size with max_segment_size_kb . It prevents creating segments that are too large to efficiently index. Increasing this number may help to reduce the number of segments if you have a lot of data, and can potentially improve search performance.

The criteria for starting the optimizer are defined in the configuration file.

Here is an example of parameter values: storage : optimizers : # Target amount of segments optimizer will try to keep.

# Real amount of segments may vary depending on multiple parameters: #  - Amount of stored points #  - Current write RPS # # It is recommended to select default number of segments as a factor of the number of search threads, # so that each segment would be handled evenly by one of the threads.

# If `default_segment_number = 0`, will be automatically selected by the number of available CPUs default_segment_number : 0 # Do not create segments larger this size (in KiloBytes).

# Large segments might require disproportionately long indexation times, # therefore it makes sense to limit the size of segments.

# # If indexation speed have more priority for your - make this parameter lower.

# If search speed is more important - make this parameter higher.

# Note: 1Kb = 1 vector of size 256 # If not set, will be automatically selected considering the number of available CPUs. max_segment_size_kb : null Indexing Optimizer Qdrant allows you to choose the type of indexes and data storage methods used depending on the number of records.

So, for example, if the number of points is less than 10000, using any index would be less efficient than a brute force scan.

The Indexing Optimizer is used to implement the enabling of indexes and memmap storage when the minimal amount of records is reached.

The criteria for starting the optimizer are defined in the configuration file.

Here is an example of parameter values: storage : optimizers : # Maximum size (in kilobytes) of vectors to store in-memory per segment.

# Segments larger than this threshold will be stored as read-only memmaped file.

# Memmap storage is disabled by default, to enable it, set this threshold to a reasonable value.

# To disable memmap storage, set this to `0`.

# Note: 1Kb = 1 vector of size 256 memmap_threshold : 200000 # Maximum size (in kilobytes) of vectors allowed for plain index, exceeding this threshold will enable vector indexing # Default value is 20,000, based on <https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md>.

# To disable vector indexing, set to `0`.

# Note: 1kB = 1 vector of size 256. indexing_threshold_kb : 20000 In addition to the configuration file, you can also set optimizer parameters separately for each collection .

Dynamic parameter updates may be useful, for example, for more efficient initial loading of points. You can disable indexing during the upload process with these settings and enable it immediately after it is finished. As a result, you will not waste extra computation resources on rebuilding the index.

================================================================================
PAGE 14/39
================================================================================
Title: Points
URL: https://qdrant.tech/documentation/concepts/points/
--------------------------------------------------------------------------------

Points The points are the central entity that Qdrant operates with.

A point is a record consisting of a vector and an optional payload .

It looks like this: // This is a simple point { "id" : 129 , "vector" : [ 0.1 , 0.2 , 0.3 , 0.4 ], "payload" : { "color" : "red" }, } You can search among the points grouped in one collection based on vector similarity.

This procedure is described in more detail in the search and filtering sections.

This section explains how to create and manage vectors.

Any point modification operation is asynchronous and takes place in 2 steps.

At the first stage, the operation is written to the Write-ahead-log.

After this moment, the service will not lose the data, even if the machine loses power supply.

Point IDs Qdrant supports using both 64-bit unsigned integers and UUID as identifiers for points.

Examples of UUID string representations: simple: 936DA01F9ABD4d9d80C702AF85C822A8 hyphenated: 550e8400-e29b-41d4-a716-446655440000 urn: urn:uuid:F9168C5E-CEB2-4faa-B6BF-329BF39FA1E4 That means that in every request UUID string could be used instead of numerical id.

Example: PUT /collections/{collection_name}/points { "points": [ { "id": "5c56c793-69f3-4fbf-87e6-c4bf54c28c26", "payload": {"color": "red"}, "vector": [0.9, 0.1, 0.1] } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" , payload = { "color" : "red" , }, vector = [ 0.9 , 0.1 , 0.1 ], ), ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" , payload : { color : "red" , }, vector : [ 0.9 , 0.1 , 0.1 ], }, ], }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" , vec!

[ 0.9 , 0.1 , 0.1 ], [( "color" , "Red" . into ())], )], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ; import java.util.UUID ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( UUID . fromString ( "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" ))) . setVectors ( vectors ( 0 .

05f , 0 .

61f , 0 .

76f , 0 .

74f )) . putAllPayload ( Map . of ( "color" , value ( "Red" ))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = Guid .

Parse ( "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" ), Vectors = new [] { 0.05f , 0.61f , 0.76f , 0.74f }, Payload = { [ "color" ] = "Red" } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewID ( "5c56c793-69f3-4fbf-87e6-c4bf54c28c26" ), Vectors : qdrant .

NewVectors ( 0.05 , 0.61 , 0.76 , 0.74 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "Red" }), }, }, }) and PUT /collections/{collection_name}/points { "points": [ { "id": 1, "payload": {"color": "red"}, "vector": [0.9, 0.1, 0.1] } ] } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , payload = { "color" : "red" , }, vector = [ 0.9 , 0.1 , 0.1 ], ), ], ) client . upsert ( "{collection_name}" , { points : [ { id : 1 , payload : { color : "red" , }, vector : [ 0.9 , 0.1 , 0.1 ], }, ], }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , vec!

[ 0.9 , 0.1 , 0.1 ], [( "color" , "Red" . into ())], )], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

05f , 0 .

61f , 0 .

76f , 0 .

74f )) . putAllPayload ( Map . of ( "color" , value ( "Red" ))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new [] { 0.05f , 0.61f , 0.76f , 0.74f }, Payload = { [ "color" ] = "Red" } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.05 , 0.61 , 0.76 , 0.74 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "Red" }), }, }, }) are both possible.

Vectors Each point in qdrant may have one or more vectors.

Vectors are the central component of the Qdrant architecture, qdrant relies on different types of vectors to provide different types of data exploration and search.

Here is a list of supported vector types: Dense Vectors A regular vectors, generated by majority of the embedding models.

Sparse Vectors Vectors with no fixed length, but only a few non-zero elements.

Useful for exact token match and collaborative filtering recommendations.

MultiVectors Matrices of numbers with fixed length but variable height.

Usually obtained from late interaction models like ColBERT.

It is possible to attach more than one type of vector to a single point.

In Qdrant we call these Named Vectors.

Read more about vector types, how they are stored and optimized in the vectors section.

Upload points To optimize performance, Qdrant supports batch loading of points. I.e., you can load several points into the service in one API call.

Batching allows you to minimize the overhead of creating a network connection.

The Qdrant API supports two ways of creating batches - record-oriented and column-oriented.

Internally, these options do not differ and are made only for the convenience of interaction.

Create points with batch: PUT /collections/{collection_name}/points { "batch": { "ids": [1, 2, 3], "payloads": [ {"color": "red"}, {"color": "green"}, {"color": "blue"} ], "vectors": [ [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9] ] } } client . upsert ( collection_name = " {collection_name} " , points = models .

Batch ( ids = [ 1 , 2 , 3 ], payloads = [ { "color" : "red" }, { "color" : "green" }, { "color" : "blue" }, ], vectors = [ [ 0.9 , 0.1 , 0.1 ], [ 0.1 , 0.9 , 0.1 ], [ 0.1 , 0.1 , 0.9 ], ], ), ) client . upsert ( "{collection_name}" , { batch : { ids : [ 1 , 2 , 3 ], payloads : [{ color : "red" }, { color : "green" }, { color : "blue" }], vectors : [ [ 0.9 , 0.1 , 0.1 ], [ 0.1 , 0.9 , 0.1 ], [ 0.1 , 0.1 , 0.9 ], ], }, }); or record-oriented equivalent: PUT /collections/{collection_name}/points { "points": [ { "id": 1, "payload": {"color": "red"}, "vector": [0.9, 0.1, 0.1] }, { "id": 2, "payload": {"color": "green"}, "vector": [0.1, 0.9, 0.1] }, { "id": 3, "payload": {"color": "blue"}, "vector": [0.1, 0.1, 0.9] } ] } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , payload = { "color" : "red" , }, vector = [ 0.9 , 0.1 , 0.1 ], ), models .

PointStruct ( id = 2 , payload = { "color" : "green" , }, vector = [ 0.1 , 0.9 , 0.1 ], ), models .

PointStruct ( id = 3 , payload = { "color" : "blue" , }, vector = [ 0.1 , 0.1 , 0.9 ], ), ], ) client . upsert ( "{collection_name}" , { points : [ { id : 1 , payload : { color : "red" }, vector : [ 0.9 , 0.1 , 0.1 ], }, { id : 2 , payload : { color : "green" }, vector : [ 0.1 , 0.9 , 0.1 ], }, { id : 3 , payload : { color : "blue" }, vector : [ 0.1 , 0.1 , 0.9 ], }, ], }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , vec!

[ 0.9 , 0.1 , 0.1 ], [( "city" , "red" . into ())]), PointStruct :: new ( 2 , vec!

[ 0.1 , 0.9 , 0.1 ], [( "city" , "green" . into ())]), PointStruct :: new ( 3 , vec!

[ 0.1 , 0.1 , 0.9 ], [( "city" , "blue" . into ())]), ], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

9f , 0 .

1f , 0 .

1f )) . putAllPayload ( Map . of ( "color" , value ( "red" ))) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( vectors ( 0 .

1f , 0 .

9f , 0 .

1f )) . putAllPayload ( Map . of ( "color" , value ( "green" ))) . build (), PointStruct . newBuilder () . setId ( id ( 3 )) . setVectors ( vectors ( 0 .

1f , 0 .

1f , 0 .

9f )) . putAllPayload ( Map . of ( "color" , value ( "blue" ))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new [] { 0.9f , 0.1f , 0.1f }, Payload = { [ "color" ] = "red" } }, new () { Id = 2 , Vectors = new [] { 0.1f , 0.9f , 0.1f }, Payload = { [ "color" ] = "green" } }, new () { Id = 3 , Vectors = new [] { 0.1f , 0.1f , 0.9f }, Payload = { [ "color" ] = "blue" } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.9 , 0.1 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "red" }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.9 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "green" }), }, { Id : qdrant .

NewIDNum ( 3 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.1 , 0.9 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "blue" }), }, }, }) Python client optimizations The Python client has additional features for loading points, which include: Parallelization A retry mechanism Lazy batching support For example, you can read your data directly from hard drives, to avoid storing all data in RAM. You can use these features with the upload_collection and upload_points methods.

Similar to the basic upsert API, these methods support both record-oriented and column-oriented formats.

Column-oriented format: client . upload_collection ( collection_name = " {collection_name} " , ids = [ 1 , 2 ], payload = [ { "color" : "red" }, { "color" : "green" }, ], vectors = [ [ 0.9 , 0.1 , 0.1 ], [ 0.1 , 0.9 , 0.1 ], ], parallel = 4 , max_retries = 3 , ) Record-oriented format: client . upload_points ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , payload = { "color" : "red" , }, vector = [ 0.9 , 0.1 , 0.1 ], ), models .

PointStruct ( id = 2 , payload = { "color" : "green" , }, vector = [ 0.1 , 0.9 , 0.1 ], ), ], parallel = 4 , max_retries = 3 , ) Idempotence All APIs in Qdrant, including point loading, are idempotent.

It means that executing the same method several times in a row is equivalent to a single execution.

In this case, it means that points with the same id will be overwritten when re-uploaded.

Idempotence property is useful if you use, for example, a message queue that doesn‚Äôt provide an exactly-once guarantee.

Even with such a system, Qdrant ensures data consistency.

Named vectors Available as of v0.10.0 If the collection was created with multiple vectors, each vector data can be provided using the vector‚Äôs name: PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": { "image": [0.9, 0.1, 0.1, 0.2], "text": [0.4, 0.7, 0.1, 0.8, 0.1, 0.1, 0.9, 0.2] } }, { "id": 2, "vector": { "image": [0.2, 0.1, 0.3, 0.9], "text": [0.5, 0.2, 0.7, 0.4, 0.7, 0.2, 0.3, 0.9] } } ] } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "image" : [ 0.9 , 0.1 , 0.1 , 0.2 ], "text" : [ 0.4 , 0.7 , 0.1 , 0.8 , 0.1 , 0.1 , 0.9 , 0.2 ], }, ), models .

PointStruct ( id = 2 , vector = { "image" : [ 0.2 , 0.1 , 0.3 , 0.9 ], "text" : [ 0.5 , 0.2 , 0.7 , 0.4 , 0.7 , 0.2 , 0.3 , 0.9 ], }, ), ], ) client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { image : [ 0.9 , 0.1 , 0.1 , 0.2 ], text : [ 0.4 , 0.7 , 0.1 , 0.8 , 0.1 , 0.1 , 0.9 , 0.2 ], }, }, { id : 2 , vector : { image : [ 0.2 , 0.1 , 0.3 , 0.9 ], text : [ 0.5 , 0.2 , 0.7 , 0.4 , 0.7 , 0.2 , 0.3 , 0.9 ], }, }, ], }); use std :: collections :: HashMap ; use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Payload ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , HashMap :: from ([ ( "image" . to_string (), vec!

[ 0.9 , 0.1 , 0.1 , 0.2 ]), ( "text" . to_string (), vec!

[ 0.4 , 0.7 , 0.1 , 0.8 , 0.1 , 0.1 , 0.9 , 0.2 ], ), ]), Payload :: default (), ), PointStruct :: new ( 2 , HashMap :: from ([ ( "image" . to_string (), vec!

[ 0.2 , 0.1 , 0.3 , 0.9 ]), ( "text" . to_string (), vec!

[ 0.5 , 0.2 , 0.7 , 0.4 , 0.7 , 0.2 , 0.3 , 0.9 ], ), ]), Payload :: default (), ), ], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ; client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "image" , vector ( List . of ( 0 .

9f , 0 .

1f , 0 .

1f , 0 .

2f )), "text" , vector ( List . of ( 0 .

4f , 0 .

7f , 0 .

1f , 0 .

8f , 0 .

1f , 0 .

1f , 0 .

9f , 0 .

2f ))))) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( namedVectors ( Map . of ( "image" , vector ( List . of ( 0 .

2f , 0 .

1f , 0 .

3f , 0 .

9f )), "text" , vector ( List . of ( 0 .

5f , 0 .

2f , 0 .

7f , 0 .

4f , 0 .

7f , 0 .

2f , 0 .

3f , 0 .

9f ))))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , float []> { ["image"] = [ 0.9f , 0.1f , 0.1f , 0.2f ], ["text"] = [ 0.4f , 0.7f , 0.1f , 0.8f , 0.1f , 0.1f , 0.9f , 0.2f ] } }, new () { Id = 2 , Vectors = new Dictionary < string , float []> { ["image"] = [ 0.2f , 0.1f , 0.3f , 0.9f ], ["text"] = [ 0.5f , 0.2f , 0.7f , 0.4f , 0.7f , 0.2f , 0.3f , 0.9f ] } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "image" : qdrant .

NewVector ( 0.9 , 0.1 , 0.1 , 0.2 ), "text" : qdrant .

NewVector ( 0.4 , 0.7 , 0.1 , 0.8 , 0.1 , 0.1 , 0.9 , 0.2 ), }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "image" : qdrant .

NewVector ( 0.2 , 0.1 , 0.3 , 0.9 ), "text" : qdrant .

NewVector ( 0.5 , 0.2 , 0.7 , 0.4 , 0.7 , 0.2 , 0.3 , 0.9 ), }), }, }, }) Available as of v1.2.0 Named vectors are optional. When uploading points, some vectors may be omitted.

For example, you can upload one point with only the image vector and a second one with only the text vector.

When uploading a point with an existing ID, the existing point is deleted first, then it is inserted with just the specified vectors. In other words, the entire point is replaced, and any unspecified vectors are set to null. To keep existing vectors unchanged and only update specified vectors, see update vectors .

Sparse vectors Available as of v1.7.0 Points can contain dense and sparse vectors.

A sparse vector is an array in which most of the elements have a value of zero.

It is possible to take advantage of this property to have an optimized representation, for this reason they have a different shape than dense vectors.

They are represented as a list of (index, value) pairs, where index is an integer and value is a floating point number. The index is the position of the non-zero value in the vector. The values is the value of the non-zero element.

For example, the following vector: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0] can be represented as a sparse vector: [(6, 1.0), (7, 2.0)] Qdrant uses the following JSON representation throughout its APIs.

{ "indices" : [ 6 , 7 ], "values" : [ 1.0 , 2.0 ] } The indices and values arrays must have the same length.

And the indices must be unique.

If the indices are not sorted, Qdrant will sort them internally so you may not rely on the order of the elements.

Sparse vectors must be named and can be uploaded in the same way as dense vectors.

PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": { "text": { "indices": [6, 7], "values": [1.0, 2.0] } } }, { "id": 2, "vector": { "text": { "indices": [1, 2, 4, 15, 33, 34], "values": [0.1, 0.2, 0.3, 0.4, 0.5] } } } ] } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "text" : models .

SparseVector ( indices = [ 6 , 7 ], values = [ 1.0 , 2.0 ], ) }, ), models .

PointStruct ( id = 2 , vector = { "text" : models .

SparseVector ( indices = [ 1 , 2 , 3 , 4 , 5 ], values = [ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 ], ) }, ), ], ) client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { text : { indices : [ 6 , 7 ], values : [ 1.0 , 2.0 ], }, }, }, { id : 2 , vector : { text : { indices : [ 1 , 2 , 3 , 4 , 5 ], values : [ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 ], }, }, }, ], }); use std :: collections :: HashMap ; use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Payload ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , HashMap :: from ([( "text" . to_string (), vec!

[( 6 , 1.0 ), ( 7 , 2.0 )])]), Payload :: default (), ), PointStruct :: new ( 2 , HashMap :: from ([( "text" . to_string (), vec!

[( 1 , 0.1 ), ( 2 , 0.2 ), ( 3 , 0.3 ), ( 4 , 0.4 ), ( 5 , 0.5 )], )]), Payload :: default (), ), ], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.VectorFactory.vector ; import io.qdrant.client.grpc.Points.NamedVectors ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.Vectors ; import java.util.List ; import java.util.Map ; client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( Vectors . newBuilder () . setVectors ( NamedVectors . newBuilder () . putAllVectors ( Map . of ( "text" , vector ( List . of ( 1 .

0f , 2 .

0f ), List . of ( 6 , 7 )))) . build ()) . build ()) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( Vectors . newBuilder () . setVectors ( NamedVectors . newBuilder () . putAllVectors ( Map . of ( "text" , vector ( List . of ( 0 .

1f , 0 .

2f , 0 .

3f , 0 .

4f , 0 .

5f ), List . of ( 1 , 2 , 3 , 4 , 5 )))) . build ()) . build ()) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , Vector > { [ "text" ] = ([ 1.0f , 2.0f ], [ 6 , 7 ]) } }, new () { Id = 2 , Vectors = new Dictionary < string , Vector > { ["text"] = ([ 0.1f , 0.2f , 0.3f , 0.4f , 0.5f ], [ 1 , 2 , 3 , 4 , 5 ]) } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "text" : qdrant .

NewVectorSparse ( [] uint32 { 6 , 7 }, [] float32 { 1.0 , 2.0 }), }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "text" : qdrant .

NewVectorSparse ( [] uint32 { 1 , 2 , 3 , 4 , 5 }, [] float32 { 0.1 , 0.2 , 0.3 , 0.4 , 0.5 }), }), }, }, }) Inference Instead of providing vectors explicitly, Qdrant can also generate vectors using a process called inference . Inference is the process of creating vector embeddings from text, images, or other data types using a machine learning model.

You can use inference in the API wherever you can use regular vectors. For example, while upserting points, you can provide the text or image and the embedding model: PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": { "my-bm25-vector": { "text": "Recipe for baking chocolate chip cookies", "model": "qdrant/bm25" } } } ] } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "https://xyz-example.qdrant.io:6333" , api_key = "<your-api-key>" , cloud_inference = True ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = { "my-bm25-vector" : models .

Document ( text = "Recipe for baking chocolate chip cookies" , model = "Qdrant/bm25" , ) }, ) ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : { 'my-bm25-vector' : { text : 'Recipe for baking chocolate chip cookies' , model : 'Qdrant/bm25' , }, }, }, ], }); use qdrant_client :: { Payload , Qdrant , qdrant :: { DocumentBuilder , PointStruct , UpsertPointsBuilder }, }; use std :: collections :: HashMap ; let client = Qdrant :: from_url ( "<your-qdrant-url>" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , HashMap :: from ([( "my-bm25-vector" . to_string (), DocumentBuilder :: new ( "Recipe for baking chocolate chip cookies" , "qdrant/bm25" ) . build (), )]), Payload :: default (), )], )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.Document ; import io.qdrant.client.grpc.Points.Image ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.qdrant.io" , 6334 , true ) . withApiKey ( "<your-api-key" ) . build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "my-bm25-vector" , vector ( Document . newBuilder () . setModel ( "qdrant/bm25" ) . setText ( "Recipe for baking chocolate chip cookies" ) . build ())))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( host : "xyz-example.qdrant.io" , port : 6334 , https : true , apiKey : "<your-api-key>" ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new Dictionary < string , Vector > { ["my-bm25-vector"] = new Document () { Model = "qdrant/bm25" , Text = "Recipe for baking chocolate chip cookies" , }, }, }, } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( uint64 ( 1 )), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "my-bm25-vector" : qdrant .

NewVectorDocument ( & qdrant .

Document { Model : "qdrant/bm25" , Text : "Recipe for baking chocolate chip cookies" , }), }), }, }, }) Qdrant uses the model to generate the embeddings and store the point with the resulting vector.

Modify points To change a point, you can modify its vectors or its payload. There are several ways to do this.

Update vectors Available as of v1.2.0 This method updates the specified vectors on the given points. Unspecified vectors are kept unchanged. All given points must exist.

REST API ( Schema ): PUT /collections/{collection_name}/points/vectors { "points": [ { "id": 1, "vector": { "image": [0.1, 0.2, 0.3, 0.4] } }, { "id": 2, "vector": { "text": [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2] } } ] } client . update_vectors ( collection_name = " {collection_name} " , points = [ models .

PointVectors ( id = 1 , vector = { "image" : [ 0.1 , 0.2 , 0.3 , 0.4 ], }, ), models .

PointVectors ( id = 2 , vector = { "text" : [ 0.9 , 0.8 , 0.7 , 0.6 , 0.5 , 0.4 , 0.3 , 0.2 ], }, ), ], ) client . updateVectors ( "{collection_name}" , { points : [ { id : 1 , vector : { image : [ 0.1 , 0.2 , 0.3 , 0.4 ], }, }, { id : 2 , vector : { text : [ 0.9 , 0.8 , 0.7 , 0.6 , 0.5 , 0.4 , 0.3 , 0.2 ], }, }, ], }); use std :: collections :: HashMap ; use qdrant_client :: qdrant :: { PointVectors , UpdatePointVectorsBuilder , }; client . update_vectors ( UpdatePointVectorsBuilder :: new ( "{collection_name}" , vec!

[ PointVectors { id : Some ( 1. into ()), vectors : Some ( HashMap :: from ([( "image" . to_string (), vec!

[ 0.1 , 0.2 , 0.3 , 0.4 ])]). into (), ), }, PointVectors { id : Some ( 2. into ()), vectors : Some ( HashMap :: from ([( "text" . to_string (), vec!

[ 0.9 , 0.8 , 0.7 , 0.6 , 0.5 , 0.4 , 0.3 , 0.2 ], )]) . into (), ), }, ], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.VectorFactory.vector ; import static io.qdrant.client.VectorsFactory.namedVectors ; import io.qdrant.client.grpc.Points.PointVectors ; import java.util.List ; import java.util.Map ; client . updateVectorsAsync ( "{collection_name}" , List . of ( PointVectors . newBuilder () . setId ( id ( 1 )) . setVectors ( namedVectors ( Map . of ( "image" , vector ( List . of ( 0 .

1f , 0 .

2f , 0 .

3f , 0 .

4f ))))) . build (), PointVectors . newBuilder () . setId ( id ( 2 )) . setVectors ( namedVectors ( Map . of ( "text" , vector ( List . of ( 0 .

9f , 0 .

8f , 0 .

7f , 0 .

6f , 0 .

5f , 0 .

4f , 0 .

3f , 0 .

2f ))))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateVectorsAsync ( collectionName : "{collection_name}" , points : new List < PointVectors > { new () { Id = 1 , Vectors = ( "image" , new float [] { 0.1f , 0.2f , 0.3f , 0.4f }) }, new () { Id = 2 , Vectors = ( "text" , new float [] { 0.9f , 0.8f , 0.7f , 0.6f , 0.5f , 0.4f , 0.3f , 0.2f }) } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateVectors ( context .

Background (), & qdrant .

UpdatePointVectors { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointVectors { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "image" : qdrant .

NewVector ( 0.1 , 0.2 , 0.3 , 0.4 ), }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectorsMap ( map [ string ] * qdrant .

Vector { "text" : qdrant .

NewVector ( 0.9 , 0.8 , 0.7 , 0.6 , 0.5 , 0.4 , 0.3 , 0.2 ), }), }, }, }) To update points and replace all of its vectors, see uploading points .

Delete vectors Available as of v1.2.0 This method deletes just the specified vectors from the given points. Other vectors are kept unchanged. Points are never deleted.

REST API ( Schema ): POST /collections/{collection_name}/points/vectors/delete { "points": [0, 3, 100], "vectors": ["text", "image"] } client . delete_vectors ( collection_name = " {collection_name} " , points = [ 0 , 3 , 100 ], vectors = [ "text" , "image" ], ) client . deleteVectors ( "{collection_name}" , { points : [ 0 , 3 , 10 ], vector : [ "text" , "image" ], }); use qdrant_client :: qdrant :: { DeletePointVectorsBuilder , PointsIdsList , }; client . delete_vectors ( DeletePointVectorsBuilder :: new ( "{collection_name}" ) . points_selector ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 10. into ()], }) . vectors ( vec!

[ "text" . into (), "image" . into ()]) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import java.util.List ; client . deleteVectorsAsync ( "{collection_name}" , List . of ( "text" , "image" ), List . of ( id ( 0 ), id ( 3 ), id ( 10 ))) . get (); await client .

DeleteVectorsAsync ( "{collection_name}" , [ "text" , "image" ], [ 0 , 3 , 10 ]); import ( "context" "github.com/qdrant/go-client/qdrant" ) client .

DeleteVectors ( context .

Background (), & qdrant .

DeletePointVectors { CollectionName : "{collection_name}" , PointsSelector : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 ), qdrant .

NewIDNum ( 10 )), Vectors : & qdrant .

VectorsSelector { Names : [] string { "text" , "image" }, }, }) To delete entire points, see deleting points .

Update payload Learn how to modify the payload of a point in the Payload section.

Delete points REST API ( Schema ): POST /collections/{collection_name}/points/delete { "points": [0, 3, 100] } client . delete ( collection_name = " {collection_name} " , points_selector = models .

PointIdsList ( points = [ 0 , 3 , 100 ], ), ) client . delete ( "{collection_name}" , { points : [ 0 , 3 , 100 ], }); use qdrant_client :: qdrant :: { DeletePointsBuilder , PointsIdsList }; client . delete_points ( DeletePointsBuilder :: new ( "{collection_name}" ) . points ( PointsIdsList { ids : vec !

[ 0. into (), 3. into (), 100. into ()], }) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import java.util.List ; client . deleteAsync ( "{collection_name}" , List . of ( id ( 0 ), id ( 3 ), id ( 100 ))); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeleteAsync ( collectionName : "{collection_name}" , ids : ( ulong [])[ 0 , 3 , 100 ]); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Delete ( context .

Background (), & qdrant .

DeletePoints { CollectionName : "{collection_name}" , Points : qdrant .

NewPointsSelector ( qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 ), qdrant .

NewIDNum ( 100 ), ), }) Alternative way to specify which points to remove is to use filter.

POST /collections/{collection_name}/points/delete { "filter": { "must": [ { "key": "color", "match": { "value": "red" } } ] } } client . delete ( collection_name = " {collection_name} " , points_selector = models .

FilterSelector ( filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" ), ), ], ) ), ) client . delete ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, }); use qdrant_client :: qdrant :: { Condition , DeletePointsBuilder , Filter }; client . delete_points ( DeletePointsBuilder :: new ( "{collection_name}" ) . points ( Filter :: must ([ Condition :: matches ( "color" , "red" . to_string (), )])) . wait ( true ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; client . deleteAsync ( "{collection_name}" , Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeleteAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "color" , "red" )); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Delete ( context .

Background (), & qdrant .

DeletePoints { CollectionName : "{collection_name}" , Points : qdrant .

NewPointsSelectorFilter ( & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, ), }) This example removes all points with { "color": "red" } from the collection.

Conditional updates Available as of v1.16.0 All update operations (including point insertion, vector updates, payload updates, and deletions) support configurable pre-conditions based on filters.

PUT /collections/{collection_name}/points { "points": [ { "id": 1, "vector": [0.05, 0.61, 0.76, 0.74], "payload": { "city": "Berlin", "price": 1.99, "version": 3 } } ], "update_filter": { "must": [ { "key": "version", "match": { "value": 2 } } ] } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , vector = [ 0.05 , 0.61 , 0.76 , 0.74 ], payload = { "city" : "Berlin" , "price" : 1.99 , "version" : 3 , }, ), ], update_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "version" , match = models .

MatchValue ( value = 2 ), ), ], ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , vector : [ 0.05 , 0.61 , 0.76 , 0.74 ], payload : { city : "Berlin" , price : 1.99 , version : 3 }, } ], update_filter : { must : [ { key : "version" , match : { value : 2 } } ] } }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder , Filter , Condition }; use qdrant_client :: { Payload , Qdrant }; use serde_json :: json ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let points = vec!

[ PointStruct :: new ( 1 , vec!

[ 0.05 , 0.61 , 0.76 , 0.74 ], Payload :: try_from ( json!

({ "city" : "Berlin" , "price" : 1.99 , "version" : 3 })). unwrap (), ) ]; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , points ) . wait ( true ) . update_filter ( Filter :: must ([ Condition :: matches ( "version" , 2 )])) ). await ? ; import static io.qdrant.client.ConditionFactory.match ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.UpsertPoints ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( UpsertPoints . newBuilder () . setCollectionName ( "{collectionName}" ) . addPoints ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

05f , 0 .

61f , 0 .

76f , 0 .

74f )) . putAllPayload ( Map . of ( "city" , value ( "Berlin" ), "price" , value ( 1 .

99 ))) . build ()) . setUpdateFilter ( Filter . newBuilder (). addMust ( match ( "version" , 2 )). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new PointStruct { Id = 1 , Vectors = new [] { 0.05f , 0.61f , 0.76f , 0.74f }, Payload = { ["city"] = "Berlin" , ["price"] = 1.99 , ["version"] = 3 } } }, updateFilter : Match ( "version" , 2 ) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.05 , 0.61 , 0.76 , 0.74 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "city" : "Berlin" , "price" : 1.99 , "version" : 3 }), }, }, UpdateFilter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatchInt ( "version" , 2 ), }, }, }) While conditional payload modification and deletion covers the use-case of mass data modification, conditional point insertion and vector updates are particularly useful for implementing optimistic concurrency control in distributed systems.

A common scenario for such mechanism is when multiple clients try to update the same point independently.

Consider the following sequence of events: Client A reads point P.

Client B reads point P.

Client A modifies point P and writes it back to Qdrant.

Client B modifies point P (based on the stale data) and writes it back to Qdrant, unintentionally overwriting changes made by Client A.

To prevent such situations, Client B can use conditional updates.

For this, we would need to introduce an additional field in the payload, e.g. version , which would be incremented on each update.

When Client A writes back the modified point P, it would set the condition that the version field must be equal to the value it read initially.

If Client B tries to write back its changes later, the condition would fail (as the version has been incremented by Client A), and Qdrant would reject the update, preventing accidental overwrites.

Instead of version , applications can use timestamps (assuming synchronized clocks) or any other monotonically increasing value that fits their data model.

This mechanism is especially useful in the scenarios of embedding model migration, where we need to resolve conflicts between regular application updates and background re-embedding tasks.

Embedding model migration in blue-green deployment Retrieve points There is a method for retrieving points by their ids.

REST API ( Schema ): POST /collections/{collection_name}/points { "ids": [0, 3, 100] } client . retrieve ( collection_name = " {collection_name} " , ids = [ 0 , 3 , 100 ], ) client . retrieve ( "{collection_name}" , { ids : [ 0 , 3 , 100 ], }); use qdrant_client :: qdrant :: GetPointsBuilder ; client . get_points ( GetPointsBuilder :: new ( "{collection_name}" , vec!

[ 0. into (), 30. into (), 100. into ()], )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import java.util.List ; client . retrieveAsync ( "{collection_name}" , List . of ( id ( 0 ), id ( 30 ), id ( 100 )), false , false , null ) . get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

RetrieveAsync ( collectionName : "{collection_name}" , ids : [ 0 , 30 , 100 ], withPayload : false , withVectors : false ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Get ( context .

Background (), & qdrant .

GetPoints { CollectionName : "{collection_name}" , Ids : [] * qdrant .

PointId { qdrant .

NewIDNum ( 0 ), qdrant .

NewIDNum ( 3 ), qdrant .

NewIDNum ( 100 ), }, }) This method has additional parameters with_vectors and with_payload .

Using these parameters, you can select parts of the point you want as a result.

Excluding helps you not to waste traffic transmitting useless data.

The single point can also be retrieved via the API: REST API ( Schema ): GET /collections/{collection_name}/points/{point_id} Scroll points Sometimes it might be necessary to get all stored points without knowing ids, or iterate over points that correspond to a filter.

REST API ( Schema ): POST /collections/{collection_name}/points/scroll { "filter": { "must": [ { "key": "color", "match": { "value": "red" } } ] }, "limit": 1, "with_payload": true, "with_vector": false } client . scroll ( collection_name = " {collection_name} " , scroll_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" )), ] ), limit = 1 , with_payload = True , with_vectors = False , ) client . scroll ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, limit : 1 , with_payload : true , with_vector : false , }); use qdrant_client :: qdrant :: { Condition , Filter , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ) . filter ( Filter :: must ([ Condition :: matches ( "color" , "red" . to_string (), )])) . limit ( 1 ) . with_payload ( true ) . with_vectors ( false ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.WithPayloadSelectorFactory.enable ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build ()) . setLimit ( 1 ) . setWithPayload ( enable ( true )) . build ()) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ScrollAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "color" , "red" ), limit : 1 , payloadSelector : true ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, Limit : qdrant .

PtrOf ( uint32 ( 1 )), WithPayload : qdrant .

NewWithPayload ( true ), }) Returns all point with color = red .

{ "result" : { "next_page_offset" : 1 , "points" : [ { "id" : 0 , "payload" : { "color" : "red" } } ] }, "status" : "ok" , "time" : 0.0001 } The Scroll API will return all points that match the filter in a page-by-page manner.

All resulting points are sorted by ID. To query the next page it is necessary to specify the largest seen ID in the offset field.

For convenience, this ID is also returned in the field next_page_offset .

If the value of the next_page_offset field is null - the last page is reached.

Order points by payload key Available as of v1.8.0 When using the scroll API, you can sort the results by payload key. For example, you can retrieve points in chronological order if your payloads have a "timestamp" field, as is shown from the example below: POST /collections/{collection_name}/points/scroll { "limit": 15, "order_by": "timestamp", // <-- this!

} client . scroll ( collection_name = " {collection_name} " , limit = 15 , order_by = "timestamp" , # <-- this! ) client . scroll ( "{collection_name}" , { limit : 15 , order_by : "timestamp" , // <-- this!

}); use qdrant_client :: qdrant :: { OrderByBuilder , ScrollPointsBuilder }; client . scroll ( ScrollPointsBuilder :: new ( "{collection_name}" ) . limit ( 15 ) . order_by ( OrderByBuilder :: new ( "timestamp" )), ) . await ? ; import io.qdrant.client.grpc.Points.OrderBy ; import io.qdrant.client.grpc.Points.ScrollPoints ; client . scrollAsync ( ScrollPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setLimit ( 15 ) . setOrderBy ( OrderBy . newBuilder (). setKey ( "timestamp" ). build ()) . build ()). get (); await client .

ScrollAsync ( "{collection_name}" , limit : 15 , orderBy : "timestamp" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Scroll ( context .

Background (), & qdrant .

ScrollPoints { CollectionName : "{collection_name}" , Limit : qdrant .

PtrOf ( uint32 ( 15 )), OrderBy : & qdrant .

OrderBy { Key : "timestamp" , }, }) You need to use the order_by key parameter to specify the payload key. Then you can add other fields to control the ordering, such as direction and start_from : "order_by": { "key": "timestamp", "direction": "desc" // default is "asc" "start_from": 123, // start from this value } order_by = models .

OrderBy ( key = "timestamp" , direction = models .

Direction .

DESC , # default is "ASC" start_from = 123 , # start from this value ) order_by : { key : "timestamp" , direction : "desc" , // default is "asc" start_from : 123 , // start from this value } use qdrant_client :: qdrant :: { start_from :: Value , Direction , OrderByBuilder };

OrderByBuilder :: new ( "timestamp" ) . direction ( Direction :: Desc . into ()) . start_from ( Value :: Integer ( 123 )) . build (); import io.qdrant.client.grpc.Points.Direction ; import io.qdrant.client.grpc.Points.OrderBy ; import io.qdrant.client.grpc.Points.StartFrom ;

OrderBy . newBuilder () . setKey ( "timestamp" ) . setDirection ( Direction .

Desc ) . setStartFrom ( StartFrom . newBuilder () . setInteger ( 123 ) . build ()) . build (); using Qdrant.Client.Grpc ; new OrderBy { Key = "timestamp" , Direction = Direction .

Desc , StartFrom = 123 }; import "github.com/qdrant/go-client/qdrant" qdrant .

OrderBy { Key : "timestamp" , Direction : qdrant .

Direction_Desc .

Enum (), StartFrom : qdrant .

NewStartFromInt ( 123 ), } When sorting is based on a non-unique value, it is not possible to rely on an ID offset. Thus, next_page_offset is not returned within the response. However, you can still do pagination by combining "order_by": { "start_from": ... } with a { "must_not": [{ "has_id": [...] }] } filter.

Counting points Available as of v0.8.4 Sometimes it can be useful to know how many points fit the filter conditions without doing a real search.

Among others, for example, we can highlight the following scenarios: Evaluation of results size for faceted search Determining the number of pages for pagination Debugging the query execution speed REST API ( Schema ): POST /collections/{collection_name}/points/count { "filter": { "must": [ { "key": "color", "match": { "value": "red" } } ] }, "exact": true } client . count ( collection_name = " {collection_name} " , count_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "color" , match = models .

MatchValue ( value = "red" )), ] ), exact = True , ) client . count ( "{collection_name}" , { filter : { must : [ { key : "color" , match : { value : "red" , }, }, ], }, exact : true , }); use qdrant_client :: qdrant :: { Condition , CountPointsBuilder , Filter }; client . count ( CountPointsBuilder :: new ( "{collection_name}" ) . filter ( Filter :: must ([ Condition :: matches ( "color" , "red" . to_string (), )])) . exact ( true ), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import io.qdrant.client.grpc.Common.Filter ; client . countAsync ( "{collection_name}" , Filter . newBuilder (). addMust ( matchKeyword ( "color" , "red" )). build (), true ) . get (); using Qdrant.Client ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CountAsync ( collectionName : "{collection_name}" , filter : MatchKeyword ( "color" , "red" ), exact : true ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Count ( context .

Background (), & qdrant .

CountPoints { CollectionName : "midlib" , Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "color" , "red" ), }, }, }) Returns number of counts matching given filtering conditions: { "count" : 3811 } Batch update Available as of v1.5.0 You can batch multiple point update operations. This includes inserting, updating and deleting points, vectors and payload.

A batch update request consists of a list of operations. These are executed in order. These operations can be batched: Upsert points : upsert or UpsertOperation Delete points : delete_points or DeleteOperation Update vectors : update_vectors or UpdateVectorsOperation Delete vectors : delete_vectors or DeleteVectorsOperation Set payload : set_payload or SetPayloadOperation Overwrite payload : overwrite_payload or OverwritePayload Delete payload : delete_payload or DeletePayloadOperation Clear payload : clear_payload or ClearPayloadOperation The following example snippet makes use of all operations.

REST API ( Schema ): POST /collections/{collection_name}/points/batch { "operations": [ { "upsert": { "points": [ { "id": 1, "vector": [1.0, 2.0, 3.0, 4.0], "payload": {} } ] } }, { "update_vectors": { "points": [ { "id": 1, "vector": [1.0, 2.0, 3.0, 4.0] } ] } }, { "delete_vectors": { "points": [1], "vector": [""] } }, { "overwrite_payload": { "payload": { "test_payload": "1" }, "points": [1] } }, { "set_payload": { "payload": { "test_payload_2": "2", "test_payload_3": "3" }, "points": [1] } }, { "delete_payload": { "keys": ["test_payload_2"], "points": [1] } }, { "clear_payload": { "points": [1] } }, {"delete": {"points": [1]}} ] } client . batch_update_points ( collection_name = " {collection_name} " , update_operations = [ models .

UpsertOperation ( upsert = models .

PointsList ( points = [ models .

PointStruct ( id = 1 , vector = [ 1.0 , 2.0 , 3.0 , 4.0 ], payload = {}, ), ] ) ), models .

UpdateVectorsOperation ( update_vectors = models .

UpdateVectors ( points = [ models .

PointVectors ( id = 1 , vector = [ 1.0 , 2.0 , 3.0 , 4.0 ], ) ] ) ), models .

DeleteVectorsOperation ( delete_vectors = models .

DeleteVectors ( points = [ 1 ], vector = [ "" ]) ), models .

OverwritePayloadOperation ( overwrite_payload = models .

SetPayload ( payload = { "test_payload" : 1 }, points = [ 1 ], ) ), models .

SetPayloadOperation ( set_payload = models .

SetPayload ( payload = { "test_payload_2" : 2 , "test_payload_3" : 3 , }, points = [ 1 ], ) ), models .

DeletePayloadOperation ( delete_payload = models .

DeletePayload ( keys = [ "test_payload_2" ], points = [ 1 ]) ), models .

ClearPayloadOperation ( clear_payload = models .

PointIdsList ( points = [ 1 ])), models .

DeleteOperation ( delete = models .

PointIdsList ( points = [ 1 ])), ], ) client . batchUpdate ( "{collection_name}" , { operations : [ { upsert : { points : [ { id : 1 , vector : [ 1.0 , 2.0 , 3.0 , 4.0 ], payload : {}, }, ], }, }, { update_vectors : { points : [ { id : 1 , vector : [ 1.0 , 2.0 , 3.0 , 4.0 ], }, ], }, }, { delete_vectors : { points : [ 1 ], vector : [ "" ], }, }, { overwrite_payload : { payload : { test_payload : 1 , }, points : [ 1 ], }, }, { set_payload : { payload : { test_payload_2 : 2 , test_payload_3 : 3 , }, points : [ 1 ], }, }, { delete_payload : { keys : [ "test_payload_2" ], points : [ 1 ], }, }, { clear_payload : { points : [ 1 ], }, }, { delete : { points : [ 1 ], }, }, ], }); use std :: collections :: HashMap ; use qdrant_client :: qdrant :: { points_update_operation :: { ClearPayload , DeletePayload , DeletePoints , DeleteVectors , Operation , OverwritePayload , PointStructList , SetPayload , UpdateVectors , }, PointStruct , PointVectors , PointsUpdateOperation , UpdateBatchPointsBuilder , VectorsSelector , }; use qdrant_client :: Payload ; client . update_points_batch ( UpdateBatchPointsBuilder :: new ( "{collection_name}" , vec!

[ PointsUpdateOperation { operation : Some ( Operation :: Upsert ( PointStructList { points : vec !

[ PointStruct :: new ( 1 , vec!

[ 1.0 , 2.0 , 3.0 , 4.0 ], Payload :: default (), )], ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: UpdateVectors ( UpdateVectors { points : vec !

[ PointVectors { id : Some ( 1. into ()), vectors : Some ( vec!

[ 1.0 , 2.0 , 3.0 , 4.0 ]. into ()), }], ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: DeleteVectors ( DeleteVectors { points_selector : Some ( vec!

[ 1. into ()]. into ()), vectors : Some ( VectorsSelector { names : vec !

[ "" . into ()], }), ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: OverwritePayload ( OverwritePayload { points_selector : Some ( vec!

[ 1. into ()]. into ()), payload : HashMap :: from ([( "test_payload" . to_string (), 1. into ())]), ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: SetPayload ( SetPayload { points_selector : Some ( vec!

[ 1. into ()]. into ()), payload : HashMap :: from ([ ( "test_payload_2" . to_string (), 2. into ()), ( "test_payload_3" . to_string (), 3. into ()), ]), ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: DeletePayload ( DeletePayload { points_selector : Some ( vec!

[ 1. into ()]. into ()), keys : vec !

[ "test_payload_2" . to_string ()], ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: ClearPayload ( ClearPayload { points : Some ( vec!

[ 1. into ()]. into ()), ..

Default :: default () })), }, PointsUpdateOperation { operation : Some ( Operation :: DeletePoints ( DeletePoints { points : Some ( vec!

[ 1. into ()]. into ()), ..

Default :: default () })), }, ], ) . wait ( true ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.PointVectors ; import io.qdrant.client.grpc.Points.PointsIdsList ; import io.qdrant.client.grpc.Points.PointsSelector ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.ClearPayload ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.DeletePayload ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.DeletePoints ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.DeleteVectors ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.OverwritePayload ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.PointStructList ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.SetPayload ; import io.qdrant.client.grpc.Points.PointsUpdateOperation.UpdateVectors ; import io.qdrant.client.grpc.Points.PointsUpdateOperation ; import io.qdrant.client.grpc.Points.VectorsSelector ; import java.util.List ; import java.util.Map ; client . batchUpdateAsync ( "{collection_name}" , List . of ( PointsUpdateOperation . newBuilder () . setUpsert ( PointStructList . newBuilder () . addPoints ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 1 .

0f , 2 .

0f , 3 .

0f , 4 .

0f )) . build ()) . build ()) . build (), PointsUpdateOperation . newBuilder () . setUpdateVectors ( UpdateVectors . newBuilder () . addPoints ( PointVectors . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 1 .

0f , 2 .

0f , 3 .

0f , 4 .

0f )) . build ()) . build ()) . build (), PointsUpdateOperation . newBuilder () . setDeleteVectors ( DeleteVectors . newBuilder () . setPointsSelector ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . setVectors ( VectorsSelector . newBuilder (). addNames ( "" ). build ()) . build ()) . build (), PointsUpdateOperation . newBuilder () . setOverwritePayload ( OverwritePayload . newBuilder () . setPointsSelector ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . putAllPayload ( Map . of ( "test_payload" , value ( 1 ))) . build ()) . build (), PointsUpdateOperation . newBuilder () . setSetPayload ( SetPayload . newBuilder () . setPointsSelector ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . putAllPayload ( Map . of ( "test_payload_2" , value ( 2 ), "test_payload_3" , value ( 3 ))) . build ()) . build (), PointsUpdateOperation . newBuilder () . setDeletePayload ( DeletePayload . newBuilder () . setPointsSelector ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . addKeys ( "test_payload_2" ) . build ()) . build (), PointsUpdateOperation . newBuilder () . setClearPayload ( ClearPayload . newBuilder () . setPoints ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . build ()) . build (), PointsUpdateOperation . newBuilder () . setDeletePoints ( DeletePoints . newBuilder () . setPoints ( PointsSelector . newBuilder () . setPoints ( PointsIdsList . newBuilder (). addIds ( id ( 1 )). build ()) . build ()) . build ()) . build ())) . get ();

To batch many points with a single operation type, please use batching functionality in that operation directly.

Awaiting result If the API is called with the &wait=false parameter, or if it is not explicitly specified, the client will receive an acknowledgment of receiving data: { "result" : { "operation_id" : 123 , "status" : "acknowledged" }, "status" : "ok" , "time" : 0.000206061 } This response does not mean that the data is available for retrieval yet. This uses a form of eventual consistency. It may take a short amount of time before it is actually processed as updating the collection happens in the background. In fact, it is possible that such request eventually fails.

If inserting a lot of vectors, we also recommend using asynchronous requests to take advantage of pipelining.

If the logic of your application requires a guarantee that the vector will be available for searching immediately after the API responds, then use the flag ?wait=true .

In this case, the API will return the result only after the operation is finished: { "result" : { "operation_id" : 0 , "status" : "completed" }, "status" : "ok" , "time" : 0.000206061 }
================================================================================
PAGE 15/39
================================================================================
Title: Storage
URL: https://qdrant.tech/documentation/concepts/storage/
--------------------------------------------------------------------------------

Storage All data within one collection is divided into segments.

Each segment has its independent vector and payload storage as well as indexes.

Data stored in segments usually do not overlap.

However, storing the same point in different segments will not cause problems since the search contains a deduplication mechanism.

The segments consist of vector and payload storages, vector and payload indexes , and id mapper, which stores the relationship between internal and external ids.

A segment can be appendable or non-appendable depending on the type of storage and index used.

You can freely add, delete and query data in the appendable segment.

With non-appendable segment can only read and delete data.

The configuration of the segments in the collection can be different and independent of one another, but at least one `appendable‚Äô segment must be present in a collection.

Vector storage Depending on the requirements of the application, Qdrant can use one of the data storage options.

The choice has to be made between the search speed and the size of the RAM used.

In-memory storage - Stores all vectors in RAM, has the highest speed since disk access is required only for persistence.

Memmap storage - Creates a virtual address space associated with the file on disk.

Wiki .

Mmapped files are not directly loaded into RAM. Instead, they use page cache to access the contents of the file.

This scheme allows flexible use of available memory. With sufficient RAM, it is almost as fast as in-memory storage.

Configuring Memmap storage There are two ways to configure the usage of memmap(also known as on-disk) storage: Set up on_disk option for the vectors in the collection create API: Available as of v1.2.0 PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine ). on_disk ( true )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( "{collection_name}" , VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( "{collection_name}" , new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), }) This will create a collection with all vectors immediately stored in memmap storage.

This is the recommended way, in case your Qdrant instance operates with fast disks and you are working with large collections.

Set up memmap_threshold option. This option will set the threshold after which the segment will be converted to memmap storage.

There are two ways to do this: You can set the threshold globally in the configuration file . The parameter is called memmap_threshold (previously memmap_threshold_kb ).

You can set the threshold for each collection separately during creation or update .

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "optimizers_config": { "indexing_threshold": 20000 } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), optimizers_config = models .

OptimizersConfigDiff ( indexing_threshold = 20000 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, optimizers_config : { indexing_threshold : 20000 , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , OptimizersConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . optimizers_config ( OptimizersConfigDiffBuilder :: default (). indexing_threshold ( 20000 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setOptimizersConfig ( OptimizersConfigDiff . newBuilder (). setIndexingThreshold ( 20000 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, optimizersConfig : new OptimizersConfigDiff { IndexingThreshold = 20000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), OptimizersConfig : & qdrant .

OptimizersConfigDiff { IndexingThreshold : qdrant .

PtrOf ( uint64 ( 20000 )), }, }) The rule of thumb to set the memmap threshold parameter is simple: if you have a balanced use scenario - set memmap threshold the same as indexing_threshold (default is 20000). In this case the optimizer will not make any extra runs and will optimize all thresholds at once. if you have a high write load and low RAM - set memmap threshold lower than indexing_threshold to e.g. 10000. In this case the optimizer will convert the segments to memmap storage first and will only apply indexing after that.

In addition, you can use memmap storage not only for vectors, but also for HNSW index.

To enable this, you need to set the hnsw_config.on_disk parameter to true during collection creation or updating .

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "hnsw_config": { "on_disk": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), hnsw_config = models .

HnswConfigDiff ( on_disk = True ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, hnsw_config : { on_disk : true , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , HnswConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine ). on_disk ( true )) . hnsw_config ( HnswConfigDiffBuilder :: default (). on_disk ( true )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.HnswConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setHnswConfig ( HnswConfigDiff . newBuilder (). setOnDisk ( true ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, hnswConfig : new HnswConfigDiff { OnDisk = true } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), HnswConfig : & qdrant .

HnswConfigDiff { OnDisk : qdrant .

PtrOf ( true ), }, }) Payload storage Qdrant supports two types of payload storages: InMemory and OnDisk.

InMemory payload storage is organized in the same way as in-memory vectors.

The payload data is loaded into RAM at service startup while disk and Gridstore are used for persistence only.

This type of storage works quite fast, but it may require a lot of space to keep all the data in RAM, especially if the payload has large values attached - abstracts of text or even images.

In the case of large payload values, it might be better to use OnDisk payload storage.

This type of storage will read and write payload directly to RocksDB, so it won‚Äôt require any significant amount of RAM to store.

The downside, however, is the access latency.

If you need to query vectors with some payload-based conditions - checking values stored on disk might take too much time.

In this scenario, we recommend creating a payload index for each field used in filtering conditions to avoid disk access.

Once you create the field index, Qdrant will preserve all values of the indexed field in RAM regardless of the payload storage type.

You can specify the desired type of payload storage with configuration file or with collection parameter on_disk_payload during creation of the collection.

Versioning To ensure data integrity, Qdrant performs all data changes in 2 stages.

In the first step, the data is written to the Write-ahead-log(WAL), which orders all operations and assigns them a sequential number.

Once a change has been added to the WAL, it will not be lost even if a power loss occurs.

Then the changes go into the segments.

Each segment stores the last version of the change applied to it as well as the version of each individual point.

If the new change has a sequential number less than the current version of the point, the updater will ignore the change.

This mechanism allows Qdrant to safely and efficiently restore the storage from the WAL in case of an abnormal shutdown.

================================================================================
PAGE 16/39
================================================================================
Title: Indexing
URL: https://qdrant.tech/documentation/concepts/indexing/
--------------------------------------------------------------------------------

Indexing A key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having a vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.

The indexes in the segments exist independently, but the parameters of the indexes themselves are configured for the whole collection.

Not all segments automatically have indexes.

Their necessity is determined by the optimizer settings and depends, as a rule, on the number of stored points.

Payload Index Payload index in Qdrant is similar to the index in conventional document-oriented databases.

This index is built for a specific field and type, and is used for quick point requests by the corresponding filtering condition.

The index is also used to accurately estimate the filter cardinality, which helps the query planning choose a search strategy.

Creating an index requires additional computational resources and memory, so choosing fields to be indexed is essential. Qdrant does not make this choice but grants it to the user.

To mark a field as indexable, you can use the following: PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": "keyword" } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = "keyword" , ) client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : "keyword" , }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , FieldType }; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Keyword , ) . wait ( true ), ) . await ? ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Keyword , null , true , null , null ); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), }) You can use dot notation to specify a nested field for indexing. Similar to specifying nested filters .

Available field types are: keyword - for keyword payload, affects Match filtering conditions. integer - for integer payload, affects Match and Range filtering conditions. float - for float payload, affects Range filtering conditions. bool - for bool payload, affects Match filtering conditions (available as of v1.4.0). geo - for geo payload, affects Geo Bounding Box and Geo Radius filtering conditions. datetime - for datetime payload, affects Range filtering conditions (available as of v1.8.0). text - a special kind of index, available for keyword / string payloads, affects Full Text search filtering conditions. Read more about text index configuration uuid - a special type of index, similar to keyword , but optimized for UUID values .

Affects Match filtering conditions. (available as of v1.11.0) Payload index may occupy some additional memory, so it is recommended to only use the index for those fields that are used in filtering conditions.

If you need to filter by many fields and the memory limits do not allow for indexing all of them, it is recommended to choose the field that limits the search result the most.

As a rule, the more different values a payload value has, the more efficiently the index will be used.

Parameterized index Available as of v1.8.0 We‚Äôve added a parameterized variant to the integer index, which allows you to fine-tune indexing and search performance.

Both the regular and parameterized integer indexes use the following flags: lookup : enables support for direct lookup using Match filters. range : enables support for Range filters.

The regular integer index assumes both lookup and range are true . In contrast, to configure a parameterized index, you would set only one of these filters to true : lookup range Result true true Regular integer index true false Parameterized integer index false true Parameterized integer index false false No integer index The parameterized index can enhance performance in collections with millions of points. We encourage you to try it out. If it does not enhance performance in your use case, you can always restore the regular integer index.

Note: If you set "lookup": true with a range filter, that may lead to significant performance issues.

For example, the following code sets up a parameterized integer index which supports only range filters: PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "integer", "lookup": false, "range": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

IntegerIndexParams ( type = models .

IntegerIndexType .

INTEGER , lookup = False , range = True , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "integer" , lookup : false , range : true , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , FieldType , IntegerIndexParamsBuilder , }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Integer , ) . field_index_params ( IntegerIndexParamsBuilder :: new ( false , true ). build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.IntegerIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Integer , PayloadIndexParams . newBuilder () . setIntegerIndexParams ( IntegerIndexParams . newBuilder (). setLookup ( false ). setRange ( true ). build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Integer , indexParams : new PayloadIndexParams { IntegerIndexParams = new () { Lookup = false , Range = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeInteger .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsInt ( & qdrant .

IntegerIndexParams { Lookup : qdrant .

PtrOf ( false ), Range : qdrant .

PtrOf ( true ), }), }) On-disk payload index Available as of v1.11.0 By default all payload-related structures are stored in memory. In this way, the vector index can quickly access payload values during search.

As latency in this case is critical, it is recommended to keep hot payload indexes in memory.

There are, however, cases when payload indexes are too large or rarely used. In those cases, it is possible to store payload indexes on disk.

To configure on-disk payload index, you can use the following index parameters: PUT /collections/{collection_name}/index { "field_name": "payload_field_name", "field_schema": { "type": "keyword", "on_disk": true } } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "payload_field_name" , field_schema = models .

KeywordIndexParams ( type = models .

KeywordIndexType .

KEYWORD , on_disk = True , ), ) client . createPayloadIndex ( "{collection_name}" , { field_name : "payload_field_name" , field_schema : { type : "keyword" , on_disk : true }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , KeywordIndexParamsBuilder , FieldType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "payload_field_name" , FieldType :: Keyword , ) . field_index_params ( KeywordIndexParamsBuilder :: default () . on_disk ( true ), ), ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.KeywordIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "payload_field_name" , PayloadSchemaType .

Keyword , PayloadIndexParams . newBuilder () . setKeywordIndexParams ( KeywordIndexParams . newBuilder () . setOnDisk ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "payload_field_name" , schemaType : PayloadSchemaType .

Keyword , indexParams : new PayloadIndexParams { KeywordIndexParams = new KeywordIndexParams { OnDisk = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsKeyword ( & qdrant .

KeywordIndexParams { OnDisk : qdrant .

PtrOf ( true ), }), }) Payload index on-disk is supported for the following types: keyword integer float datetime uuid text geo The list will be extended in future versions.

Tenant Index Available as of v1.11.0 Many vector search use-cases require multitenancy. In a multi-tenant scenario the collection is expected to contain multiple subsets of data, where each subset belongs to a different tenant.

Qdrant supports efficient multi-tenant search by enabling special configuration vector index, which disables global search and only builds sub-indexes for each tenant.

However, knowing that the collection contains multiple tenants unlocks more opportunities for optimization.

To optimize storage in Qdrant further, you can enable tenant indexing for payload fields.

This option will tell Qdrant which fields are used for tenant identification and will allow Qdrant to structure storage for faster search of tenant-specific data.

One example of such optimization is localizing tenant-specific data closer on disk, which will reduce the number of disk reads during search.

To enable tenant index for a field, you can use the following index parameters: PUT /collections/{collection_name}/index { "field_name": "payload_field_name", "field_schema": { "type": "keyword", "is_tenant": true } } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "payload_field_name" , field_schema = models .

KeywordIndexParams ( type = models .

KeywordIndexType .

KEYWORD , is_tenant = True , ), ) client . createPayloadIndex ( "{collection_name}" , { field_name : "payload_field_name" , field_schema : { type : "keyword" , is_tenant : true }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , KeywordIndexParamsBuilder , FieldType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "payload_field_name" , FieldType :: Keyword , ) . field_index_params ( KeywordIndexParamsBuilder :: default () . is_tenant ( true ), ), ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.KeywordIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "payload_field_name" , PayloadSchemaType .

Keyword , PayloadIndexParams . newBuilder () . setKeywordIndexParams ( KeywordIndexParams . newBuilder () . setIsTenant ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "payload_field_name" , schemaType : PayloadSchemaType .

Keyword , indexParams : new PayloadIndexParams { KeywordIndexParams = new KeywordIndexParams { IsTenant = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsKeyword ( & qdrant .

KeywordIndexParams { IsTenant : qdrant .

PtrOf ( true ), }), }) Tenant optimization is supported for the following datatypes: keyword uuid Principal Index Available as of v1.11.0 Similar to the tenant index, the principal index is used to optimize storage for faster search, assuming that the search request is primarily filtered by the principal field.

A good example of a use case for the principal index is time-related data, where each point is associated with a timestamp. In this case, the principal index can be used to optimize storage for faster search with time-based filters.

PUT /collections/{collection_name}/index { "field_name": "timestamp", "field_schema": { "type": "integer", "is_principal": true } } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "timestamp" , field_schema = models .

IntegerIndexParams ( type = models .

IntegerIndexType .

INTEGER , is_principal = True , ), ) client . createPayloadIndex ( "{collection_name}" , { field_name : "timestamp" , field_schema : { type : "integer" , is_principal : true }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , IntegerIndexParamsBuilder , FieldType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "timestamp" , FieldType :: Integer , ) . field_index_params ( IntegerIndexParamsBuilder :: default () . is_principal ( true ), ), ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.IntegerIndexParams ; import io.qdrant.client.grpc.Collections.KeywordIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "timestamp" , PayloadSchemaType .

Integer , PayloadIndexParams . newBuilder () . setIntegerIndexParams ( IntegerIndexParams . newBuilder () . setIsPrincipal ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "timestamp" , schemaType : PayloadSchemaType .

Integer , indexParams : new PayloadIndexParams { IntegerIndexParams = new IntegerIndexParams { IsPrincipal = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeInteger .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsInt ( & qdrant .

IntegerIndexParams { IsPrincipal : qdrant .

PtrOf ( true ), }), }) Principal optimization is supported for following types: integer float datetime Full-text index Qdrant supports full-text search for string payload.

Full-text index allows you to filter points by the presence of a word or a phrase in the payload field.

Full-text index configuration is a bit more complex than other indexes, as you can specify the tokenization parameters.

Tokenization is the process of splitting a string into tokens, which are then indexed in the inverted index.

See Full Text match for examples of querying with a full-text index.

To create a full-text index, you can use the following: PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "min_token_len": 2, "max_token_len": 10, "lowercase": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , min_token_len = 2 , max_token_len = 10 , lowercase = True , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , min_token_len : 2 , max_token_len : 10 , lowercase : true , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . min_token_len ( 2 ) . max_token_len ( 10 ) . lowercase ( true ); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setMinTokenLen ( 2 ) . setMaxTokenLen ( 10 ) . setLowercase ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , MinTokenLen = 2 , MaxTokenLen = 10 , Lowercase = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Whitespace , MinTokenLen : qdrant .

PtrOf ( uint64 ( 2 )), MaxTokenLen : qdrant .

PtrOf ( uint64 ( 10 )), Lowercase : qdrant .

PtrOf ( true ), }), }) Tokenizers Tokenizers are algorithms used to split text into smaller units called tokens, which are then indexed and searched in a full-text index.

In the context of Qdrant, tokenizers determine how string payloads are broken down for efficient searching and filtering.

The choice of tokenizer affects how queries match the indexed text, supporting different languages, word boundaries, and search behaviours such as prefix or phrase matching.

Available tokenizers are: word (default) - splits the string into words, separated by spaces, punctuation marks, and special characters. whitespace - splits the string into words, separated by spaces. prefix - splits the string into words, separated by spaces, punctuation marks, and special characters, and then creates a prefix index for each word. For example: hello will be indexed as h , he , hel , hell , hello . multilingual - a special type of tokenizer based on multiple packages like charabia and vaporetto to deliver fast and accurate tokenization for a large variety of languages. It allows proper tokenization and lemmatization for multiple languages, including those with non-Latin alphabets and non-space delimiters. See the charabia documentation for a full list of supported languages and normalization options. Note: For the Japanese language, Qdrant relies on the vaporetto project, which has much less overhead compared to charabia , while maintaining comparable performance.

Lowercasing By default, full-text search in Qdrant is case-insensitive. For example, users can search for the lowercase term tv and find text fields containing the uppercase word TV . Case-insensitivity is achieved by converting both the words in the index and the query terms to lowercase.

Lowercasing is enabled by default. To use case-sensitive full-text search, configure a full-text index with lowercase set to false .

PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "lowercase": false } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , lowercase = False , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , lowercase : false , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . lowercase ( false ); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setLowercase ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , Lowercase = true , } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Word , Lowercase : qdrant .

PtrOf ( true ), }), }) ASCII Folding Available as of v1.16.0 When enabled, ASCII folding converts Unicode characters into their corresponding ASCII equivalents, for example, by removing diacritics. For instance, the character √£ is changed into a , √ß becomes c , and √© is converted to e .

Because ASCII folding is applied to both the words in the index and the query terms, it increases recall. For example, users can search for cafe and also find text fields containing the word caf√© .

ASCII folding is not enabled by default. To enable it, configure a full-text index with ascii_folding set to true .

PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "ascii_folding": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , ascii_folding = True , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , ascii_folding : true , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . ascii_folding ( true ); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setLowercase ( true ) . setAsciiFolding ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , Lowercase = true , AsciiFolding = true , } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Word , Lowercase : qdrant .

PtrOf ( true ), AsciiFolding : qdrant .

PtrOf ( true ), }), }) Stemmer A stemmer is an algorithm used in text processing to reduce words to their root or base form, known as the ‚Äústem.‚Äù For example, the words ‚Äúrunning‚Äù, ‚Äúrunner and ‚Äúruns‚Äù can all be reduced to the stem ‚Äúrun.‚Äù When configuring a full-text index in Qdrant, you can specify a stemmer to be used for a particular language. This enables the index to recognize and match different inflections or derivations of a word.

Qdrant provides an implementation of Snowball stemmer , a widely used and performant variant for some of the most popular languages.

For the list of supported languages, please visit the rust-stemmers repository .

For full-text indices, stemming is not enabled by default. To enable it, configure the snowball stemmer with the desired language: PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "stemmer": { "type": "snowball", "language": "english" } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , stemmer = models .

SnowballParams ( type = models .

Snowball .

SNOWBALL , language = models .

SnowballLanguage .

ENGLISH ) ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , stemmer : { type : "snowball" , language : "english" } } }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . snowball_stemmer ( "english" . to_string ()); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "{field_name}" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.SnowballParams ; import io.qdrant.client.grpc.Collections.StemmingAlgorithm ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setStemmer ( StemmingAlgorithm . newBuilder () . setSnowball ( SnowballParams . newBuilder (). setLanguage ( "english" ). build ()) . build ()) . build ()) . build (), true , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , Stemmer = new StemmingAlgorithm { Snowball = new SnowballParams { Language = "english" } } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Word , Stemmer : qdrant .

NewStemmingAlgorithmSnowball ( & qdrant .

SnowballParams { Language : "english" , }), }), }) Stopwords Stopwords are common words (such as ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúat‚Äù, ‚Äúwhich‚Äù, and ‚Äúon‚Äù) that are often filtered out during text processing because they carry little meaningful information for search and retrieval tasks.

In Qdrant, you can specify a list of stopwords to be ignored during full-text indexing and search. This helps simplify search queries and improves relevance.

You can configure stopwords based on predefined languages, as well as extend existing stopword lists with custom words.

For full-text indices, stopword removal is not enabled by default. To enable it, configure the stopwords parameter with the desired languages and any custom stopwords: // Simple PUT collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "stopwords": "english" } } // Explicit PUT collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "stopwords": { "languages": [ "english", "spanish" ], "custom": [ "example" ] } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) # Simple client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , stopwords = models .

Language .

ENGLISH , ), ) # Explicit client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , stopwords = models .

StopwordsSet ( languages = [ models .

Language .

ENGLISH , models .

Language .

SPANISH , ], custom = [ "example" ] ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 });

// Simple client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , stopwords : "english" }, });

// Explicit client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , stopwords : { languages : [ "english" , "spanish" ], custom : [ "example" ] } }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , StopwordsSet , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ;

// Simple let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . stopwords_language ( "english" . to_string ()); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ;

// Explicit let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . stopwords ( StopwordsSet { languages : vec !

[ "english" . to_string (), "spanish" . to_string (), ], custom : vec !

[ "example" . to_string ()], }); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "{field_name}" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.StopwordsSet ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setStopwords ( StopwordsSet . newBuilder () . addAllLanguages ( List . of ( "english" , "spanish" )) . addAllCustom ( List . of ( "example" )) . build ()) . build ()) . build (), true , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , Stopwords = new StopwordsSet { Languages = { "english" , "spanish" }, Custom = { "example" } } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Word , Stopwords : & qdrant .

StopwordsSet { Languages : [] string { "english" , "spanish" }, Custom : [] string { "example" }, }, }), }) Phrase Search Phrase search in Qdrant allows you to find documents or points where a specific sequence of words appears together, in the same order, within a text payload field.

This is useful when you want to match exact phrases rather than individual words scattered throughout the text.

When using a full-text index with phrase search enabled, you can perform phrase search by enclosing the desired phrase in double quotes in your filter query.

For example, searching for "machine learning" will only return results where the words ‚Äúmachine‚Äù and ‚Äúlearning‚Äù appear together as a phrase, not just anywhere in the text.

For efficient phrase search, Qdrant requires building an additional data structure, so it needs to be configured during the creation of the full-text index: PUT /collections/{collection_name}/index { "field_name": "name_of_the_field_to_index", "field_schema": { "type": "text", "tokenizer": "word", "lowercase": true, "phrase_matching": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_payload_index ( collection_name = " {collection_name} " , field_name = "name_of_the_field_to_index" , field_schema = models .

TextIndexParams ( type = models .

TextIndexType .

TEXT , tokenizer = models .

TokenizerType .

WORD , lowercase = True , phrase_matching = True , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createPayloadIndex ( "{collection_name}" , { field_name : "name_of_the_field_to_index" , field_schema : { type : "text" , tokenizer : "word" , lowercase : true , phrase_matching : true , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , TextIndexParamsBuilder , FieldType , TokenizerType , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let text_index_params = TextIndexParamsBuilder :: new ( TokenizerType :: Word ) . phrase_matching ( true ) . lowercase ( true ); client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "name_of_the_field_to_index" , FieldType :: Text , ). field_index_params ( text_index_params . build ()), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ; import io.qdrant.client.grpc.Collections.TextIndexParams ; import io.qdrant.client.grpc.Collections.TokenizerType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "name_of_the_field_to_index" , PayloadSchemaType .

Text , PayloadIndexParams . newBuilder () . setTextIndexParams ( TextIndexParams . newBuilder () . setTokenizer ( TokenizerType .

Word ) . setLowercase ( true ) . setPhraseMatching ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "name_of_the_field_to_index" , schemaType : PayloadSchemaType .

Text , indexParams : new PayloadIndexParams { TextIndexParams = new TextIndexParams { Tokenizer = TokenizerType .

Word , Lowercase = true , PhraseMatching = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "name_of_the_field_to_index" , FieldType : qdrant .

FieldType_FieldTypeText .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParamsText ( & qdrant .

TextIndexParams { Tokenizer : qdrant .

TokenizerType_Whitespace , Lowercase : qdrant .

PtrOf ( true ), PhraseMatching : qdrant .

PtrOf ( true ), }), }) See Phrase Match for examples of querying phrases with a full-text index.

Vector Index A vector index is a data structure built on vectors through a specific mathematical model.

Through the vector index, we can efficiently query several vectors similar to the target vector.

Qdrant currently only uses HNSW as a dense vector index.

HNSW (Hierarchical Navigable Small World Graph) is a graph-based indexing algorithm. It builds a multi-layer navigation structure for an image according to certain rules. In this structure, the upper layers are more sparse and the distances between nodes are farther. The lower layers are denser and the distances between nodes are closer. The search starts from the uppermost layer, finds the node closest to the target in this layer, and then enters the next layer to begin another search. After multiple iterations, it can quickly approach the target position.

In order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to m . In addition, you can use ef_construct (when building an index) or ef (when searching targets) to specify a search range.

The corresponding parameters could be configured in the configuration file: storage : # Default parameters of HNSW Index. Could be overridden for each collection or named vector individually hnsw_index : # Number of edges per node in the index graph.

# Larger the value - more accurate the search, more space required. m : 16 # Number of neighbours to consider during the index building.

# Larger the value - more accurate the search, more time required to build index. ef_construct : 100 # Minimal size threshold (in KiloBytes) below which full-scan is preferred over HNSW search.

# This measures the total size of vectors being queried against.

# When the maximum estimated amount of points that a condition satisfies is smaller than # `full_scan_threshold_kb`, the query planner will use full-scan search instead of HNSW index # traversal for better performance.

# Note: 1Kb = 1 vector of size 256 full_scan_threshold : 10000 And so in the process of creating a collection . The ef parameter is configured during the search and by default is equal to ef_construct .

HNSW is chosen for several reasons.

First, HNSW is well-compatible with the modification that allows Qdrant to use filters during a search.

Second, it is one of the most accurate and fastest algorithms, according to public benchmarks .

Available as of v1.1.1 The HNSW parameters can also be configured on a collection and named vector level by setting hnsw_config to fine-tune search performance.

Sparse Vector Index Available as of v1.7.0 Sparse vectors in Qdrant are indexed with a special data structure, which is optimized for vectors that have a high proportion of zeroes. In some ways, this indexing method is similar to the inverted index, which is used in text search engines.

A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms.

All sparse vectors added to the collection are immediately indexed in the mutable version of a sparse index.

With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is constructed during the same optimization process as the dense vector index.

This approach is particularly useful for collections storing both dense and sparse vectors.

To configure a sparse vector index, create a collection with the following parameters: PUT /collections/{collection_name} { "sparse_vectors": { "text": { "index": { "on_disk": false } } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = {}, sparse_vectors_config = { "text" : models .

SparseVectorParams ( index = models .

SparseIndexParams ( on_disk = False ), ) }, ) import { QdrantClient , Schemas } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { sparse_vectors : { "splade-model-name" : { index : { on_disk : false } } } }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , SparseIndexConfigBuilder , SparseVectorParamsBuilder , SparseVectorsConfigBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut sparse_vectors_config = SparseVectorsConfigBuilder :: default (); sparse_vectors_config . add_named_vector_params ( "splade-model-name" , SparseVectorParamsBuilder :: default () . index ( SparseIndexConfigBuilder :: default (). on_disk ( true )), ); client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . sparse_vectors_config ( sparse_vectors_config ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( Collections .

CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setSparseVectorsConfig ( Collections .

SparseVectorConfig . newBuilder (). putMap ( "splade-model-name" , Collections .

SparseVectorParams . newBuilder () . setIndex ( Collections .

SparseIndexConfig . newBuilder () . setOnDisk ( false ) . build () ). build () ). build () ). build () ). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , sparseVectorsConfig : ( "splade-model-name" , new SparseVectorParams { Index = new SparseIndexConfig { OnDisk = false , } }) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , SparseVectorsConfig : qdrant .

NewSparseVectorsConfig ( map [ string ] * qdrant .

SparseVectorParams { "splade-model-name" : { Index : & qdrant .

SparseIndexConfig { OnDisk : qdrant .

PtrOf ( false ), }}, }), }) ` The following parameters may affect performance: on_disk: true - The index is stored on disk, which lets you save memory. This may slow down search performance. on_disk: false - The index is still persisted on disk, but it is also loaded into memory for faster search.

Unlike a dense vector index, a sparse vector index does not require a predefined vector size. It automatically adjusts to the size of the vectors added to the collection.

Note: A sparse vector index only supports dot-product similarity searches. It does not support other distance metrics.

IDF Modifier Available as of v1.10.0 For many search algorithms, it is important to consider how often an item occurs in a collection.

Intuitively speaking, the less frequently an item appears in a collection, the more important it is in a search.

This is also known as the Inverse Document Frequency (IDF). It is used in text search engines to rank search results based on the rarity of a word in a collection.

IDF depends on the currently stored documents and therefore can‚Äôt be pre-computed in the sparse vectors in streaming inference mode.

In order to support IDF in the sparse vector index, Qdrant provides an option to modify the sparse vector query with the IDF statistics automatically.

The only requirement is to enable the IDF modifier in the collection configuration: PUT /collections/{collection_name} { "sparse_vectors": { "text": { "modifier": "idf" } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = {}, sparse_vectors_config = { "text" : models .

SparseVectorParams ( modifier = models .

Modifier .

IDF , ), }, ) import { QdrantClient , Schemas } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { sparse_vectors : { "text" : { modifier : "idf" } } }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Modifier , SparseVectorParamsBuilder , SparseVectorsConfigBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let mut sparse_vectors_config = SparseVectorsConfigBuilder :: default (); sparse_vectors_config . add_named_vector_params ( "text" , SparseVectorParamsBuilder :: default (). modifier ( Modifier :: Idf ), ); client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . sparse_vectors_config ( sparse_vectors_config ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Modifier ; import io.qdrant.client.grpc.Collections.SparseVectorConfig ; import io.qdrant.client.grpc.Collections.SparseVectorParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setSparseVectorsConfig ( SparseVectorConfig . newBuilder () . putMap ( "text" , SparseVectorParams . newBuilder (). setModifier ( Modifier .

Idf ). build ())) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , sparseVectorsConfig : ( "text" , new SparseVectorParams { Modifier = Modifier .

Idf , }) ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , SparseVectorsConfig : qdrant .

NewSparseVectorsConfig ( map [ string ] * qdrant .

SparseVectorParams { "text" : { Modifier : qdrant .

Modifier_Idf .

Enum (), }, }), }) Qdrant uses the following formula to calculate the IDF modifier: $$ \text{IDF}(q_i) = \ln \left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}+1\right) $$ Where: N is the total number of documents in the collection. n is the number of documents containing non-zero values for the given vector element.

Filterable Index Separately, a payload index and a vector index cannot solve the problem of search using the filter completely.

In the case of high-selectivity (weak) filters, you can use the HNSW index as it is.

In the case of low-selectivity (strict) filters, you can use the payload index and complete rescore.

However, for cases in the middle, this approach does not work well.

On the one hand, we cannot apply a full scan on too many vectors.

On the other hand, the HNSW graph starts to fall apart when using too strict filters.

Qdrant solves this problem by extending the HNSW graph with additional edges based on the stored payload values.

Extra edges allow you to efficiently search for nearby vectors using the HNSW index and apply filters as you search in the graph.

You can find more information on this approach in our article .

However, in some cases, these additional edges might not be enough.

These extra edges are added per each payload index separately, but not per each possible combination of them.

So, a combination of two or more strict filters still might lead to disconnected graph components.

The same may happen when having a large number of soft-deleted points in the graph.

In such cases, the ACORN Search Algorithm can be used.

================================================================================
PAGE 17/39
================================================================================
Title: Snapshots
URL: https://qdrant.tech/documentation/concepts/snapshots/
--------------------------------------------------------------------------------

Snapshots Available as of v0.8.4 Snapshots are tar archive files that contain data and configuration of a specific collection on a specific node at a specific time. In a distributed setup, when you have multiple nodes in your cluster, you must create snapshots for each node separately when dealing with a single collection.

This feature can be used to archive data or easily replicate an existing deployment. For disaster recovery, Qdrant Cloud users may prefer to use Backups instead, which are physical disk-level copies of your data.

A collection level snapshot only contains data within that collection, including the collection configuration, all points and payloads. Collection aliases are not included and can be migrated or recovered separately .

For a step-by-step guide on how to use snapshots, see our tutorial .

Create snapshot To create a new snapshot for an existing collection: POST /collections/{collection_name}/snapshots from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . create_snapshot ( collection_name = " {collection_name} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createSnapshot ( "{collection_name}" ); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_snapshot ( "{collection_name}" ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createSnapshotAsync ( "{collection_name}" ). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateSnapshotAsync ( "{collection_name}" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateSnapshot ( context .

Background (), "{collection_name}" ) This is a synchronous operation for which a tar archive file will be generated into the snapshot_path .

Delete snapshot Available as of v1.0.0 DELETE /collections/{collection_name}/snapshots/{snapshot_name} from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . delete_snapshot ( collection_name = " {collection_name} " , snapshot_name = " {snapshot_name} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . deleteSnapshot ( "{collection_name}" , "{snapshot_name}" ); use qdrant_client :: qdrant :: DeleteSnapshotRequestBuilder ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . delete_snapshot ( DeleteSnapshotRequestBuilder :: new ( "{collection_name}" , "{snapshot_name}" , )) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . deleteSnapshotAsync ( "{collection_name}" , "{snapshot_name}" ). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeleteSnapshotAsync ( collectionName : "{collection_name}" , snapshotName : "{snapshot_name}" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

DeleteSnapshot ( context .

Background (), "{collection_name}" , "{snapshot_name}" ) List snapshot List of snapshots for a collection: GET /collections/{collection_name}/snapshots from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . list_snapshots ( collection_name = " {collection_name} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . listSnapshots ( "{collection_name}" ); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . list_snapshots ( "{collection_name}" ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . listSnapshotAsync ( "{collection_name}" ). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ListSnapshotsAsync ( "{collection_name}" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

ListSnapshots ( context .

Background (), "{collection_name}" ) Retrieve snapshot To download a specified snapshot from a collection as a file: GET /collections/{collection_name}/snapshots/{snapshot_name} curl 'http://{qdrant-url}:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot' \ -H 'api-key: ********' \ --output 'filename.snapshot' curl 'http://{qdrant-url}:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot' \ -H 'api-key: ********' \ --output 'filename.snapshot' Restore snapshot Snapshots can be restored in three possible ways: Recovering from a URL or local file (useful for restoring a snapshot file that is on a remote server or already stored on the node) Recovering from an uploaded file (useful for migrating data to a new cluster) Recovering during start-up (useful when running a self-hosted single-node Qdrant instance) Regardless of the method used, Qdrant will extract the shard data from the snapshot and properly register shards in the cluster.

If there are other active replicas of the recovered shards in the cluster, Qdrant will replicate them to the newly recovered node by default to maintain data consistency.

Recover from a URL or local file Available as of v0.11.3 This method of recovery requires the snapshot file to be downloadable from a URL or exist as a local file on the node (like if you created the snapshot on this node previously). If instead you need to upload a snapshot file, see the next section.

To recover from a URL or local file use the snapshot recovery endpoint . This endpoint accepts either a URL like https://example.com or a file URI like file:///tmp/snapshot-2022-10-10.snapshot . If the target collection does not exist, it will be created.

PUT /collections/{collection_name}/snapshots/recover { "location": "http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot" } from qdrant_client import QdrantClient client = QdrantClient ( url = "http://qdrant-node-2:6333" ) client . recover_snapshot ( " {collection_name} " , "http://qdrant-node-1:6333/collections/collection_name/snapshots/snapshot-2022-10-10.snapshot" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . recoverSnapshot ( "{collection_name}" , { location : "http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot" , });

Recover from an uploaded file The snapshot file can also be uploaded as a file and restored using the recover from uploaded snapshot . This endpoint accepts the raw snapshot data in the request body. If the target collection does not exist, it will be created. curl -X POST 'http://{qdrant-url}:6333/collections/{collection_name}/snapshots/upload?priority=snapshot' \ -H 'api-key: ********' \ -H 'Content-Type:multipart/form-data' \ -F 'snapshot=@/path/to/snapshot-2022-10-10.snapshot' This method is typically used to migrate data from one cluster to another, so we recommend setting the priority to ‚Äúsnapshot‚Äù for that use-case.

Recover during start-up If you have a single-node deployment, you can recover any collection at start-up and it will be immediately available.

Restoring snapshots is done through the Qdrant CLI at start-up time via the --snapshot argument which accepts a list of pairs such as <snapshot_file_path>:<target_collection_name> For example: ./qdrant --snapshot /snapshots/test-collection-archive.snapshot:test-collection --snapshot /snapshots/test-collection-archive.snapshot:test-copy-collection The target collection must be absent otherwise the program will exit with an error.

If you wish instead to overwrite an existing collection, use the --force_snapshot flag with caution.

Snapshot priority When recovering a snapshot to a non-empty node, there may be conflicts between the snapshot data and the existing data. The ‚Äúpriority‚Äù setting controls how Qdrant handles these conflicts. The priority setting is important because different priorities can give very different end results. The default priority may not be best for all situations.

The available snapshot recovery priorities are: replica : (default) prefer existing data over the snapshot. snapshot : prefer snapshot data over existing data. no_sync : restore snapshot without any additional synchronization.

To recover a new collection from a snapshot, you need to set the priority to snapshot . With snapshot priority, all data from the snapshot will be recovered onto the cluster. With replica priority (default) , you‚Äôd end up with an empty collection because the collection on the cluster did not contain any points and that source was preferred. no_sync is for specialized use cases and is not commonly used. It allows managing shards and transferring shards between clusters manually without any additional synchronization. Using it incorrectly will leave your cluster in a broken state.

To recover from a URL, you specify an additional parameter in the request body: PUT /collections/{collection_name}/snapshots/recover { "location": "http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot", "priority": "snapshot" } curl -X POST 'http://qdrant-node-1:6333/collections/{collection_name}/snapshots/upload?priority=snapshot' \ -H 'api-key: ********' \ -H 'Content-Type:multipart/form-data' \ -F 'snapshot=@/path/to/snapshot-2022-10-10.snapshot' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://qdrant-node-2:6333" ) client . recover_snapshot ( " {collection_name} " , "http://qdrant-node-1:6333/collections/ {collection_name} /snapshots/snapshot-2022-10-10.snapshot" , priority = models .

SnapshotPriority .

SNAPSHOT , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . recoverSnapshot ( "{collection_name}" , { location : "http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.snapshot" , priority : "snapshot" });

Snapshots for the whole storage Available as of v0.8.5 Sometimes it might be handy to create snapshot not just for a single collection, but for the whole storage, including collection aliases.

Qdrant provides a dedicated API for that as well. It is similar to collection-level snapshots, but does not require collection_name .

Create full storage snapshot POST /snapshots from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . create_full_snapshot () import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createFullSnapshot (); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_full_snapshot (). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createFullSnapshotAsync (). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateFullSnapshotAsync (); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFullSnapshot ( context .

Background ()) Delete full storage snapshot Available as of v1.0.0 DELETE /snapshots/{snapshot_name} from qdrant_client import QdrantClient client = QdrantClient ( url = "http://localhost:6333" ) client . delete_full_snapshot ( snapshot_name = " {snapshot_name} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . deleteFullSnapshot ( "{snapshot_name}" ); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . delete_full_snapshot ( "{snapshot_name}" ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . deleteFullSnapshotAsync ( "{snapshot_name}" ). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

DeleteFullSnapshotAsync ( "{snapshot_name}" ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

DeleteFullSnapshot ( context .

Background (), "{snapshot_name}" ) List full storage snapshots GET /snapshots from qdrant_client import QdrantClient client = QdrantClient ( "localhost" , port = 6333 ) client . list_full_snapshots () import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . listFullSnapshots (); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . list_full_snapshots (). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . listFullSnapshotAsync (). get (); using Qdrant.Client ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

ListFullSnapshotsAsync (); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

ListFullSnapshots ( context .

Background ()) Download full storage snapshot GET /snapshots/{snapshot_name} Restore full storage snapshot Restoring snapshots can only be done through the Qdrant CLI at startup time.

For example: ./qdrant --storage-snapshot /snapshots/full-snapshot-2022-07-18-11-20-51.snapshot Storage Created, uploaded and recovered snapshots are stored as .snapshot files. By default, they‚Äôre stored on the local file system . You may also configure to use an S3 storage service for them.

Local file system By default, snapshots are stored at ./snapshots or at /qdrant/snapshots when using our Docker image.

The target directory can be controlled through the configuration : storage : # Specify where you want to store snapshots. snapshots_path : ./snapshots Alternatively you may use the environment variable QDRANT__STORAGE__SNAPSHOTS_PATH=./snapshots .

Available as of v1.3.0 While a snapshot is being created, temporary files are placed in the configured storage directory by default. In case of limited capacity or a slow network attached disk, you can specify a separate location for temporary files: storage : # Where to store temporary files temp_path : /tmp S3 Available as of v1.10.0 Rather than storing snapshots on the local file system, you may also configure to store snapshots in an S3-compatible storage service. To enable this, you must configure it in the configuration file.

For example, to configure for AWS S3: storage : snapshots_config : # Use 's3' to store snapshots on S3 snapshots_storage : s3 s3_config : # Bucket name bucket : your_bucket_here # Bucket region (e.g. eu-central-1) region : your_bucket_region_here # Storage access key # Can be specified either here or in the `QDRANT__STORAGE__SNAPSHOTS_CONFIG__S3_CONFIG__ACCESS_KEY` environment variable. access_key : your_access_key_here # Storage secret key # Can be specified either here or in the `QDRANT__STORAGE__SNAPSHOTS_CONFIG__S3_CONFIG__SECRET_KEY` environment variable. secret_key : your_secret_key_here # S3-Compatible Storage URL # Can be specified either here or in the `QDRANT__STORAGE__SNAPSHOTS_CONFIG__S3_CONFIG__ENDPOINT_URL` environment variable. endpoint_url : your_url_here Apart from Snapshots, Qdrant also provides the Qdrant Migration Tool that supports: Migration between Qdrant Cloud instances.

Migrating vectors from other providers into Qdrant.

Migrating from Qdrant OSS to Qdrant Cloud.

Follow our migration guide to learn how to effectively use the Qdrant Migration tool.

================================================================================
PAGE 18/39
================================================================================
Title: Quantization
URL: https://qdrant.tech/documentation/guides/quantization/
--------------------------------------------------------------------------------

Quantization Quantization is an optional feature in Qdrant that enables efficient storage and search of high-dimensional vectors.

By transforming original vectors into a new representations, quantization compresses data while preserving close to original relative distances between vectors.

Different quantization methods have different mechanics and tradeoffs. We will cover them in this section.

Quantization is primarily used to reduce the memory footprint and accelerate the search process in high-dimensional vector spaces.

In the context of the Qdrant, quantization allows you to optimize the search engine for specific use cases, striking a balance between accuracy, storage efficiency, and search speed.

There are tradeoffs associated with quantization.

On the one hand, quantization allows for significant reductions in storage requirements and faster search times.

This can be particularly beneficial in large-scale applications where minimizing the use of resources is a top priority.

On the other hand, quantization introduces an approximation error, which can lead to a slight decrease in search quality.

The level of this tradeoff depends on the quantization method and its parameters, as well as the characteristics of the data.

Scalar Quantization Available as of v1.1.0 Scalar quantization, in the context of vector search engines, is a compression technique that compresses vectors by reducing the number of bits used to represent each vector component.

For instance, Qdrant uses 32-bit floating numbers to represent the original vector components. Scalar quantization allows you to reduce the number of bits used to 8.

In other words, Qdrant performs float32 -> uint8 conversion for each vector component.

Effectively, this means that the amount of memory required to store a vector is reduced by a factor of 4.

In addition to reducing the memory footprint, scalar quantization also speeds up the search process.

Qdrant uses a special SIMD CPU instruction to perform fast vector comparison.

This instruction works with 8-bit integers, so the conversion to uint8 allows Qdrant to perform the comparison faster.

The main drawback of scalar quantization is the loss of accuracy. The float32 -> uint8 conversion introduces an error that can lead to a slight decrease in search quality.

However, this error is usually negligible, and tends to be less significant for high-dimensional vectors.

In our experiments, we found that the error introduced by scalar quantization is usually less than 1%.

However, this value depends on the data and the quantization parameters.

Please refer to the Quantization Tips section for more information on how to optimize the quantization parameters for your use case.

Binary Quantization Available as of v1.5.0 Binary quantization is an extreme case of scalar quantization.

This feature lets you represent each vector component as a single bit, effectively reducing the memory footprint by a factor of 32 .

This is the fastest quantization method, since it lets you perform a vector comparison with a few CPU instructions.

Binary quantization can achieve up to a 40x speedup compared to the original vectors.

However, binary quantization is only efficient for high-dimensional vectors and require a centered distribution of vector components.

At the moment, binary quantization shows good accuracy results with the following models: OpenAI text-embedding-ada-002 - 1536d tested with dbpedia dataset achieving 0.98 recall@100 with 4x oversampling Cohere AI embed-english-v2.0 - 4096d tested on Wikipedia embeddings - 0.98 recall@50 with 2x oversampling Models with a lower dimensionality or a different distribution of vector components may require additional experiments to find the optimal quantization parameters.

We recommend using binary quantization only with rescoring enabled, as it can significantly improve the search quality with just a minor performance impact.

Additionally, oversampling can be used to tune the tradeoff between search speed and search quality in the query time.

Binary Quantization as Hamming Distance The additional benefit of this method is that you can efficiently emulate Hamming distance with dot product.

Specifically, if original vectors contain {-1, 1} as possible values, then the dot product of two vectors is equal to the Hamming distance by simply replacing -1 with 0 and 1 with 1 .

Sample truth table Vector 1 Vector 2 Dot product 1 1 1 1 -1 -1 -1 1 -1 -1 -1 1 Vector 1 Vector 2 Hamming distance 1 1 0 1 0 1 0 1 1 0 0 0 As you can see, both functions are equal up to a constant factor, which makes similarity search equivalent.

Binary quantization makes it efficient to compare vectors using this representation.

1.5-Bit and 2-Bit Quantization Available as of v1.15.0 Binary quantization storage can use 2 and 1.5 bits per dimension, improving precision for smaller vectors. One-bit compression resulted in significant data loss and precision drops for vectors smaller than a thousand dimensions, often requiring expensive rescoring. 2-bit quantization offers 16X compression compared to 32X with one bit, improving performance for smaller vector dimensions. The 1.5-bit quantization compression offers 24X compression and intermediate accuracy.

A major limitation of binary quantization is poor handling of values close to zero.

2-bit quantization addresses this by explicitly representing zeros using an efficient scoring mechanism. In the case of 1.5-bit quantization, the zero-bit is shared between two values, balancing the efficiency of binary quantization with the accuracy improvements of 2-bit quantization, especially when 2-bit BQ requires too much memory.

In order to build 2-bit representation, Qdrant computes values distribution and then assigns bit values to 3 possible buckets: -1 - 00 0 - 01 1 - 11 1.5-bit quantization is similar, but merges buckets of pairs of elements into a binary triptets 2-bit quantization See how to set up 1.5-bit and 2-bit quantization in the following section .

Asymmetric Quantization Available as of v1.15.0 The Asymmetric Quantization technique allows qdrant to use different vector encoding algorithm for stored vectors and for queries.

Particularly interesting combination is a Binary stored vectors and Scalar quantized queries.

Asymmetric quantization This approach maintains storage size and RAM usage similar to binary quantization while offering improved precision. It is beneficial for memory-constrained deployments, or where the bottleneck is disk I/O rather than CPU.

This is particularly useful for indexing millions of vectors as it improves precision without sacrificing much because the limitation in such scenarios is disk speed, not CPU. This approach requires less rescoring for the same quality output.

See how to set up Asymmetric Quantization quantization in the following section Product Quantization Available as of v1.2.0 Product quantization is a method of compressing vectors to minimize their memory usage by dividing them into chunks and quantizing each segment individually.

Each chunk is approximated by a centroid index that represents the original vector component.

The positions of the centroids are determined through the utilization of a clustering algorithm such as k-means.

For now, Qdrant uses only 256 centroids, so each centroid index can be represented by a single byte.

Product quantization can compress by a more prominent factor than a scalar one.

But there are some tradeoffs. Product quantization distance calculations are not SIMD-friendly, so it is slower than scalar quantization.

Also, product quantization has a loss of accuracy, so it is recommended to use it only for high-dimensional vectors.

Please refer to the Quantization Tips section for more information on how to optimize the quantization parameters for your use case.

How to choose the right quantization method Here is a brief table of the pros and cons of each quantization method: Quantization method Accuracy Speed Compression Scalar 0.99 up to x2 4 Product 0.7 0.5 up to 64 Binary (1 bit) 0.95* up to x40 32 Binary (1.5 bit) 0.95** up to x30 24 Binary (2 bit) 0.95*** up to x20 16 * - for compatible models with high-dimensional vectors (approx. 1536+ dimensions) ** - for compatible models with medium-dimensional vectors (approx. 1024-1536 dimensions) *** - for compatible models with low-dimensional vectors (approx. 768-1024 dimensions) Binary Quantization is the fastest method and the most memory-efficient, but it requires a centered distribution of vector components. It is recommended to use with tested models only.

If you are planning to use binary quantization with low or medium-dimensional vectors (approx. 512-1024 dimensions), it is recommended to use 1.5-bit or 2-bit quantization as well as asymmetric quantization feature.

Scalar Quantization is the most universal method, as it provides a good balance between accuracy, speed, and compression. It is recommended as default quantization if binary quantization is not applicable.

Product Quantization may provide a better compression ratio, but it has a significant loss of accuracy and is slower than scalar quantization. It is recommended if the memory footprint is the top priority and the search speed is not critical.

Setting up Quantization in Qdrant You can configure quantization for a collection by specifying the quantization parameters in the quantization_config section of the collection configuration.

Quantization will be automatically applied to all vectors during the indexation process.

Quantized vectors are stored alongside the original vectors in the collection, so you will still have access to the original vectors if you need them.

Available as of v1.1.1 The quantization_config can also be set on a per vector basis by specifying it in a named vector.

Setting up Scalar Quantization To enable scalar quantization, you need to specify the quantization parameters in the quantization_config section of the collection configuration.

When enabling scalar quantization on an existing collection, use a PATCH request or the corresponding update_collection method and omit the vector configuration, as it‚Äôs already defined.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "quantization_config": { "scalar": { "type": "int8", "quantile": 0.99, "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , quantile = 0.99 , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, quantization_config : { scalar : { type : "int8" , quantile : 0.99 , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , QuantizationType , ScalarQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . quantization_config ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . quantile ( 0.99 ) . always_ram ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setQuantile ( 0 .

99f ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , Quantile = 0.99f , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , Quantile : qdrant .

PtrOf ( float32 ( 0.99 )), AlwaysRam : qdrant .

PtrOf ( true ), }, ), }) There are 3 parameters that you can specify in the quantization_config section: type - the type of the quantized vector components. Currently, Qdrant supports only int8 . quantile - the quantile of the quantized vector components.

The quantile is used to calculate the quantization bounds.

For instance, if you specify 0.99 as the quantile, 1% of extreme values will be excluded from the quantization bounds.

Using quantiles lower than 1.0 might be useful if there are outliers in your vector components.

This parameter only affects the resulting precision and not the memory footprint.

It might be worth tuning this parameter if you experience a significant decrease in search quality. always_ram - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.

However, in some setups you might want to keep quantized vectors in RAM to speed up the search process.

In this case, you can set always_ram to true to store quantized vectors in RAM.

Setting up Binary Quantization To enable binary quantization, you need to specify the quantization parameters in the quantization_config section of the collection configuration.

When enabling binary quantization on an existing collection, use a PATCH request or the corresponding update_collection method and omit the vector configuration, as it‚Äôs already defined.

PUT /collections/{collection_name} { "vectors": { "size": 1536, "distance": "Cosine" }, "quantization_config": { "binary": { "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 1536 , distance = models .

Distance .

COSINE ), quantization_config = models .

BinaryQuantization ( binary = models .

BinaryQuantizationConfig ( always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 1536 , distance : "Cosine" , }, quantization_config : { binary : { always_ram : true , }, }, }); use qdrant_client :: qdrant :: { BinaryQuantizationBuilder , CreateCollectionBuilder , Distance , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 1536 , Distance :: Cosine )) . quantization_config ( BinaryQuantizationBuilder :: new ( true )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.BinaryQuantization ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 1536 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setBinary ( BinaryQuantization . newBuilder (). setAlwaysRam ( true ). build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 1536 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Binary = new BinaryQuantization { AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 1536 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationBinary ( & qdrant .

BinaryQuantization { AlwaysRam : qdrant .

PtrOf ( true ), }, ), }) always_ram - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.

However, in some setups you might want to keep quantized vectors in RAM to speed up the search process.

In this case, you can set always_ram to true to store quantized vectors in RAM.

Set up bit depth To enable 2bit or 1.5bit quantization, you need to specify encoding parameter in the quantization_config section of the collection configuration. Available values are two_bits and one_and_half_bits .

PUT /collections/{collection_name} { "vectors": { "size": 1536, "distance": "Cosine" }, "quantization_config": { "binary": { "encoding": "two_bits", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 1536 , distance = models .

Distance .

COSINE ), quantization_config = models .

BinaryQuantization ( binary = models .

BinaryQuantizationConfig ( encoding = models .

BinaryQuantizationEncoding .

TWO_BITS , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 1536 , distance : "Cosine" , }, quantization_config : { binary : { encoding : "two_bits" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { BinaryQuantizationBuilder , CreateCollectionBuilder , Distance , VectorParamsBuilder , BinaryQuantizationEncoding , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 1536 , Distance :: Cosine )) . quantization_config ( BinaryQuantizationBuilder :: new ( true ) . encoding ( BinaryQuantizationEncoding :: TwoBits ) ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.BinaryQuantization ; import io.qdrant.client.grpc.Collections.BinaryQuantizationEncoding ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 1536 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setBinary ( BinaryQuantization . newBuilder () . setEncoding ( BinaryQuantizationEncoding .

TwoBits ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 1536 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Binary = new BinaryQuantization { Encoding = BinaryQuantizationEncoding .

TwoBits , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 1536 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationBinary ( & qdrant .

BinaryQuantization { Encoding : qdrant .

BinaryQuantizationEncoding_TwoBits .

Enum (), AlwaysRam : qdrant .

PtrOf ( true ), }, ), }) Set up asymmetric quantization To enable asymmetric quantization, you need to specify query_encoding parameter in the quantization_config section of the collection configuration. Available values are: default and binary - use regular binary quantization for the query. scalar8bits - use 8bit quantization for the query. scalar4bits - use 4bit quantization for the query.

PUT /collections/{collection_name} { "vectors": { "size": 1536, "distance": "Cosine" }, "quantization_config": { "binary": { "query_encoding": "scalar8bits", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 1536 , distance = models .

Distance .

COSINE ), quantization_config = models .

BinaryQuantization ( binary = models .

BinaryQuantizationConfig ( query_encoding = models .

BinaryQuantizationQueryEncoding .

SCALAR8BITS , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 1536 , distance : "Cosine" , }, quantization_config : { binary : { query_encoding : "scalar8bits" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { BinaryQuantizationBuilder , CreateCollectionBuilder , Distance , VectorParamsBuilder , BinaryQuantizationQueryEncoding , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 1536 , Distance :: Cosine )) . quantization_config ( BinaryQuantizationBuilder :: new ( true ) . query_encoding ( BinaryQuantizationQueryEncoding :: scalar8bits ()) ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.BinaryQuantization ; import io.qdrant.client.grpc.Collections.BinaryQuantizationQueryEncoding ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 1536 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setBinary ( BinaryQuantization . newBuilder () . setQueryEncoding ( BinaryQuantizationQueryEncoding . newBuilder () . setSetting ( BinaryQuantizationQueryEncoding .

Setting .

Scalar8Bits ) . build ()) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 1536 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Binary = new BinaryQuantization { QueryEncoding = new BinaryQuantizationQueryEncoding { Setting = BinaryQuantizationQueryEncoding .

Types .

Setting .

Scalar8Bits , }, AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 1536 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationBinary ( & qdrant .

BinaryQuantization { QueryEncoding : qdrant .

NewBinaryQuantizationQueryEncodingSetting ( qdrant .

BinaryQuantizationQueryEncoding_Scalar8Bits ), AlwaysRam : qdrant .

PtrOf ( true ), }, ), }) Setting up Product Quantization To enable product quantization, you need to specify the quantization parameters in the quantization_config section of the collection configuration.

When enabling product quantization on an existing collection, use a PATCH request or the corresponding update_collection method and omit the vector configuration, as it‚Äôs already defined.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "quantization_config": { "product": { "compression": "x16", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), quantization_config = models .

ProductQuantization ( product = models .

ProductQuantizationConfig ( compression = models .

CompressionRatio .

X16 , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, quantization_config : { product : { compression : "x16" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { CompressionRatio , CreateCollectionBuilder , Distance , ProductQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . quantization_config ( ProductQuantizationBuilder :: new ( CompressionRatio :: X16 . into ()). always_ram ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CompressionRatio ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.ProductQuantization ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setProduct ( ProductQuantization . newBuilder () . setCompression ( CompressionRatio . x16 ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Product = new ProductQuantization { Compression = CompressionRatio .

X16 , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationProduct ( & qdrant .

ProductQuantization { Compression : qdrant .

CompressionRatio_x16 , AlwaysRam : qdrant .

PtrOf ( true ), }, ), }) There are two parameters that you can specify in the quantization_config section: compression - compression ratio.

Compression ratio represents the size of the quantized vector in bytes divided by the size of the original vector in bytes.

In this case, the quantized vector will be 16 times smaller than the original vector. always_ram - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.

However, in some setups you might want to keep quantized vectors in RAM to speed up the search process. Then set always_ram to true .

Disabling Quantization To disable quantization in an existing collection, you can do the following: PATCH /collections/{collection_name} { "quantization_config": "Disabled" } curl -X PATCH http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "quantization_config": "Disabled" }' client . update_collection ( collection_name = " {collection_name} " , quantization_config = models .

Disabled .

DISABLED , ) client . updateCollection ( "{collection_name}" , { quantization_config : 'Disabled' }); use qdrant_client :: qdrant :: { Disabled , UpdateCollectionBuilder }; client . update_collection ( UpdateCollectionBuilder :: new ( "{collection_name}" ). quantization_config ( Disabled {})) . await ? ; import io.qdrant.client.grpc.Collections.Disabled ; import io.qdrant.client.grpc.Collections.QuantizationConfigDiff ; import io.qdrant.client.grpc.Collections.UpdateCollection ; client . updateCollectionAsync ( UpdateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuantizationConfig ( QuantizationConfigDiff . newBuilder () . setDisabled ( Disabled . getDefaultInstance ()) . build ()) . build ()); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionAsync ( collectionName : "{collection_name}" , quantizationConfig : new QuantizationConfigDiff { Disabled = new Disabled () } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateCollection ( context .

Background (), & qdrant .

UpdateCollection { CollectionName : "{collection_name}" , QuantizationConfig : qdrant .

NewQuantizationDiffDisabled (), }) Searching with Quantization Once you have configured quantization for a collection, you don‚Äôt need to do anything extra to search with quantization.

Qdrant will automatically use quantized vectors if they are available.

However, there are a few options that you can use to control the search process: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "quantization": { "ignore": false, "rescore": true, "oversampling": 2.0 } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( quantization = models .

QuantizationSearchParams ( ignore = False , rescore = True , oversampling = 2.0 , ) ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { quantization : { ignore : false , rescore : true , oversampling : 2.0 , }, }, limit : 10 , }); use qdrant_client :: qdrant :: { QuantizationSearchParamsBuilder , QueryPointsBuilder , SearchParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 10 ) . params ( SearchParamsBuilder :: default (). quantization ( QuantizationSearchParamsBuilder :: default () . ignore ( false ) . rescore ( true ) . oversampling ( 2.0 ), ), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QuantizationSearchParams ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder () . setQuantization ( QuantizationSearchParams . newBuilder () . setIgnore ( false ) . setRescore ( true ) . setOversampling ( 2 .

0 ) . build ()) . build ()) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { Quantization = new QuantizationSearchParams { Ignore = false , Rescore = true , Oversampling = 2.0 } }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { Quantization : & qdrant .

QuantizationSearchParams { Ignore : qdrant .

PtrOf ( false ), Rescore : qdrant .

PtrOf ( true ), Oversampling : qdrant .

PtrOf ( 2.0 ), }, }, }) ignore - Toggle whether to ignore quantized vectors during the search process. By default, Qdrant will use quantized vectors if they are available. rescore - Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors.

This can improve the search quality, but may slightly decrease the search speed, compared to the search without rescore.

It is recommended to disable rescore only if the original vectors are stored on a slow storage (e.g. HDD or network storage).

By default, rescore is enabled.

Available as of v1.3.0 oversampling - Defines how many extra vectors should be pre-selected using quantized index, and then re-scored using original vectors.

For example, if oversampling is 2.4 and limit is 100, then 240 vectors will be pre-selected using quantized index, and then top-100 will be returned after re-scoring.

Oversampling is useful if you want to tune the tradeoff between search speed and search quality in the query time.

Quantization tips Accuracy tuning In this section, we will discuss how to tune the search precision.

The fastest way to understand the impact of quantization on the search quality is to compare the search results with and without quantization.

In order to disable quantization, you can set ignore to true in the search request: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "quantization": { "ignore": true } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( quantization = models .

QuantizationSearchParams ( ignore = True , ) ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { quantization : { ignore : true , }, }, }); use qdrant_client :: qdrant :: { QuantizationSearchParamsBuilder , QueryPointsBuilder , SearchParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . params ( SearchParamsBuilder :: default () . quantization ( QuantizationSearchParamsBuilder :: default (). ignore ( true )), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QuantizationSearchParams ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder () . setQuantization ( QuantizationSearchParams . newBuilder (). setIgnore ( true ). build ()) . build ()) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { Quantization = new QuantizationSearchParams { Ignore = true } }, limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { Quantization : & qdrant .

QuantizationSearchParams { Ignore : qdrant .

PtrOf ( false ), }, }, }) Adjust the quantile parameter : The quantile parameter in scalar quantization determines the quantization bounds.

By setting it to a value lower than 1.0, you can exclude extreme values (outliers) from the quantization bounds.

For example, if you set the quantile to 0.99, 1% of the extreme values will be excluded.

By adjusting the quantile, you find an optimal value that will provide the best search quality for your collection.

Enable rescore : Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors. On large collections, this can improve the search quality, with just minor performance impact.

Memory and speed tuning In this section, we will discuss how to tune the memory and speed of the search process with quantization.

There are 3 possible modes to place storage of vectors within the qdrant collection: All in RAM - all vector, original and quantized, are loaded and kept in RAM. This is the fastest mode, but requires a lot of RAM. Enabled by default.

Original on Disk, quantized in RAM - this is a hybrid mode, allows to obtain a good balance between speed and memory usage. Recommended scenario if you are aiming to shrink the memory footprint while keeping the search speed.

This mode is enabled by setting always_ram to true in the quantization config while using memmap storage: PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "quantization_config": { "scalar": { "type": "int8", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, quantization_config : { scalar : { type : "int8" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , QuantizationType , ScalarQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . quantization_config ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . always_ram ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, quantizationConfig : new QuantizationConfig { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), QuantizationConfig : qdrant .

NewQuantizationScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , AlwaysRam : qdrant .

PtrOf ( true ), }), }) In this scenario, the number of disk reads may play a significant role in the search speed.

In a system with high disk latency, the re-scoring step may become a bottleneck.

Consider disabling rescore to improve the search speed: POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "quantization": { "rescore": false } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( quantization = models .

QuantizationSearchParams ( rescore = False ) ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { quantization : { rescore : false , }, }, }); use qdrant_client :: qdrant :: { QuantizationSearchParamsBuilder , QueryPointsBuilder , SearchParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . params ( SearchParamsBuilder :: default () . quantization ( QuantizationSearchParamsBuilder :: default (). rescore ( false )), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QuantizationSearchParams ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder () . setQuantization ( QuantizationSearchParams . newBuilder (). setRescore ( false ). build ()) . build ()) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { Quantization = new QuantizationSearchParams { Rescore = false } }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { Quantization : & qdrant .

QuantizationSearchParams { Rescore : qdrant .

PtrOf ( false ), }, }, }) All on Disk - all vectors, original and quantized, are stored on disk. This mode allows to achieve the smallest memory footprint, but at the cost of the search speed.

It is recommended to use this mode if you have a large collection and fast storage (e.g. SSD or NVMe).

This mode is enabled by setting always_ram to false in the quantization config while using mmap storage: PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "quantization_config": { "scalar": { "type": "int8", "always_ram": false } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , always_ram = False , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, quantization_config : { scalar : { type : "int8" , always_ram : false , }, }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , QuantizationType , ScalarQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine ). on_disk ( true )) . quantization_config ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . always_ram ( false ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setAlwaysRam ( false ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, quantizationConfig : new QuantizationConfig { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , AlwaysRam = false } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), QuantizationConfig : qdrant .

NewQuantizationScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , AlwaysRam : qdrant .

PtrOf ( false ), }, ), })
================================================================================
PAGE 19/39
================================================================================
Title: Installation requirements
URL: https://qdrant.tech/documentation/guides/installation/
--------------------------------------------------------------------------------

Installation requirements The following sections describe the requirements for deploying Qdrant.

CPU and memory The preferred size of your CPU and RAM depends on: Number of vectors Vector dimensions Payloads and their indexes Storage Replication How you configure quantization Our Cloud Pricing Calculator can help you estimate required resources without payload or index data.

Supported CPU architectures: 64-bit system: x86_64/amd64 AArch64/arm64 32-bit system: Not supported Storage For persistent storage, Qdrant requires block-level access to storage devices with a POSIX-compatible file system . Network systems such as iSCSI that provide block-level access are also acceptable.

Qdrant won‚Äôt work with Network file systems such as NFS, or Object storage systems such as S3.

If you offload vectors to a local disk, we recommend you use a solid-state (SSD or NVMe) drive.

Networking Each Qdrant instance requires three open ports: 6333 - For the HTTP API, for the Monitoring health and metrics endpoints 6334 - For the gRPC API 6335 - For Distributed deployment All Qdrant instances in a cluster must be able to: Communicate with each other over these ports Allow incoming connections to ports 6333 and 6334 from clients that use Qdrant.

Security The default configuration of Qdrant might not be secure enough for every situation. Please see our security documentation for more information.

Installation options Qdrant can be installed in different ways depending on your needs: For production, you can use our Qdrant Cloud to run Qdrant either fully managed in our infrastructure or with Hybrid Cloud in yours.

If you want to run Qdrant in your own infrastructure, without any cloud connection, we recommend to install Qdrant in a Kubernetes cluster with our Qdrant Private Cloud Enterprise Operator.

For testing or development setups, you can run the Qdrant container or as a binary executable. We also provide a Helm chart for an easy installation in Kubernetes.

Production Qdrant Cloud You can set up production with the Qdrant Cloud , which provides fully managed Qdrant databases.

It provides horizontal and vertical scaling, one click installation and upgrades, monitoring, logging, as well as backup and disaster recovery. For more information, see the Qdrant Cloud documentation .

Qdrant Kubernetes Operator We provide a Qdrant Enterprise Operator for Kubernetes installations as part of our Qdrant Private Cloud offering. For more information, use this form to contact us.

Kubernetes You can use a ready-made Helm Chart to run Qdrant in your Kubernetes cluster. While it is possible to deploy Qdrant in a distributed setup with the Helm chart, it does not come with the same level of features for zero-downtime upgrades, up and down-scaling, monitoring, logging, and backup and disaster recovery as the Qdrant Cloud offering or the Qdrant Private Cloud Enterprise Operator. Instead you must manage and set this up yourself . Support for the Helm chart is limited to community support.

The following table gives you an overview about the feature differences between the Qdrant Cloud and the Helm chart: Feature Qdrant Helm Chart Qdrant Cloud Open-source ‚úÖ Community support only ‚úÖ Quick to get started ‚úÖ ‚úÖ Vertical and horizontal scaling ‚úÖ ‚úÖ API keys with granular access control ‚úÖ ‚úÖ Qdrant version upgrades ‚úÖ ‚úÖ Support for transit and storage encryption ‚úÖ ‚úÖ Zero-downtime upgrades with optimized restart strategy ‚úÖ Production ready out-of the box ‚úÖ Dataloss prevention on downscaling ‚úÖ Full cluster backup and disaster recovery ‚úÖ Automatic shard rebalancing ‚úÖ Re-sharding support ‚úÖ Automatic persistent volume scaling ‚úÖ Advanced telemetry ‚úÖ One-click API key revoking ‚úÖ Recreating nodes with new volumes in existing cluster ‚úÖ Enterprise support ‚úÖ To install the helm chart: helm repo add qdrant https://qdrant.to/helm helm install qdrant qdrant/qdrant For more information, see the qdrant-helm README.

Docker and Docker Compose Usually, we recommend to run Qdrant in Kubernetes, or use the Qdrant Cloud for production setups. This makes setting up highly available and scalable Qdrant clusters with backups and disaster recovery a lot easier.

However, you can also use Docker and Docker Compose to run Qdrant in production, by following the setup instructions in the Docker and Docker Compose Development sections.

In addition, you have to make sure: To use a performant persistent storage for your data To configure the security settings for your deployment To set up and configure Qdrant on multiple nodes for a highly available distributed deployment To set up a load balancer for your Qdrant cluster To create a backup and disaster recovery strategy for your data To integrate Qdrant with your monitoring and logging solutions Development For development and testing, we recommend that you set up Qdrant in Docker. We also have different client libraries.

Docker The easiest way to start using Qdrant for testing or development is to run the Qdrant container image.

The latest versions are always available on DockerHub .

Make sure that Docker , Podman or the container runtime of your choice is installed and running. The following instructions use Docker.

Pull the image: docker pull qdrant/qdrant In the following command, revise $(pwd)/path/to/data for your Docker configuration. Then use the updated command to run the container: docker run -p 6333:6333 \ -v $( pwd ) /path/to/data:/qdrant/storage \ qdrant/qdrant With this command, you start a Qdrant instance with the default configuration.

It stores all data in the ./path/to/data directory.

By default, Qdrant uses port 6333, so at localhost:6333 you should see the welcome message.

To change the Qdrant configuration, you can overwrite the production configuration: docker run -p 6333:6333 \ -v $( pwd ) /path/to/data:/qdrant/storage \ -v $( pwd ) /path/to/custom_config.yaml:/qdrant/config/production.yaml \ qdrant/qdrant Alternatively, you can use your own custom_config.yaml configuration file: docker run -p 6333:6333 \ -v $( pwd ) /path/to/data:/qdrant/storage \ -v $( pwd ) /path/to/custom_config.yaml:/qdrant/config/custom_config.yaml \ qdrant/qdrant \ ./qdrant --config-path config/custom_config.yaml For more information, see the Configuration documentation.

Docker Compose You can also use Docker Compose to run Qdrant.

Here is an example customized compose file for a single node Qdrant cluster: services : qdrant : image : qdrant/qdrant:latest restart : always container_name : qdrant ports : - 6333 : 6333 - 6334 : 6334 expose : - 6333 - 6334 - 6335 configs : - source : qdrant_config target : /qdrant/config/production.yaml volumes : - ./qdrant_data:/qdrant/storage configs : qdrant_config : content : | log_level: INFO From source Qdrant is written in Rust and can be compiled into a binary executable.

This installation method can be helpful if you want to compile Qdrant for a specific processor architecture or if you do not want to use Docker.

Before compiling, make sure that the necessary libraries and the rust toolchain are installed.

The current list of required libraries can be found in the Dockerfile .

Build Qdrant with Cargo: cargo build --release --bin qdrant After a successful build, you can find the binary in the following subdirectory ./target/release/qdrant .

Client libraries In addition to the service, Qdrant provides a variety of client libraries for different programming languages. For a full list, see our Client libraries documentation.

================================================================================
PAGE 20/39
================================================================================
Title: Administration
URL: https://qdrant.tech/documentation/guides/administration/
--------------------------------------------------------------------------------

Administration Qdrant exposes administration tools which enable to modify at runtime the behavior of a qdrant instance without changing its configuration manually.

Recovery mode Available as of v1.2.0 Recovery mode can help in situations where Qdrant fails to start repeatedly.

When starting in recovery mode, Qdrant only loads collection metadata to prevent going out of memory. This allows you to resolve out of memory situations, for example, by deleting a collection. After resolving Qdrant can be restarted normally to continue operation.

In recovery mode, collection operations are limited to deleting a collection. That is because only collection metadata is loaded during recovery.

To enable recovery mode with the Qdrant Docker image you must set the environment variable QDRANT_ALLOW_RECOVERY_MODE=true . The container will try to start normally first, and restarts in recovery mode if initialisation fails due to an out of memory error. This behavior is disabled by default.

If using a Qdrant binary, recovery mode can be enabled by setting a recovery message in an environment variable, such as QDRANT__STORAGE__RECOVERY_MODE="My recovery message" .

Strict mode Available as of v1.13.0 Strict mode is a feature to restrict certain type of operations on a collection in order to protect the Qdrant cluster.

The goal is to prevent inefficient usage patterns that could overload the system.

Strict mode ensures a more predictable and responsive service when you do not have control over the queries that are being executed.

Upon crossing a limit, the server will return a client side error with the information about the limit that was crossed.

The strict_mode_config can be enabled when creating a new collection, see schema definitions for all the available strict_mode_config parameters.

As part of the config, the enabled field act as a toggle to enable or disable the strict mode dynamically.

It is possible to raise the default limits and/or disable strict mode entirely. Though, in order to ensure a stable cluster we strongly recommend to keep strict mode enabled using its default configuration. For disabling strict mode on an existing collection use: PUT /collections/{collection_name} { "strict_mode_config": { "enabled": false } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" false } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = False ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : false , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( false )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( false ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = false } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( false ), }, }) Disable retrieving via non indexed payload Setting unindexed_filtering_retrieve to false prevents retrieving points by filtering on a non indexed payload key which can be very slow.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "unindexed_filtering_retrieve": false } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "unindexed_filtering_retrieve": false } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , unindexed_filtering_retrieve = False ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , unindexed_filtering_retrieve : false , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). unindexed_filtering_retrieve ( false )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setUnindexedFilteringRetrieve ( false ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , UnindexedFilteringRetrieve = false } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), UnindexedFilteringRetrieve : qdrant .

PtrOf ( false ), }, }) Or turn it off later on an existing collection through the collection update API.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "unindexed_filtering_retrieve": true } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "unindexed_filtering_retrieve": true } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , unindexed_filtering_retrieve = True ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , unindexed_filtering_retrieve : true , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). unindexed_filtering_retrieve ( true )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setUnindexedFilteringRetrieve ( true ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , UnindexedFilteringRetrieve = true } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), UnindexedFilteringRetrieve : qdrant .

PtrOf ( true ), }, }) Disable updating via non indexed payload Setting unindexed_filtering_update to false prevents updating points by filtering on a non indexed payload key which can be very slow.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "unindexed_filtering_update": false } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "unindexed_filtering_update": false } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , unindexed_filtering_update = False ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , unindexed_filtering_update : false , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). unindexed_filtering_update ( false )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setUnindexedFilteringUpdate ( false ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , UnindexedFilteringUpdate = false } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), UnindexedFilteringUpdate : qdrant .

PtrOf ( false ), }, }) Maximum number of payload index count Setting max_payload_index_count caps the maximum number of payload index that can exist on a collection.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "max_payload_index_count": 10 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "max_payload_index_count": 10 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , max_payload_index_count = 10 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , max_payload_index_count : 10 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). max_payload_index_count ( 10 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setMaxPayloadIndexCount ( 10 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , MaxPayloadIndexCount = 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), MaxPayloadIndexCount : qdrant .

PtrOf ( uint64 ( 10 )), }, }) Maximum query limit parameter Retrieving large result set is expensive.

Setting max_query_limit caps the maximum number of points that can be retrieved in a single query.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "max_query_limit": 10 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "max_query_limit": 10 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , max_query_limit = 10 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , max_query_limit : 10 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). max_query_limit ( 10 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setMaxQueryLimit ( 10 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , MaxQueryLimit = 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), MaxQueryLimit : qdrant .

PtrOf ( uint32 ( 10 )), }, }) Maximum timeout parameter Long running operations are often symptomatic of a deeper issue.

Setting max_timeout caps the maximum value in seconds for the timeout parameter in all API operations.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "max_timeout": 10 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "max_timeout": 10 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , max_timeout = 10 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , max_timeout : 10 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). max_timeout ( 10 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setMaxTimeout ( 10 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , MaxTimeout = 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), MaxTimeout : qdrant .

PtrOf ( uint32 ( 10 )), }, }) Maximum size of a filtering condition Large filtering conditions are expensive to evaluate.

Setting condition_max_size caps the maximum number of element a filtering condition can have. e.g. the number of elements in MatchAny PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "condition_max_size": 10 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "condition_max_size": 10 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , condition_max_size = 10 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , condition_max_size : 10 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). condition_max_size ( 10 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setConditionMaxSize ( 10 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , ConditionMaxSize = 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), ConditionMaxSize : qdrant .

PtrOf ( uint64 ( 10 )), }, }) Maximum number of conditions in a filter A large number of filtering conditions are expensive to evaluate.

Setting filter_max_conditions caps the maximum number of conditions filters can have.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "filter_max_conditions": 10 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "filter_max_conditions": 10 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , filter_max_conditions = 10 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , filter_max_conditions : 10 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). filter_max_conditions ( 10 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setFilterMaxConditions ( 10 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , FilterMaxConditions = 10 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), FilterMaxConditions : qdrant .

PtrOf ( uint64 ( 10 )), }, }) Maximum batch size when inserting vectors Sending very large batch upserts can create internal congestion.

Setting upsert_max_batchsize caps the maximum size in bytes of a batch during vector upserts.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "upsert_max_batchsize": 1000 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "upsert_max_batchsize": 1000 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , upsert_max_batchsize = 1000 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , upsert_max_batchsize : 1000 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). upsert_max_batchsize ( 1000 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setUpsertMaxBatchsize ( 1000 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , UpsertMaxBatchsize = 1000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), UpsertMaxBatchsize : qdrant .

PtrOf ( uint64 ( 1000 )), }, }) Maximum collection storage size It is possible to set the maximum size of a collection in terms of vectors and/or payload storage size.

Setting max_collection_vector_size_bytes and/or max_collection_payload_size_bytes caps the maximum byte size of a collection.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "max_collection_vector_size_bytes": 1000000, "max_collection_payload_size_bytes": 1000000 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "max_collection_vector_size_bytes": 100000, "max_collection_payload_size_bytes": 100000 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , max_collection_vector_size_bytes = 1000000 , max_collection_payload_size_bytes = 1000000 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , max_collection_vector_size_bytes : 1000000 , max_collection_payload_size_bytes : 1000000 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). max_collection_vector_size_bytes ( 1000000 ). max_collection_payload_size_bytes ( 1000000 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setMaxCollectionVectorSizeBytes ( 1000000 ). setMaxCollectionPayloadSizeBytes ( 1000000 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , MaxCollectionVectorSizeBytes = 1000000 , MaxCollectionPayloadSizeBytes = 1000000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), MaxCollectionVectorSizeBytes : qdrant .

PtrOf ( uint64 ( 1000000 )), MaxCollectionPayloadSizeBytes : qdrant .

PtrOf ( uint64 ( 1000000 )), }, }) Maximum points count Setting max_points_count caps the maximum number of points for a collection.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "max_points_count": 1000 } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "max_points_count": 1000 } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , max_points_count = 1000 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , max_points_count : 1000 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). max_points_count ( 1000 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setMaxPointsCount ( 1000 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , MaxPointsCount = 1000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), MaxPointsCount : qdrant .

PtrOf ( uint64 ( 1000 )), }, }) Rate limiting An extremely high rate of incoming requests can have a negative impact on the latency.

Setting read_rate_limit and/or write_rate_limit to cap the maximum number of operations per minute per replica.

When exceeding the maximum number of operations, the client will receive an HTTP 429 error code with a suggested delay before retrying.

PUT /collections/{collection_name} { "strict_mode_config": { "enabled": true, "read_rate_limit": 1000, "write_rate_limit": 100, } } curl -X PUT http://localhost:6333/collections/ { collection_name } \ -H 'Content-Type: application/json' \ --data-raw '{ "strict_mode_config": { "enabled":" true, "read_rate_limit": 1000, "write_rate_limit": 100, } }' from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , strict_mode_config = models .

StrictModeConfig ( enabled = True , read_rate_limit = 1000 , write_rate_limit = 1000 ,), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { strict_mode_config : { enabled : true , read_rate_limit : 1000 , write_rate_limit : 100 , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { CreateCollectionBuilder , StrictModeConfigBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . strict_mode_config ( StrictModeConfigBuilder :: default (). enabled ( true ). read_rate_limit ( 1000 ). write_rate_limit ( 100 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.StrictModeConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setStrictModeConfig ( StrictModeConfig . newBuilder (). setEnabled ( true ). setReadRateLimit ( 1000 ). setWriteRateLimit ( 100 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , strictModeConfig : new StrictModeConfig { Enabled = true , ReadRateLimit = 1000 , WriteRateLimit = 100 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , StrictModeConfig : & qdrant .

StrictModeConfig { Enabled : qdrant .

PtrOf ( true ), ReadRateLimit : qdrant .

PtrOf ( uint32 ( 1000 )), WriteRateLimit : qdrant .

PtrOf ( uint32 ( 100 )), }, })
================================================================================
PAGE 21/39
================================================================================
Title: Running Qdrant with GPU Support
URL: https://qdrant.tech/documentation/guides/running-with-gpu/
--------------------------------------------------------------------------------

Running Qdrant with GPU Support Starting from version v1.13.0, Qdrant offers support for GPU acceleration.

However, GPU support is not included in the default Qdrant binary due to additional dependencies and libraries. Instead, you will need to use dedicated Docker images with GPU support ( NVIDIA , AMD ).

Configuration Qdrant includes a number of configuration options to control GPU usage. The following options are available: gpu : # Enable GPU indexing. indexing : false # Force half precision for `f32` values while indexing.

# `f16` conversion will take place # only inside GPU memory and won't affect storage type. force_half_precision : false # Used vulkan "groups" of GPU.

# In other words, how many parallel points can be indexed by GPU.

# Optimal value might depend on the GPU model.

# Proportional, but doesn't necessary equal # to the physical number of warps.

# Do not change this value unless you know what you are doing.

# Default: 512 groups_count : 512 # Filter for GPU devices by hardware name. Case insensitive.

# Comma-separated list of substrings to match # against the gpu device name.

# Example: "nvidia" # Default: "" - all devices are accepted. device_filter : "" # List of explicit GPU devices to use.

# If host has multiple GPUs, this option allows to select specific devices # by their index in the list of found devices.

# If `device_filter` is set, indexes are applied after filtering.

# By default, all devices are accepted. devices : null # How many parallel indexing processes are allowed to run.

# Default: 1 parallel_indexes : 1 # Allow to use integrated GPUs.

# Default: false allow_integrated : false # Allow to use emulated GPUs like LLVMpipe. Useful for CI.

# Default: false allow_emulated : false It is not recommended to change these options unless you are familiar with the Qdrant internals and the Vulkan API.

Standalone GPU Support For standalone usage, you can build Qdrant with GPU support by running the following command: cargo build --release --features gpu Ensure your device supports Vulkan API v1.3. This includes compatibility with Apple Silicon, Intel GPUs, and CPU emulators. Note that gpu.indexing: true must be set in your configuration to use GPUs at runtime.

NVIDIA GPUs Prerequisites To use Docker with NVIDIA GPU support, ensure the following are installed on your host: Latest NVIDIA drivers nvidia-container-toolkit Most AI or CUDA images on Amazon/GCP come pre-configured with the NVIDIA container toolkit.

Docker images with NVIDIA GPU support Docker images with NVIDIA GPU support use the tag suffix gpu-nvidia , e.g., qdrant/qdrant:v1.13.0-gpu-nvidia . These images include all necessary dependencies.

To enable GPU support, use the --gpus=all flag with Docker settings. Example: # `--gpus=all` flag says to Docker that we want to use GPUs.

# `-e QDRANT__GPU__INDEXING=1` flag says to Qdrant that we want to use GPUs for indexing. docker run \ --rm \ --gpus = all \ -p 6333:6333 \ -p 6334:6334 \ -e QDRANT__GPU__INDEXING = 1 \ qdrant/qdrant:gpu-nvidia-latest To ensure that the GPU was initialized correctly, you may check it in logs. First Qdrant prints all found GPU devices without filtering and then prints list of all created devices: 2025-01-13T11:58:29.124087Z  INFO gpu::instance: Found GPU device: NVIDIA GeForce RTX 3090 2025-01-13T11:58:29.124118Z  INFO gpu::instance: Found GPU device: llvmpipe (LLVM 15.0.7, 256 bits) 2025-01-13T11:58:29.124138Z  INFO gpu::device: Create GPU device NVIDIA GeForce RTX 3090 Here you can see that two devices were found: RTX 3090 and llvmpipe (a CPU-emulated GPU which is included in the Docker image). Later, you will see that only RTX was initialized.

This concludes the setup. Now, you can start using this Qdrant instance.

Troubleshooting NVIDIA GPUs If your GPU is not detected in Docker, make sure your driver and nvidia-container-toolkit are up-to-date.

If needed, you can install latest version of nvidia-container-toolkit from it‚Äôs GitHub Releases page Verify Vulkan API visibility in the Docker container using: docker run --rm --gpus = all qdrant/qdrant:gpu-nvidia-latest vulkaninfo --summary The system may show you an error message explaining why the NVIDIA device is not visible.

Note that if your NVIDIA GPU is not visible in Docker, the Docker image cannot use libGLX_nvidia.so.0 on your host. Here is what an error message could look like: ERROR: [Loader Message] Code 0 : loader_scanned_icd_add: Could not get `vkCreateInstance` via `vk_icdGetInstanceProcAddr` for ICD libGLX_nvidia.so.0 WARNING: [Loader Message] Code 0 : terminator_CreateInstance: Failed to CreateInstance in ICD 0. Skipping ICD.

To resolve errors, update your NVIDIA container runtime configuration: sudo nano /etc/nvidia-container-runtime/config.toml Set no-cgroups=false , save the configuration, and restart Docker: sudo systemctl restart docker AMD GPUs Prerequisites Running Qdrant with AMD GPUs requires ROCm to be installed on your host.

Docker images with AMD GPU support Docker images for AMD GPUs use the tag suffix gpu-amd , e.g., qdrant/qdrant:v1.13.0-gpu-amd . These images include all required dependencies.

To enable GPU for Docker, you need additional --device /dev/kfd --device /dev/dri flags. To enable GPU for Qdrant you need to set the enable flag. Here is an example: # `--device /dev/kfd --device /dev/dri` flags say to Docker that we want to use GPUs.

# `-e QDRANT__GPU__INDEXING=1` flag says to Qdrant that we want to use GPUs for indexing. docker run \ --rm \ --device /dev/kfd --device /dev/dri \ -p 6333:6333 \ -p 6334:6334 \ -e QDRANT__LOG_LEVEL = debug \ -e QDRANT__GPU__INDEXING = 1 \ qdrant/qdrant:gpu-amd-latest Check logs to confirm GPU initialization. Example log output: 2025-01-10T11:56:55.926466Z  INFO gpu::instance: Found GPU device: AMD Radeon Graphics (RADV GFX1103_R1) 2025-01-10T11:56:55.926485Z  INFO gpu::instance: Found GPU device: llvmpipe (LLVM 17.0.6, 256 bits) 2025-01-10T11:56:55.926504Z  INFO gpu::device: Create GPU device AMD Radeon Graphics (RADV GFX1103_R1) This concludes the setup. In a basic scenario, you won‚Äôt need to configure anything else.

Known limitations Platform Support: Docker images are only available for Linux x86_64. Windows, macOS, ARM, and other platforms are not supported.

Memory Limits: Each GPU can process up to 16GB of vector data per indexing iteration.

Due to this limitation, you should not create segments where either original vectors OR quantized vectors are larger than 16GB.

For example, a collection with 1536d vectors and scalar quantization can have at most: 16Gb / 1536 ~= 11 million vectors per segment And without quantization: 16Gb / 1536 * 4 ~= 2.7 million vectors per segment The maximum size of each segment can be configured in the collection settings.

Use the following operation to change on your existing collection: PATCH collections/{collection_name} { "optimizers_config": { "max_segment_size": 1000000 } } Note that max_segment_size is specified in KiloBytes.

================================================================================
PAGE 22/39
================================================================================
Title: Capacity Planning
URL: https://qdrant.tech/documentation/guides/capacity-planning/
--------------------------------------------------------------------------------

Capacity Planning When setting up your cluster, you‚Äôll need to figure out the right balance of RAM and disk storage . The best setup depends on a few things: How many vectors you have and their dimensions.

The amount of payload data you‚Äôre using and their indexes.

What data you want to store in memory versus on disk.

Your cluster‚Äôs replication settings.

Whether you‚Äôre using quantization and how you‚Äôve set it up.

Calculating RAM size You should store frequently accessed data in RAM for faster retrieval. If you want to keep all vectors in memory for optimal performance, you can use this rough formula for estimation: memory_size = number_of_vectors * vector_dimension * 4 bytes * 1.5 At the end, we multiply everything by 1.5. This extra 50% accounts for metadata (such as indexes and point versions) and temporary segments created during optimization.

Let‚Äôs say you want to store 1 million vectors with 1024 dimensions: memory_size = 1,000,000 * 1024 * 4 bytes * 1.5 The memory_size is approximately 6,144,000,000 bytes, or about 5.72 GB.

Depending on the use case, large datasets can benefit from reduced memory requirements via quantization .

Calculating payload size This is always different. The size of the payload depends on the structure and content of your data . For instance: Text fields consume space based on length and encoding (e.g. a large chunk of text vs a few words).

Floats have fixed sizes of 8 bytes for int64 or float64 .

Boolean fields typically consume 1 byte.

Calculating total payload size is similar to vectors. We have to multiply it by 1.5 for back-end indexing processes. total_payload_size = number_of_points * payload_size * 1.5 Let‚Äôs say you want to store 1 million points with JSON payloads of 5KB: total_payload_size = 1,000,000 * 5KB * 1.5 The total_payload_size is approximately 5,000,000 bytes, or about 4.77 GB.

Choosing disk over RAM For optimal performance, you should store only frequently accessed data in RAM. The rest should be offloaded to the disk. For example, extra payload fields that you don‚Äôt use for filtering can be stored on disk.

Only indexed fields should be stored in RAM. You can read more about payload storage in the Storage section.

Storage-focused configuration If your priority is to handle large volumes of vectors with average search latency, it‚Äôs recommended to configure memory-mapped (mmap) storage . In this setup, vectors are stored on disk in memory-mapped files, while only the most frequently accessed vectors are cached in RAM.

The amount of available RAM greatly impacts search performance. As a general rule, if you store half as many vectors in RAM, search latency will roughly double.

Disk speed is also crucial.

Contact us if you have specific requirements for high-volume searches in our Cloud.

Subgroup-oriented configuration If your use case involves splitting vectors into multiple collections or subgroups based on payload values (e.g., serving searches for multiple users, each with their own subset of vectors), memory-mapped storage is recommended.

In this scenario, only the active subset of vectors will be cached in RAM, allowing for fast searches for the most recent and active users. You can estimate the required memory size as: memory_size = number_of_active_vectors * vector_dimension * 4 bytes * 1.5 Please refer to our multitenancy documentation for more details on partitioning data in a Qdrant.

Scaling disk space in Qdrant Cloud Clusters supporting vector search require substantial disk space compared to other search systems. If you‚Äôre running low on disk space, you can use the UI at cloud.qdrant.io to Scale Up your cluster.

When running low on disk space, consider the following benefits of scaling up: Larger Datasets : Supports larger datasets, which can improve the relevance and quality of search results.

Improved Indexing : Enables the use of advanced indexing strategies like HNSW.

Caching : Enhances speed by having more RAM, allowing more frequently accessed data to be cached.

Backups and Redundancy : Facilitates more frequent backups, which is a key advantage for data safety.

Always remember to add 50% of the vector size. This would account for things like indexes and auxiliary data used during operations such as vector insertion, deletion, and search. Thus, the estimated memory size including metadata is: total_vector_size = number_of_dimensions * 4 bytes * 1.5 Disclaimer The above calculations are estimates at best. If you‚Äôre looking for more accurate numbers, you should always test your data set in practice.

================================================================================
PAGE 23/39
================================================================================
Title: Optimizing Qdrant Performance: Three Scenarios
URL: https://qdrant.tech/documentation/guides/optimize/
--------------------------------------------------------------------------------

Optimizing Qdrant Performance: Three Scenarios Different use cases require different balances between memory usage, search speed, and precision. Qdrant is designed to be flexible and customizable so you can tune it to your specific needs.

This guide will walk you three main optimization strategies: High Speed Search & Low Memory Usage High Precision & Low Memory Usage High Precision & High Speed Search 1. High-Speed Search with Low Memory Usage To achieve high search speed with minimal memory usage, you can store vectors on disk while minimizing the number of disk reads. Vector quantization is a technique that compresses vectors, allowing more of them to be stored in memory, thus reducing the need to read from disk.

To configure in-memory quantization, with on-disk original vectors, you need to create a collection with the following parameters: on_disk : Stores original vectors on disk. quantization_config : Compresses quantized vectors to int8 using the scalar method. always_ram : Keeps quantized vectors in RAM.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "quantization_config": { "scalar": { "type": "int8", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, quantization_config : { scalar : { type : "int8" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , QuantizationType , ScalarQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . quantization_config ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . always_ram ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, quantizationConfig : new QuantizationConfig { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), QuantizationConfig : qdrant .

NewQuantizationScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , AlwaysRam : qdrant .

PtrOf ( true ), }), }) Disable Rescoring for Faster Search (optional) This is completely optional. Disabling rescoring with search params can further reduce the number of disk reads. Note that this might slightly decrease precision.

POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "quantization": { "rescore": false } }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( quantization = models .

QuantizationSearchParams ( rescore = False ) ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { quantization : { rescore : false , }, }, }); use qdrant_client :: qdrant :: { QuantizationSearchParamsBuilder , QueryPointsBuilder , SearchParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . params ( SearchParamsBuilder :: default () . quantization ( QuantizationSearchParamsBuilder :: default (). rescore ( false )), ), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QuantizationSearchParams ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder () . setQuantization ( QuantizationSearchParams . newBuilder (). setRescore ( false ). build ()) . build ()) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { Quantization = new QuantizationSearchParams { Rescore = false } }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { Quantization : & qdrant .

QuantizationSearchParams { Rescore : qdrant .

PtrOf ( true ), }, }, }) 2. High Precision with Low Memory Usage If you require high precision but have limited RAM, you can store both vectors and the HNSW index on disk. This setup reduces memory usage while maintaining search precision.

To store the vectors on_disk , you need to configure both the vectors and the HNSW index: PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "hnsw_config": { "on_disk": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), hnsw_config = models .

HnswConfigDiff ( on_disk = True ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, hnsw_config : { on_disk : true , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , HnswConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine ). on_disk ( true )) . hnsw_config ( HnswConfigDiffBuilder :: default (). on_disk ( true )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.HnswConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setHnswConfig ( HnswConfigDiff . newBuilder (). setOnDisk ( true ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, hnswConfig : new HnswConfigDiff { OnDisk = true } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), HnswConfig : & qdrant .

HnswConfigDiff { OnDisk : qdrant .

PtrOf ( true ), }, }) Improving Precision Increase the ef and m parameters of the HNSW index to improve precision, even with limited RAM: ...

"hnsw_config" : { "m" : 64 , "ef_construct" : 512 , "on_disk" : true } ...

Note: The speed of this setup depends on the disk‚Äôs IOPS (Input/Output Operations Per Second).You can use fio to measure disk IOPS.

Inline Storage in HNSW Index Available as of v1.16.0 When storing vectors and the HNSW index on disk, you can improve search performance by enabling the inline_storage option in the hnsw_config .

With inline storage, Qdrant stores copies of vectors directly within the HNSW index file.

It makes searches faster by reducing the number of IO operations, at the cost of 3-4x increased storage usage.

It requires quantization to be enabled.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine", "on_disk": true }, "quantization_config": { "binary": { "always_ram": false } }, "hnsw_config": { "on_disk": true, "inline_storage": true } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE , on_disk = True ), quantization_config = models .

BinaryQuantization ( binary = models .

BinaryQuantizationConfig ( always_ram = False ), ), hnsw_config = models .

HnswConfigDiff ( on_disk = True , inline_storage = True ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , on_disk : true , }, quantization_config : { binary : { always_ram : false , }, }, hnsw_config : { on_disk : true , inline_storage : true , }, }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { BinaryQuantizationBuilder , CreateCollectionBuilder , Distance , HnswConfigDiffBuilder , VectorParamsBuilder , }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine ). on_disk ( true )) . quantization_config ( BinaryQuantizationBuilder :: new ( false )) . hnsw_config ( HnswConfigDiffBuilder :: default () . on_disk ( true ) . inline_storage ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.BinaryQuantization ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.HnswConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . setOnDisk ( true ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setBinary ( BinaryQuantization . newBuilder (). setAlwaysRam ( false ). build ()) . build ()) . setHnswConfig ( HnswConfigDiff . newBuilder (). setOnDisk ( true ). setInlineStorage ( true ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine , OnDisk = true }, quantizationConfig : new QuantizationConfig { Binary = new BinaryQuantization { AlwaysRam = false } }, hnswConfig : new HnswConfigDiff { OnDisk = true , InlineStorage = true } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , OnDisk : qdrant .

PtrOf ( true ), }), QuantizationConfig : qdrant .

NewQuantizationBinary ( & qdrant .

BinaryQuantization { AlwaysRam : qdrant .

PtrOf ( false ), }, ), HnswConfig : & qdrant .

HnswConfigDiff { OnDisk : qdrant .

PtrOf ( true ), InlineStorage : qdrant .

PtrOf ( true ), }, }) 3. High Precision with High-Speed Search For scenarios requiring both high speed and high precision, keep as much data in RAM as possible. Apply quantization with re-scoring for tunable accuracy.

Here is how you can configure scalar quantization for a collection: PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "quantization_config": { "scalar": { "type": "int8", "always_ram": true } } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), quantization_config = models .

ScalarQuantization ( scalar = models .

ScalarQuantizationConfig ( type = models .

ScalarType .

INT8 , always_ram = True , ), ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, quantization_config : { scalar : { type : "int8" , always_ram : true , }, }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , QuantizationType , ScalarQuantizationBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . quantization_config ( ScalarQuantizationBuilder :: default () . r#type ( QuantizationType :: Int8 . into ()) . always_ram ( true ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.QuantizationConfig ; import io.qdrant.client.grpc.Collections.QuantizationType ; import io.qdrant.client.grpc.Collections.ScalarQuantization ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setQuantizationConfig ( QuantizationConfig . newBuilder () . setScalar ( ScalarQuantization . newBuilder () . setType ( QuantizationType .

Int8 ) . setAlwaysRam ( true ) . build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, quantizationConfig : new QuantizationConfig { Scalar = new ScalarQuantization { Type = QuantizationType .

Int8 , AlwaysRam = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), QuantizationConfig : qdrant .

NewQuantizationScalar ( & qdrant .

ScalarQuantization { Type : qdrant .

QuantizationType_Int8 , AlwaysRam : qdrant .

PtrOf ( true ), }), }) Fine-Tuning Search Parameters You can adjust search parameters like hnsw_ef and exact to balance between speed and precision: Key Parameters: hnsw_ef : Number of neighbors to visit during search (higher value = better accuracy, slower speed). exact : Set to true for exact search, which is slower but more accurate. You can use it to compare results of the search with different hnsw_ef values versus the ground truth.

POST /collections/{collection_name}/points/query { "query": [0.2, 0.1, 0.9, 0.7], "params": { "hnsw_ef": 128, "exact": false }, "limit": 3 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], search_params = models .

SearchParams ( hnsw_ef = 128 , exact = False ), limit = 3 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], params : { hnsw_ef : 128 , exact : false , }, limit : 3 , }); use qdrant_client :: qdrant :: { QueryPointsBuilder , SearchParamsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . params ( SearchParamsBuilder :: default (). hnsw_ef ( 128 ). exact ( false )), ) . await ? ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.SearchParams ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setQuery ( nearest ( 0 .

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder (). setHnswEf ( 128 ). setExact ( false ). build ()) . setLimit ( 3 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, searchParams : new SearchParams { HnswEf = 128 , Exact = false }, limit : 3 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Params : & qdrant .

SearchParams { HnswEf : qdrant .

PtrOf ( uint64 ( 128 )), Exact : qdrant .

PtrOf ( false ), }, }) Balancing Latency and Throughput When optimizing search performance, latency and throughput are two main metrics to consider: Latency: Time taken for a single request.

Throughput: Number of requests handled per second.

The following optimization approaches are not mutually exclusive, but in some cases it might be preferable to optimize for one or another.

Minimizing Latency To minimize latency, you can set up Qdrant to use as many cores as possible for a single request.

You can do this by setting the number of segments in the collection to be equal to the number of cores in the system.

In this case, each segment will be processed in parallel, and the final result will be obtained faster.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "optimizers_config": { "default_segment_number": 16 } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), optimizers_config = models .

OptimizersConfigDiff ( default_segment_number = 16 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, optimizers_config : { default_segment_number : 16 , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , OptimizersConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . optimizers_config ( OptimizersConfigDiffBuilder :: default (). default_segment_number ( 16 ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setOptimizersConfig ( OptimizersConfigDiff . newBuilder (). setDefaultSegmentNumber ( 16 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, optimizersConfig : new OptimizersConfigDiff { DefaultSegmentNumber = 16 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), OptimizersConfig : & qdrant .

OptimizersConfigDiff { DefaultSegmentNumber : qdrant .

PtrOf ( uint64 ( 16 )), }, }) Maximizing Throughput To maximize throughput, configure Qdrant to use as many cores as possible to process multiple requests in parallel.

To do that, use fewer segments (usually 2) of larger size (default 200Mb per segment) to handle more requests in parallel.

Large segments benefit from the size of the index and overall smaller number of vector comparisons required to find the nearest neighbors. However, they will require more time to build the HNSW index.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "optimizers_config": { "default_segment_number": 2, "max_segment_size": 5000000 } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), optimizers_config = models .

OptimizersConfigDiff ( default_segment_number = 2 , max_segment_size = 5000000 ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, optimizers_config : { default_segment_number : 2 , max_segment_size : 5000000 , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , OptimizersConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . optimizers_config ( OptimizersConfigDiffBuilder :: default (). default_segment_number ( 2 ). max_segment_size ( 5000000 ), ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setOptimizersConfig ( OptimizersConfigDiff . newBuilder () . setDefaultSegmentNumber ( 2 ) . setMaxSegmentSize ( 5000000 ) . build () ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, optimizersConfig : new OptimizersConfigDiff { DefaultSegmentNumber = 2 , MaxSegmentSize = 5000000 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), OptimizersConfig : & qdrant .

OptimizersConfigDiff { DefaultSegmentNumber : qdrant .

PtrOf ( uint64 ( 2 )), MaxSegmentSize : qdrant .

PtrOf ( uint64 ( 5000000 )), }, }) Summary By adjusting configurations like vector storage, quantization, and search parameters, you can optimize Qdrant for different use cases: Low Memory + High Speed: Use vector quantization.

High Precision + Low Memory: Store vectors and HNSW index on disk.

High Precision + High Speed: Keep data in RAM, use quantization with re-scoring.

Latency vs. Throughput: Adjust segment numbers based on the priority.

Choose the strategy that best fits your use case to get the most out of Qdrant‚Äôs performance capabilities.

================================================================================
PAGE 24/39
================================================================================
Title: Configure Multitenancy
URL: https://qdrant.tech/documentation/guides/multitenancy/
--------------------------------------------------------------------------------

Configure Multitenancy How many collections should you create?

In most cases, a single collection per embedding model with payload-based partitioning for different tenants and use cases. This approach is called multitenancy. It is efficient for most users, but requires additional configuration. This document will show you how to set it up.

When should you create multiple collections?

When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.

Partition by payload When an instance is shared between multiple users, you may need to partition vectors by user. This is done so that each user can only access their own vectors and can‚Äôt see the vectors of other users.

PUT /collections/{collection_name}/points { "points": [ { "id": 1, "payload": {"group_id": "user_1"}, "vector": [0.9, 0.1, 0.1] }, { "id": 2, "payload": {"group_id": "user_1"}, "vector": [0.1, 0.9, 0.1] }, { "id": 3, "payload": {"group_id": "user_2"}, "vector": [0.1, 0.1, 0.9] }, ] } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , payload = { "group_id" : "user_1" }, vector = [ 0.9 , 0.1 , 0.1 ], ), models .

PointStruct ( id = 2 , payload = { "group_id" : "user_1" }, vector = [ 0.1 , 0.9 , 0.1 ], ), models .

PointStruct ( id = 3 , payload = { "group_id" : "user_2" }, vector = [ 0.1 , 0.1 , 0.9 ], ), ], ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , payload : { group_id : "user_1" }, vector : [ 0.9 , 0.1 , 0.1 ], }, { id : 2 , payload : { group_id : "user_1" }, vector : [ 0.1 , 0.9 , 0.1 ], }, { id : 3 , payload : { group_id : "user_2" }, vector : [ 0.1 , 0.1 , 0.9 ], }, ], }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , vec!

[ 0.9 , 0.1 , 0.1 ], [( "group_id" , "user_1" . into ())]), PointStruct :: new ( 2 , vec!

[ 0.1 , 0.9 , 0.1 ], [( "group_id" , "user_1" . into ())]), PointStruct :: new ( 3 , vec!

[ 0.1 , 0.1 , 0.9 ], [( "group_id" , "user_2" . into ())]), ], )) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( "{collection_name}" , List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

9f , 0 .

1f , 0 .

1f )) . putAllPayload ( Map . of ( "group_id" , value ( "user_1" ))) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( vectors ( 0 .

1f , 0 .

9f , 0 .

1f )) . putAllPayload ( Map . of ( "group_id" , value ( "user_1" ))) . build (), PointStruct . newBuilder () . setId ( id ( 3 )) . setVectors ( vectors ( 0 .

1f , 0 .

1f , 0 .

9f )) . putAllPayload ( Map . of ( "group_id" , value ( "user_2" ))) . build ())) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new [] { 0.9f , 0.1f , 0.1f }, Payload = { [ "group_id" ] = "user_1" } }, new () { Id = 2 , Vectors = new [] { 0.1f , 0.9f , 0.1f }, Payload = { [ "group_id" ] = "user_1" } }, new () { Id = 3 , Vectors = new [] { 0.1f , 0.1f , 0.9f }, Payload = { [ "group_id" ] = "user_2" } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.9 , 0.1 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "group_id" : "user_1" }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.9 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "group_id" : "user_1" }), }, { Id : qdrant .

NewIDNum ( 3 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.1 , 0.9 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "group_id" : "user_2" }), }, }, }) Use a filter along with group_id to filter vectors for each user.

POST /collections/{collection_name}/points/query { "query": [0.1, 0.1, 0.9], "filter": { "must": [ { "key": "group_id", "match": { "value": "user_1" } } ] }, "limit": 10 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . query_points ( collection_name = " {collection_name} " , query = [ 0.1 , 0.1 , 0.9 ], query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "group_id" , match = models .

MatchValue ( value = "user_1" , ), ) ] ), limit = 10 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . query ( "{collection_name}" , { query : [ 0.1 , 0.1 , 0.9 ], filter : { must : [{ key : "group_id" , match : { value : "user_1" } }], }, limit : 10 , }); use qdrant_client :: qdrant :: { Condition , Filter , QueryPointsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.1 , 0.1 , 0.9 ]) . limit ( 10 ) . filter ( Filter :: must ([ Condition :: matches ( "group_id" , "user_1" . to_string (), )])), ) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.nearest ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "group_id" , "user_1" )). build ()) . setQuery ( nearest ( 0 .

1f , 0 .

1f , 0 .

9f )) . setLimit ( 10 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.1f , 0.1f , 0.9f }, filter : MatchKeyword ( "group_id" , "user_1" ), limit : 10 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.1 , 0.1 , 0.9 ), Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "group_id" , "user_1" ), }, }, }) Calibrate performance The speed of indexation may become a bottleneck in this case, as each user‚Äôs vector will be indexed into the same collection. To avoid this bottleneck, consider bypassing the construction of a global vector index for the entire collection and building it only for individual groups instead.

By adopting this strategy, Qdrant will index vectors for each user independently, significantly accelerating the process.

To implement this approach, you should: Set payload_m in the HNSW configuration to a non-zero value, such as 16.

Set m in hnsw config to 0. This will disable building global index for the whole collection.

PUT /collections/{collection_name} { "vectors": { "size": 768, "distance": "Cosine" }, "hnsw_config": { "payload_m": 16, "m": 0 } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 768 , distance = models .

Distance .

COSINE ), hnsw_config = models .

HnswConfigDiff ( payload_m = 16 , m = 0 , ), ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 768 , distance : "Cosine" , }, hnsw_config : { payload_m : 16 , m : 0 , }, }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , HnswConfigDiffBuilder , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 768 , Distance :: Cosine )) . hnsw_config ( HnswConfigDiffBuilder :: default (). payload_m ( 16 ). m ( 0 )), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.HnswConfigDiff ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 768 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setHnswConfig ( HnswConfigDiff . newBuilder (). setPayloadM ( 16 ). setM ( 0 ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 768 , Distance = Distance .

Cosine }, hnswConfig : new HnswConfigDiff { PayloadM = 16 , M = 0 } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 768 , Distance : qdrant .

Distance_Cosine , }), HnswConfig : & qdrant .

HnswConfigDiff { PayloadM : qdrant .

PtrOf ( uint64 ( 16 )), M : qdrant .

PtrOf ( uint64 ( 0 )), }, }) Create keyword payload index for group_id field.

PUT /collections/{collection_name}/index { "field_name": "group_id", "field_schema": { "type": "keyword", "is_tenant": true } } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "group_id" , field_schema = models .

KeywordIndexParams ( type = models .

KeywordIndexType .

KEYWORD , is_tenant = True , ), ) client . createPayloadIndex ( "{collection_name}" , { field_name : "group_id" , field_schema : { type : "keyword" , is_tenant : true , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , KeywordIndexParamsBuilder , FieldType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "group_id" , FieldType :: Keyword , ). field_index_params ( KeywordIndexParamsBuilder :: default () . is_tenant ( true ) ) ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.KeywordIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "group_id" , PayloadSchemaType .

Keyword , PayloadIndexParams . newBuilder () . setKeywordIndexParams ( KeywordIndexParams . newBuilder () . setIsTenant ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "group_id" , schemaType : PayloadSchemaType .

Keyword , indexParams : new PayloadIndexParams { KeywordIndexParams = new KeywordIndexParams { IsTenant = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "group_id" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParams ( & qdrant .

KeywordIndexParams { IsTenant : qdrant .

PtrOf ( true ), }), }) is_tenant=true parameter is optional, but specifying it provides storage with additional information about the usage patterns the collection is going to use.

When specified, storage structure will be organized in a way to co-locate vectors of the same tenant together, which can significantly improve performance by utilizing sequential reads during queries.

Grouping tenants together by tenant ID, if is_tenant=true is used Limitations One downside to this approach is that global requests (without the group_id filter) will be slower since they will necessitate scanning all groups to identify the nearest neighbors.

Tiered multitenancy In some real-world applications, tenants might not be equally distributed. For example, a SaaS application might have a few large customers and many small ones.

Large tenants might require extended resources and isolation, while small tenants should not create too much overhead.

One solution to this problem might be to introduce application-level logic to separate tenants into different collections based on their size or resource requirements.

There is, however, a downside to this approach: we might not know in advance which tenants will be large and which stay small.

In addition, application-level logic increases complexity of the system and requires additional source of truth for tenant placement management.

To address this problem, in v1.16.0 Qdrant provides a built-in mechanism for tiered multitenancy.

With tiered multitenancy, you can implement two levels of tenant isolation within a single collection, keeping small tenants together inside a shared Shard, while isolating large tenants into their own dedicated Shards.

There are 3 components in Qdrant, that allows you to implement tiered multitenancy: User-defined Sharding allows you to create named Shards within a collection. It allows to isolate large tenants into their own Shards.

Fallback shards - a special routing mechanism that allows to route request to either a dedicated Shard (if it exists) or to a shared Fallback Shard. It allows to keep requests unified, without the need to know whether a tenant is dedicated or shared.

Tenant promotion - a mechanism that allows to move tenants from the shared Fallback Shard to their own dedicated Shard when they grow large enough. This process is based on Qdrant‚Äôs internal shard transfer mechanism, which makes promotion completely transparent for the application. Both read and write requests are supported during the promotion process.

Tiered multitenancy with tenant promotion Configure tiered multitenancy To take advantage of tiered multitenancy, you need to create a collection with user-defined (aka custom ) sharding and create a Fallback Shard in it.

PUT /collections/{collection_name} { "shard_number": 1, "sharding_method": "custom" // ... other collection parameters } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , shard_number = 1 , sharding_method = models .

ShardingMethod .

CUSTOM , # ... other collection parameters ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { shard_number : 1 , sharding_method : "custom" , // ... other collection parameters }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , ShardingMethod , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 300 , Distance :: Cosine )) . shard_number ( 1 ) . sharding_method ( ShardingMethod :: Custom . into ()), ) . await ? ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.ShardingMethod ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) // ... other collection parameters . setShardNumber ( 1 ) . setShardingMethod ( ShardingMethod .

Custom ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , // ... other collection parameters shardNumber : 1 , shardingMethod : ShardingMethod .

Custom ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , // ... other collection parameters ShardNumber : qdrant .

PtrOf ( uint32 ( 1 )), ShardingMethod : qdrant .

ShardingMethod_Custom .

Enum (), }) Start with creating a fallback Shard, which will be used to store small tenants.

Let‚Äôs name it default .

PUT /collections/{collection_name}/shards { "shard_key": "default" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_shard_key ( " {collection_name} " , "default" ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createShardKey ( "{collection_name}" , { shard_key : "default" }); use qdrant_client :: qdrant :: { CreateShardKeyBuilder , CreateShardKeyRequestBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_shard_key ( CreateShardKeyRequestBuilder :: new ( "{collection_name}" ) . request ( CreateShardKeyBuilder :: default (). shard_key ( "default" . to_string ())), ) . await ? ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateShardKey ; import io.qdrant.client.grpc.Collections.CreateShardKeyRequest ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createShardKeyAsync ( CreateShardKeyRequest . newBuilder () . setCollectionName ( "{collection_name}" ) . setRequest ( CreateShardKey . newBuilder () . setShardKey ( shardKey ( "default" )) . build ()) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateShardKeyAsync ( "{collection_name}" , new CreateShardKey { ShardKey = new ShardKey { Keyword = "default" , } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateShardKey ( context .

Background (), "{collection_name}" , & qdrant .

CreateShardKey { ShardKey : qdrant .

NewShardKey ( "default" ), }) Since the collection will allow both dedicated and shared tenants, we need still need to configure payload-based tenancy for this collection the same way as described in the Partition by payload section above. Namely, we need to create a payload index for the group_id field with is_tenant=true .

PUT /collections/{collection_name}/index { "field_name": "group_id", "field_schema": { "type": "keyword", "is_tenant": true } } client . create_payload_index ( collection_name = " {collection_name} " , field_name = "group_id" , field_schema = models .

KeywordIndexParams ( type = models .

KeywordIndexType .

KEYWORD , is_tenant = True , ), ) client . createPayloadIndex ( "{collection_name}" , { field_name : "group_id" , field_schema : { type : "keyword" , is_tenant : true , }, }); use qdrant_client :: qdrant :: { CreateFieldIndexCollectionBuilder , KeywordIndexParamsBuilder , FieldType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_field_index ( CreateFieldIndexCollectionBuilder :: new ( "{collection_name}" , "group_id" , FieldType :: Keyword , ). field_index_params ( KeywordIndexParamsBuilder :: default () . is_tenant ( true ) ) ). await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.KeywordIndexParams ; import io.qdrant.client.grpc.Collections.PayloadIndexParams ; import io.qdrant.client.grpc.Collections.PayloadSchemaType ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createPayloadIndexAsync ( "{collection_name}" , "group_id" , PayloadSchemaType .

Keyword , PayloadIndexParams . newBuilder () . setKeywordIndexParams ( KeywordIndexParams . newBuilder () . setIsTenant ( true ) . build ()) . build (), null , null , null ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreatePayloadIndexAsync ( collectionName : "{collection_name}" , fieldName : "group_id" , schemaType : PayloadSchemaType .

Keyword , indexParams : new PayloadIndexParams { KeywordIndexParams = new KeywordIndexParams { IsTenant = true } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateFieldIndex ( context .

Background (), & qdrant .

CreateFieldIndexCollection { CollectionName : "{collection_name}" , FieldName : "group_id" , FieldType : qdrant .

FieldType_FieldTypeKeyword .

Enum (), FieldIndexParams : qdrant .

NewPayloadIndexParams ( & qdrant .

KeywordIndexParams { IsTenant : qdrant .

PtrOf ( true ), }), }) Query tiered multitenant collection Now we can start uploading data into the collection. One important difference from the simple payload-based multitenancy is that now we need to specify the Shard Key Selector in each request to route requests to the correct Shard.

Shard Key Selector will specify two keys: target shard - name of the tenant‚Äôs dedicated Shard (which may or may not exist). fallback shard - name of the shared Fallback Shard (in our case, default ).

PUT /collections/{collection_name}/points { "points": [ { "id": 1, "payload": {"group_id": "user_1"}, "vector": [0.9, 0.1, 0.1] } ], "shard_key": { "fallback": "default", "target": "user_1" } } client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1 , payload = { "group_id" : "user_1" }, vector = [ 0.9 , 0.1 , 0.1 ], ), ], shard_key_selector = models .

ShardKeyWithFallback ( target = "user_1" , fallback = "default" ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1 , payload : { group_id : "user_1" }, vector : [ 0.9 , 0.1 , 0.1 ], } ], shard_key : { target : "user_1" , fallback : "default" } }); use qdrant_client :: Qdrant ; use qdrant_client :: qdrant :: { PointStruct , ShardKeySelectorBuilder , UpsertPointsBuilder }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; let shard_key_selector = ShardKeySelectorBuilder :: with_shard_key ( "user_1" ) . fallback ( "default" ) . build (); client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , vec!

[ 0.9 , 0.1 , 0.1 ], [( "group_id" , "user_1" . into ())] ), ], ) . shard_key_selector ( shard_key_selector ), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.ShardKeySelector ; import io.qdrant.client.grpc.Points.UpsertPoints ; import java.util.List ; import java.util.Map ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( UpsertPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addAllPoints ( List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

9f , 0 .

1f , 0 .

1f )) . putAllPayload ( Map . of ( "group_id" , value ( "user_1" ))) . build ())) . setShardKeySelector ( ShardKeySelector . newBuilder () . addShardKeys ( shardKey ( "user_1" )) . setFallback ( shardKey ( "default" )) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new [] { 0.9f , 0.1f , 0.1f }, Payload = { [ "group_id" ] = "user_1" } } }, shardKeySelector : new ShardKeySelector { ShardKeys = { new List < ShardKey > { "user_1" } }, Fallback = new ShardKey { Keyword = "default" } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.9 , 0.1 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "group_id" : "user_1" }), }, }, ShardKeySelector : & qdrant .

ShardKeySelector { ShardKeys : [] * qdrant .

ShardKey { qdrant .

NewShardKey ( "user_1" ), }, Fallback : qdrant .

NewShardKey ( "default" ), }, }) The routing logic will work as follows: If the target Shard exists and active, the request will be routed to it.

If the target Shard does not exist, the request will be routed to the fallback Shard.

Similarly, when querying points, we need to specify the Shard Key Selector and filter by group_id .

Note, that filter match value should always match the target Shard Key.

Promote tenant to dedicated Shard When a tenant grows large enough, you can promote it to its own dedicated Shard.

In order to do that, you first need to create a new Shard for the tenant: PUT /collections/{collection_name}/shards { "shard_key": "user_1", "initial_state": "Partial" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_shard_key ( " {collection_name} " , shard_key = "user_1" , initial_state = models .

ReplicaState .

PARTIAL ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createShardKey ( "{collection_name}" , { shard_key : "default" , initial_state : "Partial" }); use qdrant_client :: qdrant :: { CreateShardKeyBuilder , CreateShardKeyRequestBuilder }; use qdrant_client :: qdrant :: ReplicaState ; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_shard_key ( CreateShardKeyRequestBuilder :: new ( "{collection_name}" ) . request ( CreateShardKeyBuilder :: default () . shard_key ( "user_1" . to_string ()) . initial_state ( ReplicaState :: Partial ) ), ) . await ? ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateShardKey ; import io.qdrant.client.grpc.Collections.CreateShardKeyRequest ; import io.qdrant.client.grpc.Collections.ReplicaState ; import io.qdrant.client.grpc.Common.Filter ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createShardKeyAsync ( CreateShardKeyRequest . newBuilder () . setCollectionName ( "{collection_name}" ) . setRequest ( CreateShardKey . newBuilder () . setShardKey ( shardKey ( "default" )) . setInitialState ( ReplicaState .

Partial ) . build ()) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateShardKeyAsync ( "{collection_name}" , new CreateShardKey { ShardKey = new ShardKey { Keyword = "default" }, InitialState = ReplicaState .

Partial } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateShardKey ( context .

Background (), "{collection_name}" , & qdrant .

CreateShardKey { ShardKey : qdrant .

NewShardKey ( "default" ), InitialState : qdrant .

PtrOf ( qdrant .

ReplicaState_Partial ), }, ) Note, that we create a Shard in Partial state, since it would still need to transfer data into it.

To initiate data transfer, there is another API method called replicate_points : POST /collections/{collection_name}/cluster { "replicate_points": { "filter": { "must": { "key": "group_id", "match": { "value": "user_1" } } }, "from_shard_key": "default", "to_shard_key": "user_1" } } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . cluster_collection_update ( collection_name = " {collection_name} " , cluster_operation = models .

ReplicatePointsOperation ( replicate_points = models .

ReplicatePoints ( from_shard_key = "default" , to_shard_key = "user_1" , filter = models .

Filter ( must = [ models .

FieldCondition ( key = "group_id" , match = models .

MatchValue ( value = "user_1" , ) ) ] ) ) ) ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . updateCollectionCluster ( "{collection_name}" , { replicate_points : { filter : { must : { key : "group_id" , match : { value : "user_1" } } }, from_shard_key : "default" , to_shard_key : "user_1" } }); use qdrant_client :: qdrant :: { update_collection_cluster_setup_request :: Operation , Condition , Filter , ReplicatePointsBuilder , ShardKey , UpdateCollectionClusterSetupRequest , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . update_collection_cluster_setup ( UpdateCollectionClusterSetupRequest { collection_name : "{collection_name}" . to_string (), operation : Some ( Operation :: ReplicatePoints ( ReplicatePointsBuilder :: new ( ShardKey :: from ( "default" ), ShardKey :: from ( "user_1" ), ) . filter ( Filter :: must ([ Condition :: matches ( "group_id" , "user_1" . to_string (), )])) . build (), )), timeout : None , }) . await ? ; import static io.qdrant.client.ConditionFactory.matchKeyword ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.ReplicatePoints ; import io.qdrant.client.grpc.Collections.UpdateCollectionClusterSetupRequest ; import io.qdrant.client.grpc.Common.Filter ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . updateCollectionClusterSetupAsync ( UpdateCollectionClusterSetupRequest . newBuilder () . setCollectionName ( "{collection_name}" ) . setReplicatePoints ( ReplicatePoints . newBuilder () . setFromShardKey ( shardKey ( "default" )) . setToShardKey ( shardKey ( "user_1" )) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "group_id" , "user_1" )). build ()) . build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpdateCollectionClusterSetupAsync ( new () { CollectionName = "{collection_name}" , ReplicatePoints = new () { FromShardKey = "default" , ToShardKey = "user_1" , Filter = MatchKeyword ( "group_id" , "user_1" ) } }); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

UpdateClusterCollectionSetup ( context .

Background (), qdrant .

NewUpdateCollectionClusterReplicatePoints ( "{collection_name}" , & qdrant .

ReplicatePoints { FromShardKey : qdrant .

NewShardKey ( "default" ), ToShardKey : qdrant .

NewShardKey ( "user_1" ), Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "group_id" , "user_1" ), }, }, }, )) Once transfer is completed, target Shard will become Active , and all requests for the tenant will be routed to it automatically.

At this point it is safe to delete the tenant‚Äôs data from the shared Fallback Shard to free up space.

Limitations Currently, fallback Shard may only contain a single shard ID on its own. That means all small tenants must fit a single peer of the cluser. This restriction will be improved in future releases.

Similar to collections, dedicated Shards introduce some resource overhead. It is not recommended to create more than a thousand dedicated Shards per cluster. Recommended threshold of promoting a tenant is the same as the indexing threshold for a single collection, which is around 20K points.

================================================================================
PAGE 25/39
================================================================================
Title: Distributed deployment
URL: https://qdrant.tech/documentation/guides/distributed_deployment/
--------------------------------------------------------------------------------

Distributed deployment Since version v0.8.0 Qdrant supports a distributed deployment mode.

In this mode, multiple Qdrant services communicate with each other to distribute the data across the peers to extend the storage capabilities and increase stability.

How many Qdrant nodes should I run?

The ideal number of Qdrant nodes depends on how much you value cost-saving, resilience, and performance/scalability in relation to each other.

Prioritizing cost-saving : If cost is most important to you, run a single Qdrant node. This is not recommended for production environments. Drawbacks: Resilience: Users will experience downtime during node restarts, and recovery is not possible unless you have backups or snapshots.

Performance: Limited to the resources of a single server.

Prioritizing resilience : If resilience is most important to you, run a Qdrant cluster with three or more nodes and two or more shard replicas. Clusters with three or more nodes and replication can perform all operations even while one node is down. Additionally, they gain performance benefits from load-balancing and they can recover from the permanent loss of one node without the need for backups or snapshots (but backups are still strongly recommended). This is most recommended for production environments. Drawbacks: Cost: Larger clusters are more costly than smaller clusters, which is the only drawback of this configuration.

Balancing cost, resilience, and performance : Running a two-node Qdrant cluster with replicated shards allows the cluster to respond to most read/write requests even when one node is down, such as during maintenance events. Having two nodes also means greater performance than a single-node cluster while still being cheaper than a three-node cluster. Drawbacks: Resilience (uptime): The cluster cannot perform operations on collections when one node is down. Those operations require >50% of nodes to be running, so this is only possible in a 3+ node cluster. Since creating, editing, and deleting collections are usually rare operations, many users find this drawback to be negligible.

Resilience (data integrity): If the data on one of the two nodes is permanently lost or corrupted, it cannot be recovered aside from snapshots or backups. Only 3+ node clusters can recover from the permanent loss of a single node since recovery operations require >50% of the cluster to be healthy.

Cost: Replicating your shards requires storing two copies of your data.

Performance: The maximum performance of a Qdrant cluster increases as you add more nodes.

In summary, single-node clusters are best for non-production workloads, replicated 3+ node clusters are the gold standard, and replicated 2-node clusters strike a good balance.

Enabling distributed mode in self-hosted Qdrant To enable distributed deployment - enable the cluster mode in the configuration or using the ENV variable: QDRANT__CLUSTER__ENABLED=true . cluster : # Use `enabled: true` to run Qdrant in distributed deployment mode enabled : true # Configuration of the inter-cluster communication p2p : # Port for internal communication between peers port : 6335 # Configuration related to distributed consensus algorithm consensus : # How frequently peers should ping each other.

# Setting this parameter to lower value will allow consensus # to detect disconnected node earlier, but too frequent # tick period may create significant network and CPU overhead.

# We encourage you NOT to change this parameter unless you know what you are doing. tick_period_ms : 100 By default, Qdrant will use port 6335 for its internal communication.

All peers should be accessible on this port from within the cluster, but make sure to isolate this port from outside access, as it might be used to perform write operations.

Additionally, you must provide the --uri flag to the first peer so it can tell other nodes how it should be reached: ./qdrant --uri 'http://qdrant_node_1:6335' Subsequent peers in a cluster must know at least one node of the existing cluster to synchronize through it with the rest of the cluster.

To do this, they need to be provided with a bootstrap URL: ./qdrant --bootstrap 'http://qdrant_node_1:6335' The URL of the new peers themselves will be calculated automatically from the IP address of their request.

But it is also possible to provide them individually using the --uri argument.

USAGE: qdrant [OPTIONS] OPTIONS: --bootstrap <URI> Uri of the peer to bootstrap from in case of multi-peer deployment. If not specified - this peer will be considered as a first in a new deployment --uri <URI> Uri of this peer. Other peers should be able to reach it by this uri.

This value has to be supplied if this is the first peer in a new deployment.

In case this is not the first peer and it bootstraps the value is optional. If not supplied then qdrant will take internal grpc port from config and derive the IP address of this peer on bootstrap peer (receiving side) After a successful synchronization you can observe the state of the cluster through the REST API : GET /cluster Example result: { "result" : { "status" : "enabled" , "peer_id" : 11532566549086892000 , "peers" : { "9834046559507417430" : { "uri" : "http://172.18.0.3:6335/" }, "11532566549086892528" : { "uri" : "http://qdrant_node_1:6335/" } }, "raft_info" : { "term" : 1 , "commit" : 4 , "pending_operations" : 1 , "leader" : 11532566549086892000 , "role" : "Leader" } }, "status" : "ok" , "time" : 5.731e-06 } Note that enabling distributed mode does not automatically replicate your data. See the section on making use of a new distributed Qdrant cluster for the next steps.

Enabling distributed mode in Qdrant Cloud For best results, first ensure your cluster is running Qdrant v1.7.4 or higher. Older versions of Qdrant do support distributed mode, but improvements in v1.7.4 make distributed clusters more resilient during outages.

In the Qdrant Cloud console , click ‚ÄúScale Up‚Äù to increase your cluster size to >1. Qdrant Cloud configures the distributed mode settings automatically.

Additionally, Qdrant Cloud also offers the ability to automatically rebalance and to reshard your collections, which is not available in self-hosted Qdrant. See the Resharding and Shard Rebalancing sections in for more details.

After the scale-up process completes, you will have a new empty node running alongside your existing node(s). To replicate data into this new empty node, see the next section.

Making use of a new distributed Qdrant cluster When you enable distributed mode and scale up to two or more nodes, your data does not move to the new node automatically; it starts out empty. To make use of your new empty node, do one of the following: Create a new replicated collection by setting the replication_factor to 2 or more and setting the number of shards to a multiple of your number of nodes.

If you have an existing collection which does not contain enough shards for each node, you must create a new collection as described in the previous bullet point.

If you already have enough shards for each node, and you merely need to replicate your data, follow the directions for creating new shard replicas .

If you already have enough shards for each node, and your data is already replicated, you can move data (without replicating it) onto the new node(s) by moving shards .

Raft Qdrant uses the Raft consensus protocol to maintain consistency regarding the cluster topology and the collections structure.

Operations on points, on the other hand, do not go through the consensus infrastructure.

Qdrant is not intended to have strong transaction guarantees, which allows it to perform point operations with low overhead.

In practice, it means that Qdrant does not guarantee atomic distributed updates but allows you to wait until the operation is complete to see the results of your writes.

Operations on collections, on the contrary, are part of the consensus which guarantees that all operations are durable and eventually executed by all nodes.

In practice it means that a majority of nodes agree on what operations should be applied before the service will perform them.

Practically, it means that if the cluster is in a transition state - either electing a new leader after a failure or starting up, the collection update operations will be denied.

You may use the cluster REST API to check the state of the consensus.

Sharding A Collection in Qdrant is made of one or more shards.

A shard is an independent store of points which is able to perform all operations provided by collections.

There are two methods of distributing points across shards: Automatic sharding : Points are distributed among shards by using a consistent hashing algorithm, so that shards are managing non-intersecting subsets of points. This is the default behavior.

User-defined sharding : Available as of v1.7.0 - Each point is uploaded to a specific shard, so that operations can hit only the shard or shards they need. Even with this distribution, shards still ensure having non-intersecting subsets of points.

See more‚Ä¶ Each node knows where all parts of the collection are stored through the consensus protocol , so when you send a search request to one Qdrant node, it automatically queries all other nodes to obtain the full search result.

Choosing the right number of shards When you create a collection, Qdrant splits the collection into shard_number shards. If left unset, shard_number is set to the number of nodes in your cluster when the collection was created. The shard_number cannot be changed without recreating the collection.

PUT /collections/{collection_name} { "vectors": { "size": 300, "distance": "Cosine" }, "shard_number": 6 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 300 , distance = models .

Distance .

COSINE ), shard_number = 6 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 300 , distance : "Cosine" , }, shard_number : 6 , }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 300 , Distance :: Cosine )) . shard_number ( 6 ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 300 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setShardNumber ( 6 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 300 , Distance = Distance .

Cosine }, shardNumber : 6 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 300 , Distance : qdrant .

Distance_Cosine , }), ShardNumber : qdrant .

PtrOf ( uint32 ( 6 )), }) To ensure all nodes in your cluster are evenly utilized, the number of shards must be a multiple of the number of nodes you are currently running in your cluster.

Aside: Advanced use cases such as multitenancy may require an uneven distribution of shards. See Multitenancy .

We recommend creating at least 2 shards per node to allow future expansion without having to re-shard.

Resharding is possible when using our cloud offering, but should be avoided if hosting elsewhere as it would require creating a new collection.

If you anticipate a lot of growth, we recommend 12 shards since you can expand from 1 node up to 2, 3, 6, and 12 nodes without having to re-shard. Having more than 12 shards in a small cluster may not be worth the performance overhead.

Shards are evenly distributed across all existing nodes when a collection is first created.

When you add or remove nodes from the cluster, rebalancing of existing shards accross the nodes depends on how you‚Äôve deployed the cluster: In Qdrant Cloud, shards are balanced across the nodes automatically .

If your cluster is not runnning in Qdrant Cloud, you need to manually balance shards .

Resharding Available as of v1.13.0 in Cloud Resharding allows you to change the number of shards in your existing collections if you‚Äôre hosting with our Cloud offering.

Resharding can change the number of shards both up and down, without having to recreate the collection from scratch.

Please refer to the Resharding section in our cloud documentation for more details.

Moving shards Available as of v0.9.0 Qdrant allows moving shards between nodes in the cluster and removing nodes from the cluster. This functionality unlocks the ability to dynamically scale the cluster size without downtime. It also allows you to upgrade or migrate nodes without downtime.

If your cluster is running in Qdrant Cloud, shards are balanced across the cluster nodes automatically. For more information see the Configuring Cloud Clusters and Cloud Cluster Scaling documentation.

Qdrant provides the information regarding the current shard distribution in the cluster with the Collection Cluster info API .

Use the Update collection cluster setup API to initiate the shard transfer: POST /collections/{collection_name}/cluster { "move_shard": { "shard_id": 0, "from_peer_id": 381894127, "to_peer_id": 467122995 } } After the transfer is initiated, the service will process it based on the used transfer method keeping both shards in sync. Once the transfer is completed, the old shard is deleted from the source node.

In case you want to downscale the cluster, you can move all shards away from a peer and then remove the peer using the remove peer API .

DELETE /cluster/peer/{peer_id} After that, Qdrant will exclude the node from the consensus, and the instance will be ready for shutdown.

User-defined sharding Available as of v1.7.0 Qdrant allows you to specify the shard for each point individually. This feature is useful if you want to control the shard placement of your data, so that operations can hit only the subset of shards they actually need. In big clusters, this can significantly improve the performance of operations that do not require the whole collection to be scanned.

A clear use-case for this feature is managing a multi-tenant collection, where each tenant (let it be a user or organization) is assumed to be segregated, so they can have their data stored in separate shards.

To enable user-defined sharding, set sharding_method to custom during collection creation: PUT /collections/{collection_name} { "shard_number": 1, "sharding_method": "custom" // ... other collection parameters } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , shard_number = 1 , sharding_method = models .

ShardingMethod .

CUSTOM , # ... other collection parameters ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { shard_number : 1 , sharding_method : "custom" , // ... other collection parameters }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , ShardingMethod , VectorParamsBuilder , }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 300 , Distance :: Cosine )) . shard_number ( 1 ) . sharding_method ( ShardingMethod :: Custom . into ()), ) . await ? ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.ShardingMethod ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) // ... other collection parameters . setShardNumber ( 1 ) . setShardingMethod ( ShardingMethod .

Custom ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , // ... other collection parameters shardNumber : 1 , shardingMethod : ShardingMethod .

Custom ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , // ... other collection parameters ShardNumber : qdrant .

PtrOf ( uint32 ( 1 )), ShardingMethod : qdrant .

ShardingMethod_Custom .

Enum (), }) In this mode, the shard_number means the number of shards per shard key, where points will be distributed evenly. For example, if you have 10 shard keys and a collection config with these settings: { "shard_number" : 1 , "sharding_method" : "custom" , "replication_factor" : 2 } Then you will have 1 * 10 * 2 = 20 total physical shards in the collection.

Physical shards require a large amount of resources, so make sure your custom sharding key has a low cardinality.

For large cardinality keys, it is recommended to use partition by payload instead.

Now you need to create custom shards ( API reference ): PUT /collections/{collection_name}/shards { "shard_key": "{shard_key}" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_shard_key ( " {collection_name} " , " {shard_key} " ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createShardKey ( "{collection_name}" , { shard_key : "{shard_key}" }); use qdrant_client :: qdrant :: { CreateShardKeyBuilder , CreateShardKeyRequestBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_shard_key ( CreateShardKeyRequestBuilder :: new ( "{collection_name}" ) . request ( CreateShardKeyBuilder :: default (). shard_key ( "{shard_key}" . to_string ())), ) . await ? ; import static io.qdrant.client.ShardKeyFactory.shardKey ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateShardKey ; import io.qdrant.client.grpc.Collections.CreateShardKeyRequest ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createShardKeyAsync ( CreateShardKeyRequest . newBuilder () . setCollectionName ( "{collection_name}" ) . setRequest ( CreateShardKey . newBuilder () . setShardKey ( shardKey ( "{shard_key}" )) . build ()) . build ()). get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateShardKeyAsync ( "{collection_name}" , new CreateShardKey { ShardKey = new ShardKey { Keyword = "{shard_key}" , } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateShardKey ( context .

Background (), "{collection_name}" , & qdrant .

CreateShardKey { ShardKey : qdrant .

NewShardKey ( "{shard_key}" ), }) To specify the shard for each point, you need to provide the shard_key field in the upsert request: PUT /collections/{collection_name}/points { "points": [ { "id": 1111, "vector": [0.1, 0.2, 0.3] }, ] "shard_key": "user_1" } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . upsert ( collection_name = " {collection_name} " , points = [ models .

PointStruct ( id = 1111 , vector = [ 0.1 , 0.2 , 0.3 ], ), ], shard_key_selector = "user_1" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . upsert ( "{collection_name}" , { points : [ { id : 1111 , vector : [ 0.1 , 0.2 , 0.3 ], }, ], shard_key : "user_1" , }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder }; use qdrant_client :: Payload ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 111 , vec!

[ 0.1 , 0.2 , 0.3 ], Payload :: default (), )], ) . shard_key_selector ( "user_1" . to_string ()), ) . await ? ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ShardKeySelectorFactory.shardKeySelector ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.UpsertPoints ; import java.util.List ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . upsertAsync ( UpsertPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addAllPoints ( List . of ( PointStruct . newBuilder () . setId ( id ( 111 )) . setVectors ( vectors ( 0 .

1f , 0 .

2f , 0 .

3f )) . build ())) . setShardKeySelector ( shardKeySelector ( "user_1" )) . build () ) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 111 , Vectors = new [] { 0.1f , 0.2f , 0.3f } } }, shardKeySelector : new ShardKeySelector { ShardKeys = { new List < ShardKey > { "user_1" } } } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 111 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.2 , 0.3 ), }, }, ShardKeySelector : & qdrant .

ShardKeySelector { ShardKeys : [] * qdrant .

ShardKey { qdrant .

NewShardKey ( "user_1" ), }, }, }) * When using custom sharding, IDs are only enforced to be unique within a shard key. This means that you can have multiple points with the same ID, if they have different shard keys.

This is a limitation of the current implementation, and is an anti-pattern that should be avoided because it can create scenarios of points with the same ID to have different contents. In the future, we plan to add a global ID uniqueness check.

Now you can target the operations to specific shard(s) by specifying the shard_key on any operation you do. Operations that do not specify the shard key will be executed on all shards.

Another use-case would be to have shards that track the data chronologically, so that you can do more complex itineraries like uploading live data in one shard and archiving it once a certain age has passed.

Shard transfer method Available as of v1.7.0 There are different methods for transferring a shard, such as moving or replicating, to another node. Depending on what performance and guarantees you‚Äôd like to have and how you‚Äôd like to manage your cluster, you likely want to choose a specific method. Each method has its own pros and cons. Which is fastest depends on the size and state of a shard.

Available shard transfer methods are: stream_records : (default) transfer by streaming just its records to the target node in batches. snapshot : transfer including its index and quantized data by utilizing a snapshot automatically. wal_delta : (auto recovery default) transfer by resolving WAL difference; the operations that were missed.

Each has pros, cons and specific requirements, some of which are: Method: Stream records Snapshot WAL delta Version v0.8.0+ v1.7.0+ v1.8.0+ Target New/existing shard New/existing shard Existing shard Connectivity Internal gRPC API ( 6335 ) REST API ( 6333 ) Internal gRPC API ( 6335 ) Internal gRPC API ( 6335 ) HNSW index Doesn‚Äôt transfer, will reindex on target.

Does transfer, immediately ready on target.

Doesn‚Äôt transfer, may index on target.

Quantization Doesn‚Äôt transfer, will requantize on target.

Does transfer, immediately ready on target.

Doesn‚Äôt transfer, may quantize on target.

Ordering Unordered updates on target 1 Ordered updates on target 2 Ordered updates on target 2 Disk space No extra required Extra required for snapshot on both nodes No extra required To select a shard transfer method, specify the method like: POST /collections/{collection_name}/cluster { "move_shard": { "shard_id": 0, "from_peer_id": 381894127, "to_peer_id": 467122995, "method": "snapshot" } } The stream_records transfer method is the simplest available. It simply transfers all shard records in batches to the target node until it has transferred all of them, keeping both shards in sync. It will also make sure the transferred shard indexing process is keeping up before performing a final switch. The method has two common disadvantages: 1. It does not transfer index or quantization data, meaning that the shard has to be optimized again on the new node, which can be very expensive. 2. The ordering guarantees are weak 1 , which is not suitable for some applications. Because it is so simple, it‚Äôs also very robust, making it a reliable choice if the above cons are acceptable in your use case. If your cluster is unstable and out of resources, it‚Äôs probably best to use the stream_records transfer method, because it is unlikely to fail.

The snapshot transfer method utilizes snapshots to transfer a shard. A snapshot is created automatically. It is then transferred and restored on the target node. After this is done, the snapshot is removed from both nodes. While the snapshot/transfer/restore operation is happening, the source node queues up all new operations. All queued updates are then sent in order to the target shard to bring it into the same state as the source. There are two important benefits: 1. It transfers index and quantization data, so that the shard does not have to be optimized again on the target node, making them immediately available. This way, Qdrant ensures that there will be no degradation in performance at the end of the transfer. Especially on large shards, this can give a huge performance improvement. 2. The ordering guarantees can be strong 2 , required for some applications.

The wal_delta transfer method only transfers the difference between two shards. More specifically, it transfers all operations that were missed to the target shard. The WAL of both shards is used to resolve this. There are two benefits: 1. It will be very fast because it only transfers the difference rather than all data. 2. The ordering guarantees can be strong 2 , required for some applications. Two disadvantages are: 1. It can only be used to transfer to a shard that already exists on the other node. 2. Applicability is limited because the WALs normally don‚Äôt hold more than 64MB of recent operations. But that should be enough for a node that quickly restarts, to upgrade for example. If a delta cannot be resolved, this method automatically falls back to stream_records which equals transferring the full shard.

The stream_records method is currently used as default. This may change in the future. As of Qdrant 1.9.0 wal_delta is used for automatic shard replications to recover dead shards.

Replication Qdrant allows you to replicate shards between nodes in the cluster.

Shard replication increases the reliability of the cluster by keeping several copies of a shard spread across the cluster.

This ensures the availability of the data in case of node failures, except if all replicas are lost.

Replication factor When you create a collection, you can control how many shard replicas you‚Äôd like to store by changing the replication_factor . By default, replication_factor is set to ‚Äú1‚Äù, meaning no additional copy is maintained automatically. The default can be changed in the Qdrant configuration . You can change that by setting the replication_factor when you create a collection.

The replication_factor can be updated for an existing collection, but the effect of this depends on how you‚Äôre running Qdrant. If you‚Äôre hosting the open source version of Qdrant yourself, changing the replication factor after collection creation doesn‚Äôt do anything. You can manually create or drop shard replicas to achieve your desired replication factor. In Qdrant Cloud (including Hybrid Cloud, Private Cloud) your shards will automatically be replicated or dropped to match your configured replication factor.

PUT /collections/{collection_name} { "vectors": { "size": 300, "distance": "Cosine" }, "shard_number": 6, "replication_factor": 2 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 300 , distance = models .

Distance .

COSINE ), shard_number = 6 , replication_factor = 2 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 300 , distance : "Cosine" , }, shard_number : 6 , replication_factor : 2 , }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 300 , Distance :: Cosine )) . shard_number ( 6 ) . replication_factor ( 2 ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 300 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setShardNumber ( 6 ) . setReplicationFactor ( 2 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 300 , Distance = Distance .

Cosine }, shardNumber : 6 , replicationFactor : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 300 , Distance : qdrant .

Distance_Cosine , }), ShardNumber : qdrant .

PtrOf ( uint32 ( 6 )), ReplicationFactor : qdrant .

PtrOf ( uint32 ( 2 )), }) This code sample creates a collection with a total of 6 logical shards backed by a total of 12 physical shards.

Since a replication factor of ‚Äú2‚Äù would require twice as much storage space, it is advised to make sure the hardware can host the additional shard replicas beforehand.

Creating new shard replicas It is possible to create or delete replicas manually on an existing collection using the Update collection cluster setup API . This is usually only necessary if you run Qdrant open-source. In Qdrant Cloud shard replication is handled and updated automatically, matching the configured replication_factor .

A replica can be added on a specific peer by specifying the peer from which to replicate.

POST /collections/{collection_name}/cluster { "replicate_shard": { "shard_id": 0, "from_peer_id": 381894127, "to_peer_id": 467122995 } } And a replica can be removed on a specific peer.

POST /collections/{collection_name}/cluster { "drop_replica": { "shard_id": 0, "peer_id": 381894127 } } Keep in mind that a collection must contain at least one active replica of a shard.

Error handling Replicas can be in different states: Active: healthy and ready to serve traffic Dead: unhealthy and not ready to serve traffic Partial: currently under resynchronization before activation A replica is marked as dead if it does not respond to internal healthchecks or if it fails to serve traffic.

A dead replica will not receive traffic from other peers and might require a manual intervention if it does not recover automatically.

This mechanism ensures data consistency and availability if a subset of the replicas fail during an update operation.

Node Failure Recovery Sometimes hardware malfunctions might render some nodes of the Qdrant cluster unrecoverable.

No system is immune to this.

But several recovery scenarios allow qdrant to stay available for requests and even avoid performance degradation.

Let‚Äôs walk through them from best to worst.

Recover with replicated collection If the number of failed nodes is less than the replication factor of the collection, then your cluster should still be able to perform read, search and update queries.

Now, if the failed node restarts, consensus will trigger the replication process to update the recovering node with the newest updates it has missed.

If the failed node never restarts, you can recover the lost shards if you have a 3+ node cluster. You cannot recover lost shards in smaller clusters because recovery operations go through raft which requires >50% of the nodes to be healthy.

Recreate node with replicated collections If a node fails and it is impossible to recover it, you should exclude the dead node from the consensus and create an empty node.

To exclude failed nodes from the consensus, use remove peer API.

Apply the force flag if necessary.

When you create a new node, make sure to attach it to the existing cluster by specifying --bootstrap CLI parameter with the URL of any of the running cluster nodes.

Once the new node is ready and synchronized with the cluster, you might want to ensure that the collection shards are replicated enough. Remember that Qdrant will not automatically balance shards since this is an expensive operation.

Use the Replicate Shard Operation to create another copy of the shard on the newly connected node.

It‚Äôs worth mentioning that Qdrant only provides the necessary building blocks to create an automated failure recovery.

Building a completely automatic process of collection scaling would require control over the cluster machines themself.

Check out our cloud solution , where we made exactly that.

Recover from snapshot If there are no copies of data in the cluster, it is still possible to recover from a snapshot.

Follow the same steps to detach failed node and create a new one in the cluster: To exclude failed nodes from the consensus, use remove peer API. Apply the force flag if necessary.

Create a new node, making sure to attach it to the existing cluster by specifying the --bootstrap CLI parameter with the URL of any of the running cluster nodes.

Snapshot recovery, used in single-node deployment, is different from cluster one.

Consensus manages all metadata about all collections and does not require snapshots to recover it.

But you can use snapshots to recover missing shards of the collections.

Use the Collection Snapshot Recovery API to do it.

The service will download the specified snapshot of the collection and recover shards with data from it.

Once all shards of the collection are recovered, the collection will become operational again.

Temporary node failure If properly configured, running Qdrant in distributed mode can make your cluster resistant to outages when one node fails temporarily.

Here is how differently-configured Qdrant clusters respond: 1-node clusters: All operations time out or fail for up to a few minutes. It depends on how long it takes to restart and load data from disk.

2-node clusters where shards ARE NOT replicated: All operations will time out or fail for up to a few minutes. It depends on how long it takes to restart and load data from disk.

2-node clusters where all shards ARE replicated to both nodes: All requests except for operations on collections continue to work during the outage.

3+-node clusters where all shards are replicated to at least 2 nodes: All requests continue to work during the outage.

Consistency guarantees By default, Qdrant focuses on availability and maximum throughput of search operations.

For the majority of use cases, this is a preferable trade-off.

During the normal state of operation, it is possible to search and modify data from any peers in the cluster.

Before responding to the client, the peer handling the request dispatches all operations according to the current topology in order to keep the data synchronized across the cluster. reads are using a partial fan-out strategy to optimize latency and availability writes are executed in parallel on all active sharded replicas By default, concurrent updates on one point can result in an inconsistent state. For example, if two clients simultaneously update the same point in a collection with three replicas per shard. On some replicas, the point may reflect the update from one client, while on other replicas, the point may reflect the update from the other client.

In some cases, it is necessary to ensure additional guarantees during possible hardware instabilities, mass concurrent updates of same documents, etc.

Qdrant provides a few options to control consistency guarantees: write_consistency_factor - defines the number of replicas that must acknowledge a write operation before responding to the client. Increasing this value will make write operations tolerant to network partitions in the cluster, but will require a higher number of replicas to be active to perform write operations.

Read consistency param, can be used with search and retrieve operations to ensure that the results obtained from all replicas are the same. If this option is used, Qdrant will perform the read operation on multiple replicas and resolve the result according to the selected strategy. This option is useful to avoid data inconsistency in case of concurrent updates of the same documents. This options is preferred if the update operations are frequent and the number of replicas is low.

Write ordering param, can be used with update and delete operations to ensure that the operations are executed in the same order on all replicas. If this option is used, Qdrant will route the operation to the leader replica of the shard and wait for the response before responding to the client. This option is useful to avoid data inconsistency in case of concurrent updates of the same documents. This options is preferred if read operations are more frequent than update and if search performance is critical.

Write consistency factor The write_consistency_factor represents the number of replicas that must acknowledge a write operation before responding to the client. It is set to 1 by default.

It can be configured at the collection‚Äôs creation or when updating the collection parameters.

This value can range from 1 to the number of replicas you have for each shard.

PUT /collections/{collection_name} { "vectors": { "size": 300, "distance": "Cosine" }, "shard_number": 6, "replication_factor": 2, "write_consistency_factor": 2 } from qdrant_client import QdrantClient , models client = QdrantClient ( url = "http://localhost:6333" ) client . create_collection ( collection_name = " {collection_name} " , vectors_config = models .

VectorParams ( size = 300 , distance = models .

Distance .

COSINE ), shard_number = 6 , replication_factor = 2 , write_consistency_factor = 2 , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "localhost" , port : 6333 }); client . createCollection ( "{collection_name}" , { vectors : { size : 300 , distance : "Cosine" , }, shard_number : 6 , replication_factor : 2 , write_consistency_factor : 2 , }); use qdrant_client :: qdrant :: { CreateCollectionBuilder , Distance , VectorParamsBuilder }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . create_collection ( CreateCollectionBuilder :: new ( "{collection_name}" ) . vectors_config ( VectorParamsBuilder :: new ( 300 , Distance :: Cosine )) . shard_number ( 6 ) . replication_factor ( 2 ) . write_consistency_factor ( 2 ), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Collections.CreateCollection ; import io.qdrant.client.grpc.Collections.Distance ; import io.qdrant.client.grpc.Collections.VectorParams ; import io.qdrant.client.grpc.Collections.VectorsConfig ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . createCollectionAsync ( CreateCollection . newBuilder () . setCollectionName ( "{collection_name}" ) . setVectorsConfig ( VectorsConfig . newBuilder () . setParams ( VectorParams . newBuilder () . setSize ( 300 ) . setDistance ( Distance .

Cosine ) . build ()) . build ()) . setShardNumber ( 6 ) . setReplicationFactor ( 2 ) . setWriteConsistencyFactor ( 2 ) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

CreateCollectionAsync ( collectionName : "{collection_name}" , vectorsConfig : new VectorParams { Size = 300 , Distance = Distance .

Cosine }, shardNumber : 6 , replicationFactor : 2 , writeConsistencyFactor : 2 ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

CreateCollection ( context .

Background (), & qdrant .

CreateCollection { CollectionName : "{collection_name}" , VectorsConfig : qdrant .

NewVectorsConfig ( & qdrant .

VectorParams { Size : 300 , Distance : qdrant .

Distance_Cosine , }), ShardNumber : qdrant .

PtrOf ( uint32 ( 6 )), ReplicationFactor : qdrant .

PtrOf ( uint32 ( 2 )), WriteConsistencyFactor : qdrant .

PtrOf ( uint32 ( 2 )), }) Write operations will fail if the number of active replicas is less than the write_consistency_factor . In this case, the client is expected to send the operation again to ensure a consistent state is reached.

Setting the write_consistency_factor to a lower value may allow accepting writes even if there are unresponsive nodes. Unresponsive nodes are marked as dead and will automatically be recovered once available to ensure data consistency.

The configuration of the write_consistency_factor is important for adjusting the cluster‚Äôs behavior when some nodes go offline due to restarts, upgrades, or failures.

By default, the cluster continues to accept updates as long as at least one replica of each shard is online. However, this behavior means that once an offline replica is restored, it will require additional synchronization with the rest of the cluster. In some cases, this synchronization can be resource-intensive and undesirable.

Setting the write_consistency_factor to match the replication factor modifies the cluster‚Äôs behavior so that unreplicated updates are rejected, preventing the need for extra synchronization.

If the update is applied to enough replicas - according to the write_consistency_factor - the update will return a successful status. Any replicas that failed to apply the update will be temporarily disabled and are automatically recovered to keep data consistency. If the update could not be applied to enough replicas, it‚Äôll return an error and may be partially applied. The user must submit the operation again to ensure data consistency.

For asynchronous updates and injection pipelines capable of handling errors and retries, this strategy might be preferable.

Read consistency Read consistency can be specified for most read requests and will ensure that the returned result is consistent across cluster nodes. all will query all nodes and return points, which present on all of them majority will query all nodes and return points, which present on the majority of them quorum will query randomly selected majority of nodes and return points, which present on all of them 1 / 2 / 3 /etc - will query specified number of randomly selected nodes and return points which present on all of them default consistency is 1 POST /collections/{collection_name}/points/query?consistency=majority { "query": [0.2, 0.1, 0.9, 0.7], "filter": { "must": [ { "key": "city", "match": { "value": "London" } } ] }, "params": { "hnsw_ef": 128, "exact": false }, "limit": 3 } client . query_points ( collection_name = " {collection_name} " , query = [ 0.2 , 0.1 , 0.9 , 0.7 ], query_filter = models .

Filter ( must = [ models .

FieldCondition ( key = "city" , match = models .

MatchValue ( value = "London" , ), ) ] ), search_params = models .

SearchParams ( hnsw_ef = 128 , exact = False ), limit = 3 , consistency = "majority" , ) client . query ( "{collection_name}" , { query : [ 0.2 , 0.1 , 0.9 , 0.7 ], filter : { must : [{ key : "city" , match : { value : "London" } }], }, params : { hnsw_ef : 128 , exact : false , }, limit : 3 , consistency : "majority" , }); use qdrant_client :: qdrant :: { read_consistency :: Value , Condition , Filter , QueryPointsBuilder , ReadConsistencyType , SearchParamsBuilder , }; use qdrant_client :: { Qdrant , QdrantError }; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . query ( QueryPointsBuilder :: new ( "{collection_name}" ) . query ( vec!

[ 0.2 , 0.1 , 0.9 , 0.7 ]) . limit ( 3 ) . filter ( Filter :: must ([ Condition :: matches ( "city" , "London" . to_string (), )])) . params ( SearchParamsBuilder :: default (). hnsw_ef ( 128 ). exact ( false )) . read_consistency ( Value :: Type ( ReadConsistencyType :: Majority . into ())), ) . await ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ; import io.qdrant.client.grpc.Common.Filter ; import io.qdrant.client.grpc.Points.QueryPoints ; import io.qdrant.client.grpc.Points.ReadConsistency ; import io.qdrant.client.grpc.Points.ReadConsistencyType ; import io.qdrant.client.grpc.Points.SearchParams ; import static io.qdrant.client.QueryFactory.nearest ; import static io.qdrant.client.ConditionFactory.matchKeyword ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "localhost" , 6334 , false ). build ()); client . queryAsync ( QueryPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . setFilter ( Filter . newBuilder (). addMust ( matchKeyword ( "city" , "London" )). build ()) . setQuery ( nearest (.

2f , 0 .

1f , 0 .

9f , 0 .

7f )) . setParams ( SearchParams . newBuilder (). setHnswEf ( 128 ). setExact ( false ). build ()) . setLimit ( 3 ) . setReadConsistency ( ReadConsistency . newBuilder (). setType ( ReadConsistencyType .

Majority ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; using static Qdrant .

Client .

Grpc .

Conditions ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

QueryAsync ( collectionName : "{collection_name}" , query : new float [] { 0.2f , 0.1f , 0.9f , 0.7f }, filter : MatchKeyword ( "city" , "London" ), searchParams : new SearchParams { HnswEf = 128 , Exact = false }, limit : 3 , readConsistency : new ReadConsistency { Type = ReadConsistencyType .

Majority } ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Query ( context .

Background (), & qdrant .

QueryPoints { CollectionName : "{collection_name}" , Query : qdrant .

NewQuery ( 0.2 , 0.1 , 0.9 , 0.7 ), Filter : & qdrant .

Filter { Must : [] * qdrant .

Condition { qdrant .

NewMatch ( "city" , "London" ), }, }, Params : & qdrant .

SearchParams { HnswEf : qdrant .

PtrOf ( uint64 ( 128 )), }, Limit : qdrant .

PtrOf ( uint64 ( 3 )), ReadConsistency : qdrant .

NewReadConsistencyType ( qdrant .

ReadConsistencyType_Majority ), }) Write ordering Write ordering can be specified for any write request to serialize it through a single ‚Äúleader‚Äù node, which ensures that all write operations (issued with the same ordering ) are performed and observed sequentially. weak (default) ordering does not provide any additional guarantees, so write operations can be freely reordered. medium ordering serializes all write operations through a dynamically elected leader, which might cause minor inconsistencies in case of leader change. strong ordering serializes all write operations through the permanent leader, which provides strong consistency, but write operations may be unavailable if the leader is down.

PUT /collections/{collection_name}/points?ordering=strong { "batch": { "ids": [1, 2, 3], "payloads": [ {"color": "red"}, {"color": "green"}, {"color": "blue"} ], "vectors": [ [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9] ] } } client . upsert ( collection_name = " {collection_name} " , points = models .

Batch ( ids = [ 1 , 2 , 3 ], payloads = [ { "color" : "red" }, { "color" : "green" }, { "color" : "blue" }, ], vectors = [ [ 0.9 , 0.1 , 0.1 ], [ 0.1 , 0.9 , 0.1 ], [ 0.1 , 0.1 , 0.9 ], ], ), ordering = models .

WriteOrdering .

STRONG , ) client . upsert ( "{collection_name}" , { batch : { ids : [ 1 , 2 , 3 ], payloads : [{ color : "red" }, { color : "green" }, { color : "blue" }], vectors : [ [ 0.9 , 0.1 , 0.1 ], [ 0.1 , 0.9 , 0.1 ], [ 0.1 , 0.1 , 0.9 ], ], }, ordering : "strong" , }); use qdrant_client :: qdrant :: { PointStruct , UpsertPointsBuilder , WriteOrdering , WriteOrderingType }; use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ; client . upsert_points ( UpsertPointsBuilder :: new ( "{collection_name}" , vec!

[ PointStruct :: new ( 1 , vec!

[ 0.9 , 0.1 , 0.1 ], [( "color" , "red" . into ())]), PointStruct :: new ( 2 , vec!

[ 0.1 , 0.9 , 0.1 ], [( "color" , "green" . into ())]), PointStruct :: new ( 3 , vec!

[ 0.1 , 0.1 , 0.9 ], [( "color" , "blue" . into ())]), ], ) . ordering ( WriteOrdering { r#type : WriteOrderingType :: Strong . into (), }), ) . await ? ; import java.util.List ; import java.util.Map ; import static io.qdrant.client.PointIdFactory.id ; import static io.qdrant.client.ValueFactory.value ; import static io.qdrant.client.VectorsFactory.vectors ; import io.qdrant.client.grpc.Points.PointStruct ; import io.qdrant.client.grpc.Points.UpsertPoints ; import io.qdrant.client.grpc.Points.WriteOrdering ; import io.qdrant.client.grpc.Points.WriteOrderingType ; client . upsertAsync ( UpsertPoints . newBuilder () . setCollectionName ( "{collection_name}" ) . addAllPoints ( List . of ( PointStruct . newBuilder () . setId ( id ( 1 )) . setVectors ( vectors ( 0 .

9f , 0 .

1f , 0 .

1f )) . putAllPayload ( Map . of ( "color" , value ( "red" ))) . build (), PointStruct . newBuilder () . setId ( id ( 2 )) . setVectors ( vectors ( 0 .

1f , 0 .

9f , 0 .

1f )) . putAllPayload ( Map . of ( "color" , value ( "green" ))) . build (), PointStruct . newBuilder () . setId ( id ( 3 )) . setVectors ( vectors ( 0 .

1f , 0 .

1f , 0 .

94f )) . putAllPayload ( Map . of ( "color" , value ( "blue" ))) . build ())) . setOrdering ( WriteOrdering . newBuilder (). setType ( WriteOrderingType .

Strong ). build ()) . build ()) . get (); using Qdrant.Client ; using Qdrant.Client.Grpc ; var client = new QdrantClient ( "localhost" , 6334 ); await client .

UpsertAsync ( collectionName : "{collection_name}" , points : new List < PointStruct > { new () { Id = 1 , Vectors = new [] { 0.9f , 0.1f , 0.1f }, Payload = { [ "color" ] = "red" } }, new () { Id = 2 , Vectors = new [] { 0.1f , 0.9f , 0.1f }, Payload = { [ "color" ] = "green" } }, new () { Id = 3 , Vectors = new [] { 0.1f , 0.1f , 0.9f }, Payload = { [ "color" ] = "blue" } } }, ordering : WriteOrderingType .

Strong ); import ( "context" "github.com/qdrant/go-client/qdrant" ) client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "localhost" , Port : 6334 , }) client .

Upsert ( context .

Background (), & qdrant .

UpsertPoints { CollectionName : "{collection_name}" , Points : [] * qdrant .

PointStruct { { Id : qdrant .

NewIDNum ( 1 ), Vectors : qdrant .

NewVectors ( 0.9 , 0.1 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "red" }), }, { Id : qdrant .

NewIDNum ( 2 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.9 , 0.1 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "green" }), }, { Id : qdrant .

NewIDNum ( 3 ), Vectors : qdrant .

NewVectors ( 0.1 , 0.1 , 0.9 ), Payload : qdrant .

NewValueMap ( map [ string ] any { "color" : "blue" }), }, }, Ordering : & qdrant .

WriteOrdering { Type : qdrant .

WriteOrderingType_Strong , }, }) Listener mode In some cases it might be useful to have a Qdrant node that only accumulates data and does not participate in search operations.

There are several scenarios where this can be useful: Listener option can be used to store data in a separate node, which can be used for backup purposes or to store data for a long time.

Listener node can be used to synchronize data into another region, while still performing search operations in the local region.

To enable listener mode, set node_type to Listener in the config file: storage : node_type : "Listener" Listener node will not participate in search operations, but will still accept write operations and will store the data in the local storage.

All shards, stored on the listener node, will be converted to the Listener state.

Additionally, all write requests sent to the listener node will be processed with wait=false option, which means that the write oprations will be considered successful once they are written to WAL.

This mechanism should allow to minimize upsert latency in case of parallel snapshotting.

Consensus Checkpointing Consensus checkpointing is a technique used in Raft to improve performance and simplify log management by periodically creating a consistent snapshot of the system state.

This snapshot represents a point in time where all nodes in the cluster have reached agreement on the state, and it can be used to truncate the log, reducing the amount of data that needs to be stored and transferred between nodes.

For example, if you attach a new node to the cluster, it should replay all the log entries to catch up with the current state.

In long-running clusters, this can take a long time, and the log can grow very large.

To prevent this, one can use a special checkpointing mechanism, that will truncate the log and create a snapshot of the current state.

To use this feature, simply call the /cluster/recover API on required node: POST /cluster/recover This API can be triggered on any non-leader node, it will send a request to the current consensus leader to create a snapshot. The leader will in turn send the snapshot back to the requesting node for application.

In some cases, this API can be used to recover from an inconsistent cluster state by forcing a snapshot creation.

Weak ordering for updates: All records are streamed to the target node in order.

New updates are received on the target node in parallel, while the transfer of records is still happening. We therefore have weak ordering, regardless of what ordering is used for updates.

‚Ü©Ô∏é ‚Ü©Ô∏é Strong ordering for updates: A snapshot of the shard is created, it is transferred and recovered on the target node. That ensures the state of the shard is kept consistent. New updates are queued on the source node, and transferred in order to the target node. Updates therefore have the same ordering as the user selects, making strong ordering possible.

‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é
================================================================================
PAGE 26/39
================================================================================
Title: No Title
URL: https://qdrant.tech/documentation/guides/text-search/
--------------------------------------------------------------------------------

Text Search Qdrant is a vector search engine, making it a great tool for semantic search . However, Qdrant‚Äôs capabilities go beyond just vector search. It also supports a range of lexical search features, including filtering on text fields and full-text search using popular algorithms like BM25.

Semantic Search Semantic search is a search technique that focuses on the meaning of the text rather than just matching on keywords. This is achieved by converting text into vectors (embeddings) using machine learning models. These vectors capture the semantic meaning of the text, enabling you to find similar text even if it doesn‚Äôt share exact keywords.

For example, to search through a collection of books, you could use a model like the all-MiniLM-L6-v2 sentence transformer model. First, create a collection and configure a dense vector for the book descriptions: PUT /collections/books { "vectors": { "description-dense": { "size": 384, "distance": "Cosine" } } } Next, you can ingest data: PUT /collections/books/points?wait=true { "points": [ { "id": 1, "vector": { "description-dense": { "text": "A Victorian scientist builds a device to travel far into the future and observes the dim trajectories of humanity. He discovers evolutionary divergence and the consequences of class division. Wells's novella established time travel as a vehicle for social commentary.", "model": "sentence-transformers/all-minilm-l6-v2" } }, "payload": { "title": "The Time Machine", "author": "H.G. Wells", "isbn": "9780553213515" } } ] } To find books related to ‚Äútime travel‚Äù, use the following query: POST /collections/books/points/query { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true } In these examples, Qdrant uses inference to generate vectors from the text provided in the request using the specified model . Alternatively, you can generate explicit vectors on the client side with a library like FastEmbed .

Lexical Search Lexical search, also known as keyword-based search, is a traditional search technique that relies on matching words or phrases in the text. Many applications require a combination of semantic and traditional lexical search. A good example is in e-commerce, where users may want to search for products using a product ID. ID values don‚Äôt lend themselves well to vectorization, but being able to search for them is essential for a good search experience. To facilitate these use cases, Qdrant enables you to use lexical search alongside semantic search.

Filtering Versus Querying When it comes to lexical search in Qdrant, it‚Äôs important to distinguish between filtering and querying. Filtering is used to narrow down results based on exact matches or specific criteria, while querying involves finding relevant documents based on the content of the text. In other words, filtering is about precision, while querying is about recall. A filter does not contribute to the ranking of search results, as no score is calculated for filters. A query calculates a relevance score for each matching document and that score is used to rank search results.

Filter Query Does not contribute to ranking Contributes to ranking Improves precision by narrowing down results Improves recall by finding relevant data Filtering Qdrant supports filtering on a wide range of datatypes: numbers, dates, booleans, geolocations, and strings. In Qdrant, a filter is typically combined with a vector query. The vector query is used to score and rank the results, while the filter is used to narrow down the results based on specific criteria.

Text and Keyword Strings When it comes to filtering on strings, it is important to understand the difference between the two types of strings in Qdrant: text and keyword. These two string types are designed for different use cases: filtering on exact string values or filtering on individual search terms. To filter on exact string values, Qdrant uses keyword strings. Keyword strings are ideal for filtering on strings like IDs, categories, or tags. To filter on individual terms or phrases within a larger body of text, Qdrant uses text strings.

For example, take a string like ‚ÄúUnited States‚Äù. If you want to filter on all points with this exact string in the payload, use a keyword filter. On the other hand, if you want to filter on all points that contain the word ‚Äúunited‚Äù (matching ‚ÄúUnited States‚Äù as well as ‚ÄúUnited Kingdom‚Äù), use a text filter.

Keyword Text Used for exact string matches Used for filtering on individual terms Ideal for IDs, categories, tags Ideal for larger text fields Not tokenized Tokenized into individual terms Case-sensitive Case-insensitive by default Filtering on an Exact String To filter on exact strings, first create a payload index of type keyword for the field you want to filter on. A payload index makes filtering faster and reduces the load on the system.

For example, to filter books by author name, create a keyword index on the ‚Äúauthor‚Äù field: PUT /collections/books/index?wait=true { "field_name": "author", "field_schema": "keyword" } Next, when querying the data, you also add a filter clause to the request. The following example searches for books related to ‚Äútime travel‚Äù but only returns books written by H.G. Wells: POST /collections/books/points/query { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "author", "match": { "value": "H.G. Wells" } } ] } } The ranking of the results of this request is based on the vector similarity of the query. The filter only narrows down the results to those points where the author field exactly matches H.G. Wells . Furthermore, the filter is case-sensitive. Filtering for the lowercase value h.g. wells would not return any results.

The previous example only returns points that match the filter value. If you want the opposite: exclude points with a specific value, use a must_not clause instead of must . The following example only returns books not written by H.G. Wells: POST /collections/books/points/query { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must_not": [ { "key": "author", "match": { "value": "H.G. Wells" } } ] } } Filtering on Multiple Exact Strings You can provide multiple filter clauses. For example, to find all books co-authored by Larry Niven and Jerry Pournelle, use the following filter: POST /collections/books/points/query { "query": { "text": "space opera", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "author", "match": { "value": "Larry Niven" } }, { "key": "author", "match": { "value": "Jerry Pournelle" } } ] } } Note that both filter clauses must be true for a point to be included in the results, because a must clause operates like a logical AND . If you want to find books written by either author (as well as both), use a should clause, which operates like a logical OR : POST /collections/books/points/query { "query": { "text": "space opera", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "should": [ { "key": "author", "match": { "value": "Larry Niven" } }, { "key": "author", "match": { "value": "Jerry Pournelle" } } ] } } Alternatively, when you want to filter on one or more values of a single key, you can use the any condition: POST /collections/books/points/query { "query": { "text": "space opera", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "author", "match": { "any": ["Larry Niven", "Jerry Pournelle"] } } ] } } Full-Text Filtering In contrast to keyword filtering, filtering on text strings enables you to filter on individual words within a larger text field in a case-insensitive manner. To understand how this works, it‚Äôs important to understand how text strings are processed at index time and query time.

Text Processing To enable efficient full-text filtering, Qdrant processes text strings by breaking them down into individual tokens (words) and applying several normalization steps. This process ensures that searches are more flexible and can match variations of words. At query time, Qdrant applies the same processing steps to the filter string, ensuring that the filter matches the indexed tokens correctly.

The following text processing steps are applied to text strings: The string is broken down into individual tokens (words) using a process called tokenization . By default, Qdrant uses the word tokenizer, which splits the string using word boundaries, discarding spaces, punctuation marks, and special characters.

By default, each word is then converted to lowercase . Lowercasing the tokens allows Qdrant to ignore capitalization, making full-text filters case-insensitive.

Optionally, Qdrant can remove diacritics (accents) from characters using a process called ASCII folding . This ensures that diacritics are ignored. As a result, filtering for the word ‚Äúcafe‚Äù matches ‚Äúcaf√©‚Äù.

Optionally, tokens can be reduced to their root form using a stemmer . This ensures that filtering for ‚Äúrunning‚Äù also matches ‚Äúrun‚Äù and ‚Äúran‚Äù. Because stemming is language-specific, if enabled, it must be configured for a specific language.

Certain words like ‚Äúthe‚Äù, ‚Äúis‚Äù, and ‚Äúand‚Äù are very common in text and do not contribute much to the meaning of text. These words are called stopwords and can optionally be removed during indexing. Like stemming, stopword removal is language-specific. You can configure specific languages for stopword removal and/or provide a custom list of stopwords to remove.

Optionally, you can enable phrase matching to allow filtering for multiple words in the exact same order as they appear in the original text.

These text processing steps can be configured when creating a full-text index . For example, to create a text index on the title field with ASCII folding enabled: PUT /collections/books/index?wait=true { "field_name": "title", "field_schema": { "type": "text", "ascii_folding": true } } When querying using this index, Qdrant automatically applies the same text processing steps to the filter string before matching it against the indexed tokens.

Filter on Text Strings To filter on text values in a payload field, first create a full-text index for that field. Next, you can use a text condition to query the collection with a filter for titles that contain the word ‚Äúspace‚Äù: POST /collections/books/points/query { "query": { "text": "space opera", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "title", "match": { "text": "space" } } ] } } When filtering on more than one term, a text filter only matches fields that contain all the specified terms (logical AND ). To match fields that contain any of the specified terms (logical OR ), use the text_any condition: POST /collections/books/points/query { "query": { "text": "space opera", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "title", "match": { "text_any": "space war" } } ] } } Qdrant also supports phrase filtering, enabling you to search for multiple words in the exact order they appear in the original text, with no other words in between. For example, a phrase filter for ‚Äútime machine‚Äù matches against the title ‚ÄúThe Time Machine‚Äù but would not match ‚ÄúThe Time Travel Machine‚Äù (there‚Äôs a word between ‚Äútime‚Äù and ‚Äúmachine‚Äù) nor ‚ÄúMachine Time‚Äù (the word order is incorrect).

The difference between phrase filtering and keyword filtering is that phrase filtering applies text processing and, as a result, is case-insensitive, while keyword filtering is case-sensitive and only matches the exact string. Additionally, keyword filtering has to match the entire string, whereas phrase filtering can match part of a larger string. So a keyword filter for ‚ÄúSpace War‚Äù would not match ‚ÄúThe Space War‚Äù because it doesn‚Äôt match ‚ÄúThe,‚Äù but a phrase filter for ‚ÄúSpace War‚Äù would.

Summarizing the differences between the four filtering methods for a multi-term filter on ‚ÄúSpace War‚Äù: Method Actual‚†Äquery‚†Ä‚†Ä‚†Ä Matches Space War ?

Matches The Space War ?

Matches War in Space ?

Matches War of the Worlds ? text_any space OR war Yes Yes Yes Yes text space AND war Yes Yes Yes No phrase "space war" Yes Yes No No keyword "Space War" Yes No No No To filter on phrases, use a phrase condition. This requires enabling phrase searching when creating the full-text index: PUT /collections/books/index?wait=true { "field_name": "title", "field_schema": { "type": "text", "ascii_folding": true, "phrase_matching": true } } Next, you can use a phrase condition to filter for titles that contain the exact phrase ‚Äútime machine‚Äù: POST /collections/books/points/query?wait=true { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "title", "match": { "phrase": "time machine" } } ] } } Progressive Filtering with the Batch Search API Even though filters are not used to rank results, you can use the batch search API to progressively relax filters. This is useful when you have strict filtering criteria that may not return results. Batching multiple search requests with progressively relaxed filters enables you to get results even when the strictest filter returns no results.

For example, the following batch search request first tries to find books that match all search terms in the title. The second search request relaxes the filter to match any of the search terms. The third search request removes the filter altogether: POST /collections/books/points/query/batch { "searches": [ { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "title", "match": { "text": "time travel" } } ] } }, { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true, "filter": { "must": [ { "key": "title", "match": { "text_any": "time travel" } } ] } }, { "query": { "text": "time travel", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "with_payload": true } ] } The response contains three separate result sets. You can return the first non-empty result set to the user, or you can use the three sets to assemble a single ranked list.

Full-Text Search Full-text search is similar to full-text filtering, with the key difference being that full-text queries are used for ranking. For each document that matches the search terms, Qdrant calculates a relevance score based on how well the document matches the search terms. That score is used to rank the results. Qdrant supports several full-text search scoring algorithms.

Full-text search in Qdrant is powered by sparse vectors . Why sparse vectors? Because they are a flexible way to represent data for search purposes, from classic BM25-based search, to semantic search, and collaborative filtering . Each term in the vocabulary corresponds to one or more dimension of the sparse vector, and the values in those dimensions represent the weight of that term in the document. Weights can be calculated using document statistics for use with the BM25 ranking algorithm, or you can use transformer-based models that can capture semantic meaning, like SPLADE++ , and miniCOIL .

BM25 BM25 (Best Matching 25) is a popular ranking algorithm that takes a probabilistic approach to score calculation. For each search term, BM25 considers several statistics about the term and the document to calculate a relevance score: Term frequency (TF): the more often a term appears in a document, the more relevant that document is likely to be.

Inverse document frequency (IDF): the rarer a term is across all documents, the higher the weight of that term.

Document length: a term appearing in a shorter document is more relevant than the same term appearing in a longer document.

Qdrant provides native support for BM25 through an inference model that generates sparse vectors, or you can generate vectors on the client side using the FastEmbed library.

The BM25 model supports the same text processing options as text indices, including tokenization, lowercasing, ASCII folding, stemming, and stopword removal. A notable difference with text indices is that BM25 defaults to English stemming and stopword removal. If you are using a language other than English, ensure that you configure the model accordingly.

To use BM25, configure a sparse vector when creating a collection: PUT /collections/books?wait=true { "sparse_vectors": { "title-bm25": { "modifier": "idf" } } } Note the IDF modifier , which configures the sparse vector for queries that use the inverse document frequency (IDF).

Now you can ingest data. The following example ingests a book with its title represented as a sparse vector generated by the BM25 model: PUT /collections/books/points?wait=true { "points": [ { "id": 1, "vector": { "title-bm25": { "text": "The Time Machine", "model": "qdrant/bm25" } }, "payload": { "title": "The Time Machine", "author": "H.G. Wells", "isbn": "9780553213515" } } ] } After ingesting data, you can query the sparse vector. The following example searches for books with ‚Äútime travel‚Äù in the title using the BM25 model: POST /collections/books/points/query { "query": { "text": "time travel", "model": "qdrant/bm25" }, "using": "title-bm25", "limit": 10, "with_payload": true } Configuring BM25 Parameters The BM25 ranking function includes three adjustable parameters that you can set to optimize search results for your specific use case: k . Controls term frequency saturation. Higher values increase the influence of term frequency. Defaults to 1.2. b . Controls document length normalization. Ranges from 0 (no normalization) to 1 (full normalization). A higher value means longer documents have less impact. Defaults to 0.75. avg_len . Average number of words in the field being queried. Defaults to 256.

For instance, book titles are generally shorter than 256 words. To achieve more accurate scoring when searching for book titles, you could calculate or estimate the average title length and set the avg_len parameter accordingly: POST /collections/books/points/query { "query": { "text": "time travel", "model": "qdrant/bm25", "options": { "avg_len": 5.0 } }, "using": "title-bm25", "limit": 10, "with_payload": true } Language-specific Settings By default, BM25 uses English-specific settings for tokenization, stemming, and stopword removal. Words are reduced to their English root form, and common English stopwords are removed. If your data is not in English, this leads to suboptimal search results. To achieve optimal results for other languages, configure language-specific BM25 settings.

Stemming and Stopwords To configure stemming and stopword removal, use the following options: language : sets the language for stemming and stopword removal. Defaults to english . To disable stemming and stopword removal, set language to none . stemmer : defaults to stemming for language (if set), but can be configured independently. stopwords : defaults to a set of stopwords for language (if set) but can be configured independently. You can configure a specific language and/or configure an explicit set of stopwords that will be merged with the stopword set of the configured language.

For example, to use Spanish stemming and stopwords during data ingestion, use: PUT /collections/books/points?wait=true { "points": [ { "id": 1, "vector": { "title-bm25": { "text": "La M√°quina del Tiempo", "model": "qdrant/bm25", "options": { "language": "spanish" } } }, "payload": { "title": "La M√°quina del Tiempo", "author": "H.G. Wells", "isbn": "9788411486880" } } ] } At query time, use the exact same parameters to ensure consistent text processing: POST /collections/books/points/query { "query": { "text": "tiempo", "model": "qdrant/bm25", "options": { "language": "spanish" } }, "using": "title-bm25", "limit": 10, "with_payload": true } To configure only a stemmer or a stopword set, rather than both, set language to none and specify the configuration for the desired stemmer or stopwords.

ASCII Folding ASCII folding is the process of removing diacritics (accents) from characters. By removing diacritics, ASCII folding enables you to ignore accents when searching. For instance, with ASCII folding enabled, searching for ‚Äúcafe‚Äù matches both ‚Äúcafe‚Äù and ‚Äúcaf√©‚Äù.

To enable ASCII folding, set the ascii_folding option to true at both ingest and query time: POST /collections/books/points/query { "query": { "text": "Mieville", "model": "qdrant/bm25", "options": { "ascii_folding": true } }, "using": "author-bm25", "limit": 10, "with_payload": true } Tokenizer The tokenizer breaks down text into individual tokens (words). By default, the BM25 model uses the word tokenizer, which splits text based on word boundaries like whitespace and punctuation. This method is effective for Latin-based languages but may not work well for languages with non-Latin alphabets or languages that do not use spaces to separate words. For those languages, use the multilingual tokenizer. This tokenizer supports multiple languages, including those with non-Latin alphabets and non-space delimiters.

POST /collections/books/points/query { "query": { "text": "Êùë‰∏äÊò•Ê®π", "model": "qdrant/bm25", "options": { "tokenizer": "multilingual" } }, "using": "author-bm25", "limit": 10, "with_payload": true } Language-neutral Text Processing In some situations, you may want to disable language-specific processing altogether. For example, when searching for author names, that don‚Äôt necessarily conform to the rules of a specific language.

To disable language-specific processing, set the following options: language : set to none to disable language-specific stemming and stopword removal. tokenizer : set to multilingual for multilingual tokenization and lemmatization.

Optionally, set ascii_folding to true to enable ASCII folding and ignore diacritics.

POST /collections/books/points/query { "query": { "text": "Mieville", "model": "qdrant/bm25", "options": { "language": "none", "tokenizer": "multilingual", "ascii_folding": true } }, "using": "author-bm25", "limit": 10, "with_payload": true } SPLADE++ The SPLADE (Sparse Lexical and Dense) family of models are transformer-based models that generate sparse vectors out of text. These models combine the benefits of traditional lexical search with the power of transformer-based models by accounting for homonyms and synonyms. SPLADE models achieve this by expanding the vocabulary of the input text using contextual embeddings from the transformer model. For example, when processing the input text ‚Äútime travel‚Äù, a SPLADE model may expand the input to include related terms like ‚Äútemporal‚Äù, ‚Äújourney‚Äù, and ‚Äúchronology‚Äù. This expansion allows SPLADE models to capture the semantic meaning of the text while still leveraging the strengths of lexical search.

The advantage of using SPLADE models is that they perform better than traditional BM25. They also have several downsides though. First, because they use a fixed vocabulary, you can‚Äôt use SPLADE models to find terms that are not in the vocabulary, such as product IDs and out-of-domain language (words not seen in training). Secondly, because they are transformer-based models, SPLADE models are slower and require more computational resources than the traditional BM25 model.

On Qdrant Cloud , you can use the SPLADE++ model with inference. Alternatively, you can generate vectors on the client side using the FastEmbed library.

POST /collections/books/points/query { "query": { "text": "time travel", "model": "prithivida/splade_pp_en_v1" }, "using": "title-splade", "limit": 10, "with_payload": true } For a tutorial on using SPLADE++ with FastEmbed, refer to How to Generate Sparse Vectors with SPLADE . miniCOIL miniCOIL strikes a balance between the flexibility of BM25 and the performance of SPLADE++. miniCOIL is a transformer-based model that generates sparse vectors for text. Unlike SPLADE++, it doesn‚Äôt use a vocabulary expansion mechanism. To capture the context and meaning of terms, the model generates a four-dimensional vector for each term. miniCOIL does not use a fixed vocabulary, making it an effective model for lexical search that ranks results based on the contextual meaning of keywords. miniCOIL can be used with the FastEmbed library .

Combining Semantic and Lexical Search with Hybrid Search Hybrid search enables you to combine semantic and lexical search in a single query, returning results that match the semantic meaning, the exact keywords, or both. This is useful when you don‚Äôt know whether the user is looking for a specific keyword or a semantically similar document. For example, when searching for books, a user may enter ‚Äútime travel‚Äù to find books related to the concept of time travel, but they may also enter a book‚Äôs ISBN to find a specific book. Hybrid queries enable you to return results for both cases in a single query.

Hybrid queries make use of Qdrant‚Äôs ability to store multiple named vectors in a single point. For example, you can store a dense vector for semantic search and a sparse vector for lexical search in the same point. To do so, first create a collection with both a dense vector and a sparse vector: PUT /collections/books?wait=true { "vectors": { "description-dense": { "size": 384, "distance": "Cosine" } }, "sparse_vectors": { "isbn-bm25": { "modifier": "idf" } } } After ingesting data with both vectors, you can use the prefetch feature to run both semantic and lexical queries in a single request. The results of both queries are then combined using a fusion method like Reciprocal Rank Fusion (RRF).

POST /collections/books/points/query { "prefetch": [ { "query": { "text": "9780553213515", "model": "sentence-transformers/all-minilm-l6-v2" }, "using": "description-dense", "score_threshold": 0.5 }, { "query": { "text": "9780553213515", "model": "Qdrant/bm25" }, "using": "isbn-bm25", "with_payload": true } ], "query": { "fusion": "rrf" }, "limit": 10, "with_payload": true } This query searches for an ISBN, for which only the lexical search returns a result. The score_threshold for the semantic query prevents low-scoring results to be returned (0.5 is just an example threshold; you need to tune what a good threshold is for your data and model). So in this case, only the lexical result is returned to the user. If a user had searched for ‚Äútime travel‚Äù, only the semantic search would return results, and those would be returned to the user. If a user would search for a term that matched both the semantic and lexical vectors, the results from both searches would be combined to provide a more comprehensive set of results.

You are not limited to prefetching just two queries. Examples include, but are not limited to: Fuse multiple lexical queries across the title , author , and isbn fields alongside a semantic query to achieve a comprehensive search across all data.

Prefetch using sparse or dense vectors and/or filters, and rescore with dense vectors .

Prefetch with dense and sparse vectors, and rerank using late interaction embeddings .

Conclusion Qdrant‚Äôs text search capabilities enable you to build powerful search applications that combine the best of semantic and lexical search. By leveraging dense and sparse vectors, along with Qdrant‚Äôs flexible querying capabilities, you can create search experiences that meet a wide range of user needs.

================================================================================
PAGE 27/39
================================================================================
Title: Monitoring & Telemetry
URL: https://qdrant.tech/documentation/guides/monitoring/
--------------------------------------------------------------------------------

Monitoring & Telemetry Qdrant exposes its metrics in Prometheus / OpenMetrics format, so you can integrate them easily with the compatible tools and monitor Qdrant with your own monitoring system. You can use the /metrics endpoint and configure it as a scrape target.

Metrics endpoint: http://localhost:6333/metrics The integration with Qdrant is easy to configure with Prometheus and Grafana.

Metrics Qdrant exposes various metrics in Prometheus/OpenMetrics format, commonly used together with Grafana for monitoring.

Two endpoints are available: /metrics for metrics of a Qdrant node/peer, see all metrics .

/sys_metrics (Qdrant Cloud only) for metrics about your cluster, like CPU, memory, disk utilisation, collection metrics and load balancer telemetry. For more information, see Qdrant Cloud Monitoring .

Note that /metrics only reports metrics for the peer connected to. It is therefore important to scrape from each peer individually, even if a load balancer is involved.

Node metrics /metrics Each Qdrant node will expose the following metrics.

Counters - such as the number of created snapshots - are reset when the node is restarted.

Application metrics Name Type Meaning app_info gauge Qdrant server name and version app_status_recovery_mode gauge If started in recovery mode Collection metrics Name Type Meaning collections_total gauge Number of collections collection_points gauge Number of points, per collection (v1.16+) collection_vectors gauge Number of vectors, per collection and vector name (v1.16+) collections_vector_total gauge Number of vectors in all collections collection_indexed_only_excluded_points gauge Number of points excluded in indexed_only search, per collection and vector name (v1.16+) collection_active_replicas_min gauge Minimum number of active replicas across all collections and shards (v1.16+) collection_active_replicas_max gauge Maximum number of active replicas across all collections and shards (v1.16+) collection_dead_replicas gauge Number of non-active replicas across all collections and shards (v1.16+) collection_running_optimizations gauge Number of running optimization tasks, per collection (v1.16+) collection_hardware_metric_cpu counter CPU measurements of a collection, per collection (v1.13+) 1 collection_hardware_metric_payload_io_read counter Payload IO read operations measurement, per collection (v1.13+) 1 collection_hardware_metric_payload_io_write counter Payload IO write operations measurement, per collection (v1.13+) 1 collection_hardware_metric_payload_index_io_read counter Payload index read operations measurement, per collection (v1.13+) 1 collection_hardware_metric_payload_index_io_write counter Payload index write operations measurement, per collection (v1.13+) 1 collection_hardware_metric_vector_io_read counter Vector IO read operations measurement, per collection (v1.13+) 1 collection_hardware_metric_vector_io_write counter Vector IO write operations measurement, per collection (v1.13+) 1 Snapshot metrics Name Type Meaning snapshot_creation_running gauge Number of snapshots being created, per collection (v1.16+) snapshot_recovery_running gauge Number of snapshots being recovered, per collection (v1.16+) snapshot_created_total counter Number of created snapshots since start, per collection (v1.16+) API response metrics Name Type Meaning rest_responses_total counter Number of responses through REST API rest_responses_fail_total counter Number of failed responses through REST API rest_responses_avg_duration_seconds gauge Average response duration in REST API rest_responses_min_duration_seconds gauge Minimum response duration in REST API rest_responses_max_duration_seconds gauge Maximum response duration in REST API rest_responses_duration_seconds histogram Histogram of response durations in the REST API (v1.8+) grpc_responses_total counter Number of responses through gRPC API grpc_responses_fail_total counter Number of failed responses through REST API grpc_responses_avg_duration_seconds gauge Average response duration in gRPC API grpc_responses_min_duration_seconds gauge Minimum response duration in gRPC API grpc_responses_max_duration_seconds gauge Maximum response duration in gRPC API grpc_responses_duration_seconds histogram Histogram of response durations in the gRPC API (v1.8+) Process metrics Name Type Meaning memory_active_bytes gauge Total number of bytes in active pages allocated by the application ( ref ) memory_allocated_bytes gauge Total number of bytes allocated by the application ( ref ) memory_metadata_bytes gauge Total number of bytes dedicated to allocator metadata ( ref ) memory_resident_bytes gauge Maximum number of bytes in physically resident data pages mapped ( ref ) memory_retained_bytes gauge Total number of bytes in virtual memory mappings ( ref ) process_threads gauge Number of used system threads (v1.16+) process_open_mmaps gauge Number of open memory maps (v1.16+) system_max_mmaps gauge System wide maximum number of open memory maps (v1.16+) process_open_fds gauge Number of open file descriptors (v1.16+) process_max_fds gauge Maximum number of open file descriptors (v1.16+) process_minor_page_faults_total counter Number of minor page faults encountered by the process (v1.16+) process_major_page_faults_total counter Number of major page faults encountered by the process (v1.16+) Cluster metrics (consensus) Metrics reporting the current cluster consensus state of the node. Exposed only when distributed mode is enabled.

Name Type Meaning cluster_enabled gauge If distributed mode is enabled 2 cluster_peers_total gauge Number of cluster peers 2 cluster_term counter Raft consensus term 2 cluster_commit counter Raft consensus commit - last committed operation 2 cluster_pending_operations_total gauge Number of pending consensus operations 2 cluster_voter gauge If a consensus voter ( 1 ) or learner ( 0 ) 2 Metrics configuration Available as of v1.16.0 In self-hosted environments you have further configuration options for metrics.

By default, all Qdrant metrics have no application namespace prefix. You may set a prefix with service.metrics_prefix in the configuration .

To achieve this you may use the following environment variable for example: QDRANT__SERVICE__METRICS_PREFIX = "qdrant_" Telemetry endpoint Qdrant also provides a /telemetry endpoint, which provides information about the current state of the database, including the number of vectors, shards, and other useful information. You can find a full documentation of this endpoint in the API reference .

Kubernetes health endpoints Available as of v1.5.0 Qdrant exposes three endpoints, namely /healthz , /livez and /readyz , to indicate the current status of the Qdrant server.

These currently provide the most basic status response, returning HTTP 200 if Qdrant is started and ready to be used.

Regardless of whether an API key is configured, the endpoints are always accessible.

You can read more about Kubernetes health endpoints here .

Only reported if hardware metrics are enabled in the configuration. See service.hardware_reporting in the configuration .

‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é Only reported if distributed mode (cluster mode) is enabled. Enabled by default in all Qdrant Cloud environments. See cluster.enabled in the configuration .

‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é ‚Ü©Ô∏é
================================================================================
PAGE 28/39
================================================================================
Title: Configuration
URL: https://qdrant.tech/documentation/guides/configuration/
--------------------------------------------------------------------------------

Configuration Qdrant ships with sensible defaults for collection and network settings that are suitable for most use cases. You can view these defaults in the Qdrant source . If you need to customize the settings, you can do so using configuration files and environment variables.

Configuration Files To customize Qdrant, you can mount your configuration file in any of the following locations. This guide uses .yaml files, but Qdrant also supports other formats such as .toml , .json , and .ini .

Main Configuration: qdrant/config/config.yaml Mount your custom config.yaml file to override default settings: docker run -p 6333:6333 \ -v $( pwd ) /config.yaml:/qdrant/config/config.yaml \ qdrant/qdrant Environment-Specific Configuration: config/{RUN_MODE}.yaml Qdrant looks for an environment-specific configuration file based on the RUN_MODE variable. By default, the official Docker image uses RUN_MODE=production , meaning it will look for config/production.yaml .

You can override this by setting RUN_MODE to another value (e.g., dev ), and providing the corresponding file: docker run -p 6333:6333 \ -v $( pwd ) /dev.yaml:/qdrant/config/dev.yaml \ -e RUN_MODE = dev \ qdrant/qdrant Local Configuration: config/local.yaml The local.yaml file is typically used for machine-specific settings that are not tracked in version control: docker run -p 6333:6333 \ -v $( pwd ) /local.yaml:/qdrant/config/local.yaml \ qdrant/qdrant Custom Configuration via --config-path You can specify a custom configuration file path using the --config-path argument. This will override other configuration files: docker run -p 6333:6333 \ -v $( pwd ) /config.yaml:/path/to/config.yaml \ qdrant/qdrant \ ./qdrant --config-path /path/to/config.yaml For details on how these configurations are loaded and merged, see the loading order and priority . The full list of available configuration options can be found below .

Environment Variables You can also configure Qdrant using environment variables, which always take the highest priority and override any file-based settings.

Environment variables follow this format: they should be prefixed with QDRANT__ , and nested properties should be separated by double underscores ( __ ). For example: docker run -p 6333:6333 \ -e QDRANT__LOG_LEVEL = INFO \ -e QDRANT__SERVICE__API_KEY = <MY_SECRET_KEY> \ -e QDRANT__SERVICE__ENABLE_TLS = 1 \ -e QDRANT__TLS__CERT = ./tls/cert.pem \ qdrant/qdrant This results in the following configuration: log_level : INFO service : enable_tls : true api_key : <MY_SECRET_KEY> tls : cert : ./tls/cert.pem Loading Order and Priority During startup, Qdrant merges multiple configuration sources into a single effective configuration. The loading order is as follows (from least to most significant): Embedded default configuration config/config.yaml config/{RUN_MODE}.yaml config/local.yaml Custom configuration file Environment variables Overriding Behavior Settings from later sources in the list override those from earlier sources: Settings in config/{RUN_MODE}.yaml (3) will override those in config/config.yaml (2).

A custom configuration file provided via --config-path (5) will override all other file-based settings.

Environment variables (6) have the highest priority and will override any settings from files.

Configuration Validation Qdrant validates the configuration during startup. If any issues are found, the server will terminate immediately, providing information about the error. For example: Error: invalid type: 64-bit integer `-1`, expected an unsigned 64-bit or smaller integer for key `storage.hnsw_index.max_indexing_threads` in config/production.yaml This ensures that misconfigurations are caught early, preventing Qdrant from running with invalid settings.

Configuration Options The following YAML example describes the available configuration options. log_level : INFO # Logging configuration # Qdrant logs to stdout. You may configure to also write logs to a file on disk.

# Be aware that this file may grow indefinitely.

# logger: #   # Logging format, supports `text` and `json` #   format: text #   on_disk: #     enabled: true #     log_file: path/to/log/file.log #     log_level: INFO #     # Logging format, supports `text` and `json` #     format: text #     buffer_size_bytes: 1024 storage : # Where to store all the data storage_path : ./storage # Where to store snapshots snapshots_path : ./snapshots snapshots_config : # "local" or "s3" - where to store snapshots snapshots_storage : local # s3_config: #   bucket: "" #   region: "" #   access_key: "" #   secret_key: "" # Where to store temporary files # If null, temporary snapshots are stored in: storage/snapshots_temp/ temp_path : null # If true - point payloads will not be stored in memory.

# It will be read from the disk every time it is requested.

# This setting saves RAM by (slightly) increasing the response time.

# Note: those payload values that are involved in filtering and are indexed - remain in RAM.

# # Default: true on_disk_payload : true # Maximum number of concurrent updates to shard replicas # If `null` - maximum concurrency is used. update_concurrency : null # Write-ahead-log related configuration wal : # Size of a single WAL segment wal_capacity_mb : 32 # Number of WAL segments to create ahead of actual data requirement wal_segments_ahead : 0 # Normal node - receives all updates and answers all queries node_type : "Normal" # Listener node - receives all updates, but does not answer search/read queries # Useful for setting up a dedicated backup node # node_type: "Listener" performance : # Number of parallel threads used for search operations. If 0 - auto selection. max_search_threads : 0 # CPU budget, how many CPUs (threads) to allocate for an optimization job.

# If 0 - auto selection, keep 1 or more CPUs unallocated depending on CPU size # If negative - subtract this number of CPUs from the available CPUs.

# If positive - use this exact number of CPUs. optimizer_cpu_budget : 0 # Prevent DDoS of too many concurrent updates in distributed mode.

# One external update usually triggers multiple internal updates, which breaks internal # timings. For example, the health check timing and consensus timing.

# If null - auto selection. update_rate_limit : null # Limit for number of incoming automatic shard transfers per collection on this node, does not affect user-requested transfers.

# The same value should be used on all nodes in a cluster.

# Default is to allow 1 transfer.

# If null - allow unlimited transfers.

#incoming_shard_transfers_limit: 1 # Limit for number of outgoing automatic shard transfers per collection on this node, does not affect user-requested transfers.

# The same value should be used on all nodes in a cluster.

# Default is to allow 1 transfer.

# If null - allow unlimited transfers.

#outgoing_shard_transfers_limit: 1 # Enable async scorer which uses io_uring when rescoring.

# Only supported on Linux, must be enabled in your kernel.

# See: <https://qdrant.tech/articles/io_uring/#and-what-about-qdrant> #async_scorer: false optimizers : # The minimal fraction of deleted vectors in a segment, required to perform segment optimization deleted_threshold : 0.2 # The minimal number of vectors in a segment, required to perform segment optimization vacuum_min_vector_number : 1000 # Target amount of segments optimizer will try to keep.

# Real amount of segments may vary depending on multiple parameters: #  - Amount of stored points #  - Current write RPS # # It is recommended to select default number of segments as a factor of the number of search threads, # so that each segment would be handled evenly by one of the threads.

# If `default_segment_number = 0`, will be automatically selected by the number of available CPUs default_segment_number : 0 # Do not create segments larger this size (in KiloBytes).

# Large segments might require disproportionately long indexation times, # therefore it makes sense to limit the size of segments.

# # If indexation speed have more priority for your - make this parameter lower.

# If search speed is more important - make this parameter higher.

# Note: 1Kb = 1 vector of size 256 # If not set, will be automatically selected considering the number of available CPUs. max_segment_size_kb : null # Maximum size (in KiloBytes) of vectors allowed for plain index.

# Default value based on experiments and observations.

# Note: 1Kb = 1 vector of size 256 # To explicitly disable vector indexing, set to `0`.

# If not set, the default value will be used. indexing_threshold_kb : 10000 # Interval between forced flushes. flush_interval_sec : 5 # Max number of threads (jobs) for running optimizations per shard.

# Note: each optimization job will also use `max_indexing_threads` threads by itself for index building.

# If null - have no limit and choose dynamically to saturate CPU.

# If 0 - no optimization threads, optimizations will be disabled. max_optimization_threads : null # This section has the same options as 'optimizers' above. All values specified here will overwrite the collections # optimizers configs regardless of the config above and the options specified at collection creation.

#optimizers_overwrite: #  deleted_threshold: 0.2 #  vacuum_min_vector_number: 1000 #  default_segment_number: 0 #  max_segment_size_kb: null #  indexing_threshold_kb: 10000 #  flush_interval_sec: 5 #  max_optimization_threads: null # Default parameters of HNSW Index. Could be overridden for each collection or named vector individually hnsw_index : # Number of edges per node in the index graph. Larger the value - more accurate the search, more space required. m : 16 # Number of neighbours to consider during the index building. Larger the value - more accurate the search, more time required to build index. ef_construct : 100 # Minimal size threshold (in KiloBytes) below which full-scan is preferred over HNSW search.

# This measures the total size of vectors being queried against.

# When the maximum estimated amount of points that a condition satisfies is smaller than # `full_scan_threshold_kb`, the query planner will use full-scan search instead of HNSW index # traversal for better performance.

# Note: 1Kb = 1 vector of size 256 full_scan_threshold_kb : 10000 # Number of parallel threads used for background index building.

# If 0 - automatically select.

# Best to keep between 8 and 16 to prevent likelihood of building broken/inefficient HNSW graphs.

# On small CPUs, less threads are used. max_indexing_threads : 0 # Store HNSW index on disk. If set to false, index will be stored in RAM. Default: false on_disk : false # Custom M param for hnsw graph built for payload index. If not set, default M will be used. payload_m : null # Default shard transfer method to use if none is defined.

# If null - don't have a shard transfer preference, choose automatically.

# If stream_records, snapshot or wal_delta - prefer this specific method.

# More info: https://qdrant.tech/documentation/guides/distributed_deployment/#shard-transfer-method shard_transfer_method : null # Default parameters for collections collection : # Number of replicas of each shard that network tries to maintain replication_factor : 1 # How many replicas should apply the operation for us to consider it successful write_consistency_factor : 1 # Default parameters for vectors. vectors : # Whether vectors should be stored in memory or on disk. on_disk : null # shard_number_per_node: 1 # Default quantization configuration.

# More info: https://qdrant.tech/documentation/guides/quantization quantization : null # Default strict mode parameters for newly created collections.

#strict_mode: # Whether strict mode is enabled for a collection or not.

#enabled: false # Max allowed `limit` parameter for all APIs that don't have their own max limit.

#max_query_limit: null # Max allowed `timeout` parameter.

#max_timeout: null # Allow usage of unindexed fields in retrieval based (eg. search) filters.

#unindexed_filtering_retrieve: null # Allow usage of unindexed fields in filtered updates (eg. delete by payload).

#unindexed_filtering_update: null # Max HNSW value allowed in search parameters.

#search_max_hnsw_ef: null # Whether exact search is allowed or not.

#search_allow_exact: null # Max oversampling value allowed in search.

#search_max_oversampling: null # Maximum number of collections allowed to be created # If null - no limit. max_collections : null service : # Maximum size of POST data in a single request in megabytes max_request_size_mb : 32 # Number of parallel workers used for serving the api. If 0 - equal to the number of available cores.

# If missing - Same as storage.max_search_threads max_workers : 0 # Host to bind the service on host : 0.0.0.0 # HTTP(S) port to bind the service on http_port : 6333 # gRPC port to bind the service on.

# If `null` - gRPC is disabled. Default: null # Comment to disable gRPC: grpc_port : 6334 # Enable CORS headers in REST API.

# If enabled, browsers would be allowed to query REST endpoints regardless of query origin.

# More info: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS # Default: true enable_cors : true # Enable HTTPS for the REST and gRPC API enable_tls : false # Check user HTTPS client certificate against CA file specified in tls config verify_https_client_certificate : false # Set an api-key.

# If set, all requests must include a header with the api-key.

# example header: `api-key: <API-KEY>` # # If you enable this you should also enable TLS.

# (Either above or via an external service like nginx.) # Sending an api-key over an unencrypted channel is insecure.

# # Uncomment to enable.

# api_key: your_secret_api_key_here # Set an api-key for read-only operations.

# If set, all requests must include a header with the api-key.

# example header: `api-key: <API-KEY>` # # If you enable this you should also enable TLS.

# (Either above or via an external service like nginx.) # Sending an api-key over an unencrypted channel is insecure.

# # Uncomment to enable.

# read_only_api_key: your_secret_read_only_api_key_here # Uncomment to enable JWT Role Based Access Control (RBAC).

# If enabled, you can generate JWT tokens with fine-grained rules for access control.

# Use generated token instead of API key.

# # jwt_rbac: true # Hardware reporting adds information to the API responses with a # hint on how many resources were used to execute the request.

# # Warning: experimental, this feature is still under development and is not supported yet.

# # Uncomment to enable.

# hardware_reporting: true # # Uncomment to enable.

# Prefix for the names of metrics in the /metrics API.

# metrics_prefix: qdrant_ cluster : # Use `enabled: true` to run Qdrant in distributed deployment mode enabled : false # Configuration of the inter-cluster communication p2p : # Port for internal communication between peers port : 6335 # Use TLS for communication between peers enable_tls : false # Configuration related to distributed consensus algorithm consensus : # How frequently peers should ping each other.

# Setting this parameter to lower value will allow consensus # to detect disconnected nodes earlier, but too frequent # tick period may create significant network and CPU overhead.

# We encourage you NOT to change this parameter unless you know what you are doing. tick_period_ms : 100 # Compact consensus operations once we have this amount of applied # operations. Allows peers to join quickly with a consensus snapshot without # replaying a huge amount of operations.

# If 0 - disable compaction compact_wal_entries : 128 # Set to true to prevent service from sending usage statistics to the developers.

# Read more: https://qdrant.tech/documentation/guides/telemetry telemetry_disabled : false # TLS configuration.

# Required if either service.enable_tls or cluster.p2p.enable_tls is true. tls : # Server certificate chain file cert : ./tls/cert.pem # Server private key file key : ./tls/key.pem # Certificate authority certificate file.

# This certificate will be used to validate the certificates # presented by other nodes during inter-cluster communication.

# # If verify_https_client_certificate is true, it will verify # HTTPS client certificate # # Required if cluster.p2p.enable_tls is true. ca_cert : ./tls/cacert.pem # TTL in seconds to reload certificate from disk, useful for certificate rotations.

# Only works for HTTPS endpoints. Does not support gRPC (and intra-cluster communication).

# If `null` - TTL is disabled. cert_ttl : 3600
================================================================================
PAGE 29/39
================================================================================
Title: Security
URL: https://qdrant.tech/documentation/guides/security/
--------------------------------------------------------------------------------

Security Qdrant supports various security features to help you secure your instance. Most of these must to be explicitly configured to make your instance production ready. Please read the following section carefully.

Secure your instance By default, all self-deployed Qdrant instances are not secure. They are open to all network interfaces and do not have any kind of authentication configured. They may be open to everybody on the internet without any restrictions. You must therefore take security measures to make your instance production-ready.

Please read through this section carefully for instructions on how to secure your instance.

Instances deployed via Qdrant Cloud are always secure by default. Refer to Authentication and Client IP Restrictions .

To properly secure your own instance, we strongly recommend taking the following steps: Authentication : set up an API key to prevent unauthorized access.

The most important step to prevent unauthenticated actors from accessing your data.

Network Bind : bind to a specific network interface or IP address.

When developing locally, bind to 127.0.0.1 to prevent all external access.

When deploying to production, bind to a private network interface or IP.

TLS : enable encrypted traffic everywhere using TLS.

Authentication Available as of v1.2.0 Qdrant supports a simple form of client authentication using a static API key.

This can be used to secure your instance.

To enable API key based authentication in your own Qdrant instance you must specify a key in the configuration: service : # Set an api-key.

# If set, all requests must include a header with the api-key.

# example header: `api-key: <API-KEY>` # # If you enable this you should also enable TLS.

# (Either above or via an external service like nginx.) # Sending an api-key over an unencrypted channel is insecure. api_key : your_secret_api_key_here Or alternatively, you can use the environment variable: docker run -p 6333:6333 \ -e QDRANT__SERVICE__API_KEY = your_secret_api_key_here \ qdrant/qdrant For using API key based authentication in Qdrant Cloud see the cloud Authentication section.

The API key then needs to be present in all REST or gRPC requests to your instance.

All official Qdrant clients for Python, Go, Rust, .NET and Java support the API key parameter. curl \ -X GET https://localhost:6333 \ --header 'api-key: your_secret_api_key_here' from qdrant_client import QdrantClient client = QdrantClient ( url = "https://localhost:6333" , api_key = "your_secret_api_key_here" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ url : "http://localhost" , port : 6333 , apiKey : "your_secret_api_key_here" , }); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "https://xyz-example.eu-central.aws.cloud.qdrant.io:6334" ) . api_key ( "<paste-your-api-key-here>" ) . build () ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.eu-central.aws.cloud.qdrant.io" , 6334 , true ) . withApiKey ( "<paste-your-api-key-here>" ) . build ()); using Qdrant.Client ; var client = new QdrantClient ( host : "xyz-example.eu-central.aws.cloud.qdrant.io" , https : true , apiKey : "<paste-your-api-key-here>" ); import "github.com/qdrant/go-client/qdrant" client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.eu-central.aws.cloud.qdrant.io" , Port : 6334 , APIKey : "<paste-your-api-key-here>" , UseTLS : true , }) Read-only API key Available as of v1.7.0 In addition to the regular API key, Qdrant also supports a read-only API key.

This key can be used to access read-only operations on the instance. service : read_only_api_key : your_secret_read_only_api_key_here Or with the environment variable: export QDRANT__SERVICE__READ_ONLY_API_KEY = your_secret_read_only_api_key_here Both API keys can be used simultaneously.

Granular access control with JWT Available as of v1.9.0 For more complex cases, Qdrant supports granular access control with JSON Web Tokens (JWT) .

This allows you to create tokens which restrict access to data stored in your cluster, and build Role-based access control (RBAC) on top of that.

In this way, you can define permissions for users and restrict access to sensitive endpoints.

To enable JWT-based authentication in your own Qdrant instance you need to specify the api-key and enable the jwt_rbac feature in the configuration: service : api_key : you_secret_api_key_here jwt_rbac : true Or with the environment variables: export QDRANT__SERVICE__API_KEY = your_secret_api_key_here export QDRANT__SERVICE__JWT_RBAC = true The api_key you set in the configuration will be used to encode and decode the JWTs, so ‚Äìneedless to say‚Äì keep it secure. If your api_key changes, all existing tokens will be invalid.

To use JWT-based authentication, you need to provide it as a bearer token in the Authorization header, or as an key in the Api-Key header of your requests.

Authorization: Bearer <JWT> // or Api-Key: <JWT> from qdrant_client import QdrantClient qdrant_client = QdrantClient ( "xyz-example.eu-central.aws.cloud.qdrant.io" , api_key = "<JWT>" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ host : "xyz-example.eu-central.aws.cloud.qdrant.io" , apiKey : "<JWT>" , }); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "https://xyz-example.eu-central.aws.cloud.qdrant.io:6334" ) . api_key ( "<JWT>" ) . build () ? ; import io.qdrant.client.QdrantClient ; import io.qdrant.client.QdrantGrpcClient ;

QdrantClient client = new QdrantClient ( QdrantGrpcClient . newBuilder ( "xyz-example.eu-central.aws.cloud.qdrant.io" , 6334 , true ) . withApiKey ( "<JWT>" ) . build ()); using Qdrant.Client ; var client = new QdrantClient ( host : "xyz-example.eu-central.aws.cloud.qdrant.io" , https : true , apiKey : "<JWT>" ); import "github.com/qdrant/go-client/qdrant" client , err := qdrant .

NewClient ( & qdrant .

Config { Host : "xyz-example.eu-central.aws.cloud.qdrant.io" , Port : 6334 , APIKey : "<JWT>" , UseTLS : true , }) Generating JSON Web Tokens Due to the nature of JWT, anyone who knows the api_key can generate tokens by using any of the existing libraries and tools, it is not necessary for them to have access to the Qdrant instance to generate them.

For convenience, we have added a JWT generation tool the Qdrant Web UI under the üîë tab, if you‚Äôre using the default url, it will be at http://localhost:6333/dashboard#/jwt .

JWT Header - Qdrant uses the HS256 algorithm to decode the tokens.

{ "alg" : "HS256" , "typ" : "JWT" } JWT Payload - You can include any combination of the parameters available in the payload. Keep reading for more info on each one.

{ "exp" : 1640995200 , // Expiration time "value_exists" : ... , // Validate this token by looking for a point with a payload value "access" : "r" , // Define the access level.

} Signing the token - To confirm that the generated token is valid, it needs to be signed with the api_key you have set in the configuration.

That would mean, that someone who knows the api_key gives the authorization for the new token to be used in the Qdrant instance.

Qdrant can validate the signature, because it knows the api_key and can decode the token.

The process of token generation can be done on the client side offline, and doesn‚Äôt require any communication with the Qdrant instance.

Here is an example of libraries that can be used to generate JWT tokens: Python: PyJWT JavaScript: jsonwebtoken Rust: jsonwebtoken CLI: jwt-cli Here is an example using jwt-cli : jwt encode --payload '{ "access": "r", "exp": 1766055305 }' --secret 'your-api-key' JWT Configuration These are the available options, or claims in the JWT lingo. You can use them in the JWT payload to define its functionality. exp - The expiration time of the token. This is a Unix timestamp in seconds. The token will be invalid after this time. The check for this claim includes a 30-second leeway to account for clock skew.

{ "exp" : 1640995200 , // Expiration time } value_exists - This is a claim that can be used to validate the token against the data stored in a collection. Structure of this claim is as follows: { "value_exists" : { "collection" : "my_validation_collection" , "matches" : [ { "key" : "my_key" , "value" : "value_that_must_exist" } ], }, } If this claim is present, Qdrant will check if there is a point in the collection with the specified key-values. If it does, the token is valid.

This claim is especially useful if you want to have an ability to revoke tokens without changing the api_key .

Consider a case where you have a collection of users, and you want to revoke access to a specific user.

{ "value_exists" : { "collection" : "users" , "matches" : [ { "key" : "user_id" , "value" : "andrey" }, { "key" : "role" , "value" : "manager" } ], }, } You can create a token with this claim, and when you want to revoke access, you can change the role of the user to something else, and the token will be invalid. access - This claim defines the access level of the token. If this claim is present, Qdrant will check if the token has the required access level to perform the operation. If this claim is not present, manage access is assumed.

It can provide global access with r for read-only, or m for manage. For example: { "access" : "r" } It can also be specific to one or more collections. The access level for each collection is r for read-only, or rw for read-write, like this: { "access" : [ { "collection" : "my_collection" , "access" : "rw" } ] } Table of access Check out this table to see which actions are allowed or denied based on the access level.

This is also applicable to using api keys instead of tokens. In that case, api_key maps to manage , while read_only_api_key maps to read-only .

Symbols: ‚úÖ Allowed | ‚ùå Denied | üü° Allowed, but filtered Action manage read-only collection read-write collection read-only list collections ‚úÖ ‚úÖ üü° üü° get collection info ‚úÖ ‚úÖ ‚úÖ ‚úÖ create collection ‚úÖ ‚ùå ‚ùå ‚ùå delete collection ‚úÖ ‚ùå ‚ùå ‚ùå update collection params ‚úÖ ‚ùå ‚ùå ‚ùå get collection cluster info ‚úÖ ‚úÖ ‚úÖ ‚úÖ collection exists ‚úÖ ‚úÖ ‚úÖ ‚úÖ update collection cluster setup ‚úÖ ‚ùå ‚ùå ‚ùå update aliases ‚úÖ ‚ùå ‚ùå ‚ùå list collection aliases ‚úÖ ‚úÖ üü° üü° list aliases ‚úÖ ‚úÖ üü° üü° create shard key ‚úÖ ‚ùå ‚ùå ‚ùå delete shard key ‚úÖ ‚ùå ‚ùå ‚ùå create payload index ‚úÖ ‚ùå ‚úÖ ‚ùå delete payload index ‚úÖ ‚ùå ‚úÖ ‚ùå list collection snapshots ‚úÖ ‚úÖ ‚úÖ ‚úÖ create collection snapshot ‚úÖ ‚ùå ‚úÖ ‚ùå delete collection snapshot ‚úÖ ‚ùå ‚úÖ ‚ùå download collection snapshot ‚úÖ ‚úÖ ‚úÖ ‚úÖ upload collection snapshot ‚úÖ ‚ùå ‚ùå ‚ùå recover collection snapshot ‚úÖ ‚ùå ‚ùå ‚ùå list shard snapshots ‚úÖ ‚úÖ ‚úÖ ‚úÖ create shard snapshot ‚úÖ ‚ùå ‚úÖ ‚ùå delete shard snapshot ‚úÖ ‚ùå ‚úÖ ‚ùå download shard snapshot ‚úÖ ‚úÖ ‚úÖ ‚úÖ upload shard snapshot ‚úÖ ‚ùå ‚ùå ‚ùå recover shard snapshot ‚úÖ ‚ùå ‚ùå ‚ùå list full snapshots ‚úÖ ‚úÖ ‚ùå ‚ùå create full snapshot ‚úÖ ‚ùå ‚ùå ‚ùå delete full snapshot ‚úÖ ‚ùå ‚ùå ‚ùå download full snapshot ‚úÖ ‚úÖ ‚ùå ‚ùå get cluster info ‚úÖ ‚úÖ ‚ùå ‚ùå recover raft state ‚úÖ ‚ùå ‚ùå ‚ùå delete peer ‚úÖ ‚ùå ‚ùå ‚ùå get point ‚úÖ ‚úÖ ‚úÖ ‚úÖ get points ‚úÖ ‚úÖ ‚úÖ ‚úÖ upsert points ‚úÖ ‚ùå ‚úÖ ‚ùå update points batch ‚úÖ ‚ùå ‚úÖ ‚ùå delete points ‚úÖ ‚ùå ‚úÖ ‚ùå update vectors ‚úÖ ‚ùå ‚úÖ ‚ùå delete vectors ‚úÖ ‚ùå ‚úÖ ‚ùå set payload ‚úÖ ‚ùå ‚úÖ ‚ùå overwrite payload ‚úÖ ‚ùå ‚úÖ ‚ùå delete payload ‚úÖ ‚ùå ‚úÖ ‚ùå clear payload ‚úÖ ‚ùå ‚úÖ ‚ùå scroll points ‚úÖ ‚úÖ ‚úÖ ‚úÖ query points ‚úÖ ‚úÖ ‚úÖ ‚úÖ search points ‚úÖ ‚úÖ ‚úÖ ‚úÖ search groups ‚úÖ ‚úÖ ‚úÖ ‚úÖ recommend points ‚úÖ ‚úÖ ‚úÖ ‚úÖ recommend groups ‚úÖ ‚úÖ ‚úÖ ‚úÖ discover points ‚úÖ ‚úÖ ‚úÖ ‚úÖ count points ‚úÖ ‚úÖ ‚úÖ ‚úÖ version ‚úÖ ‚úÖ ‚úÖ ‚úÖ readyz, healthz, livez ‚úÖ ‚úÖ ‚úÖ ‚úÖ telemetry ‚úÖ ‚úÖ ‚ùå ‚ùå metrics ‚úÖ ‚úÖ ‚ùå ‚ùå Network bind By default, a custom Qdrant deployment binds to all network interfaces. Your instance may be open to everybody on the internet. On a local development machine you likely have a firewall in place to prevent public access, but that may not be the case on a public VPS or dedicated server.

It is highly recommended to bind to a specific interface or IP address to prevent unwanted access: when developing locally, bind to 127.0.0.1 so no external access is possible or, when deploying to production, bind to a private network interface or IP When using Docker, you may use the publish flag to bind to a specific interface.

For example: docker run -p 127.0.0.1:6333:6333 qdrant/qdrant If using another type of deployment you may configure the bind address in Qdrant itself. Either set service.host: 127.0.0.1 in the configuration, or use an environment variable like this: QDRANT__SERVICE__HOST = 127.0.0.1 ./qdrant Managed Qdrant Cloud deployments are always secure by default. They are publicly accessible and bound to the endpoint that is assigned to the cluster. You may configure authentication with API keys , and restrict access to specific IP addresses through Client IP Restrictions .

Hybrid Cloud and Private Cloud deployments have their own kind of configuration.

TLS Available as of v1.2.0 TLS for encrypted connections can be enabled on your Qdrant instance to secure connections.

First make sure you have a certificate and private key for TLS, usually in .pem format. On your local machine you may use mkcert to generate a self signed certificate.

To enable TLS, set the following properties in the Qdrant configuration with the correct paths and restart: service : # Enable HTTPS for the REST and gRPC API enable_tls : true # TLS configuration.

# Required if either service.enable_tls or cluster.p2p.enable_tls is true. tls : # Server certificate chain file cert : ./tls/cert.pem # Server private key file key : ./tls/key.pem For internal communication when running cluster mode, TLS can be enabled with: cluster : # Configuration of the inter-cluster communication p2p : # Use TLS for communication between peers enable_tls : true With TLS enabled, you must start using HTTPS connections. For example: curl -X GET https://localhost:6333 from qdrant_client import QdrantClient client = QdrantClient ( url = "https://localhost:6333" , ) import { QdrantClient } from "@qdrant/js-client-rest" ; const client = new QdrantClient ({ url : "https://localhost" , port : 6333 }); use qdrant_client :: Qdrant ; let client = Qdrant :: from_url ( "http://localhost:6334" ). build () ? ;

Certificate rotation is enabled with a default refresh time of one hour. This reloads certificate files every hour while Qdrant is running. This way changed certificates are picked up when they get updated externally. The refresh time can be tuned by changing the tls.cert_ttl setting. You can leave this on, even if you don‚Äôt plan to update your certificates. Currently this is only supported for the REST API.

Optionally, you can enable client certificate validation on the server against a local certificate authority. Set the following properties and restart: service : # Check user HTTPS client certificate against CA file specified in tls config verify_https_client_certificate : false # TLS configuration.

# Required if either service.enable_tls or cluster.p2p.enable_tls is true. tls : # Certificate authority certificate file.

# This certificate will be used to validate the certificates # presented by other nodes during inter-cluster communication.

# # If verify_https_client_certificate is true, it will verify # HTTPS client certificate # # Required if cluster.p2p.enable_tls is true. ca_cert : ./tls/cacert.pem Hardening We recommend reducing the amount of permissions granted to Qdrant containers so that you can reduce the risk of exploitation. Here are some ways to reduce the permissions of a Qdrant container: Run Qdrant as a non-root user. This can help mitigate the risk of future container breakout vulnerabilities. Qdrant does not need the privileges of the root user for any purpose.

You can use the image qdrant/qdrant:<version>-unprivileged instead of the default Qdrant image.

You can use the flag --user=1000:2000 when running docker run .

You can set user: 1000 when using Docker Compose.

You can set runAsUser: 1000 when running in Kubernetes (our Helm chart does this by default).

Run Qdrant with a read-only root filesystem. This can help mitigate vulnerabilities that require the ability to modify system files, which is a permission Qdrant does not need. As long as the container uses mounted volumes for storage ( /qdrant/storage and /qdrant/snapshots by default), Qdrant can continue to operate while being prevented from writing data outside of those volumes.

You can use the flag --read-only when running docker run .

You can set read_only: true when using Docker Compose.

You can set readOnlyRootFilesystem: true when running in Kubernetes (our Helm chart does this by default).

Block Qdrant‚Äôs external network access. This can help mitigate server side request forgery attacks , like via the snapshot recovery API . Single-node Qdrant clusters do not require any outbound network access. Multi-node Qdrant clusters only need the ability to connect to other Qdrant nodes via TCP ports 6333, 6334, and 6335.

You can use docker network create --internal <name> and use that network when running docker run --network <name> .

You can create an internal network when using Docker Compose.

You can create a NetworkPolicy when using Kubernetes. Note that multi-node Qdrant clusters will also need access to cluster DNS in Kubernetes .

There are other techniques for reducing the permissions such as dropping Linux capabilities depending on your deployment method, but the methods mentioned above are the most important.

================================================================================
PAGE 30/39
================================================================================
Title: Usage statistics
URL: https://qdrant.tech/documentation/guides/usage-statistics/
--------------------------------------------------------------------------------

Usage statistics The Qdrant open-source container image collects anonymized usage statistics from users in order to improve the engine by default. You can deactivate at any time, and any data that has already been collected can be deleted on request .

Deactivating this will not affect your ability to monitor the Qdrant database yourself by accessing the /metrics or /telemetry endpoints of your database. It will just stop sending independend, anonymized usage statistics to the Qdrant team.

Why do we collect usage statistics?

We want to make Qdrant fast and reliable. To do this, we need to understand how it performs in real-world scenarios.

We do a lot of benchmarking internally, but it is impossible to cover all possible use cases, hardware, and configurations.

In order to identify bottlenecks and improve Qdrant, we need to collect information about how it is used.

Additionally, Qdrant uses a bunch of internal heuristics to optimize the performance.

To better set up parameters for these heuristics, we need to collect timings and counters of various pieces of code.

With this information, we can make Qdrant faster for everyone.

What information is collected?

There are 3 types of information that we collect: System information - general information about the system, such as CPU, RAM, and disk type. As well as the configuration of the Qdrant instance.

Performance - information about timings and counters of various pieces of code.

Critical error reports - information about critical errors, such as backtraces, that occurred in Qdrant. This information would allow to identify problems nobody yet reported to us.

We never collect the following information: User‚Äôs IP address Any data that can be used to identify the user or the user‚Äôs organization Any data, stored in the collections Any names of the collections Any URLs How do we anonymize data?

We understand that some users may be concerned about the privacy of their data.

That is why we make an extra effort to ensure your privacy.

There are several different techniques that we use to anonymize the data: We use a random UUID to identify instances. This UUID is generated on each startup and is not stored anywhere. There are no other ways to distinguish between different instances.

We round all big numbers, so that the last digits are always 0. For example, if the number is 123456789, we will store 123456000.

We replace all names with irreversibly hashed values. So no collection or field names will leak into the telemetry.

All urls are hashed as well.

You can see exact version of anomymized collected data by accessing the telemetry API with anonymize=true parameter.

For example, http://localhost:6333/telemetry?details_level=6&anonymize=true Deactivate usage statistics You can deactivate usage statistics by: setting the QDRANT__TELEMETRY_DISABLED environment variable to true setting the config option telemetry_disabled to true in the config/production.yaml or config/config.yaml files using cli option --disable-telemetry Any of these options will prevent Qdrant from sending any usage statistics data.

If you decide to deactivate usage statistics, we kindly ask you to share your feedback with us in the Discord community or GitHub discussions Request information deletion We provide an email address so that users can request the complete removal of their data from all of our tools.

To do so, send an email to privacy@qdrant.com containing the unique identifier generated for your Qdrant installation.

You can find this identifier in the telemetry API response ( "id" field), or in the logs of your Qdrant instance.

Any questions regarding the management of the data we collect can also be sent to this email address.

================================================================================
PAGE 31/39
================================================================================
Title: Solving common errors
URL: https://qdrant.tech/documentation/guides/common-errors/
--------------------------------------------------------------------------------

Solving common errors Too many files open (OS error 24) Each collection segment needs some files to be open. At some point you may encounter the following errors in your server log: Error: Too many files open (OS error 24) In such a case you may need to increase the limit of the open files. It might be done, for example, while you launch the Docker container: docker run --ulimit nofile = 10000:10000 qdrant/qdrant:latest The command above will set both soft and hard limits to 10000 .

If you are not using Docker, the following command will change the limit for the current user session: ulimit -n 10000 Please note, the command should be executed before you run Qdrant server.

Incompatible file system Qdrant have a set of requirements for persistent file storage.

The most important requirement is that file system must be POSIX-compatible .

Starting from v1.15.0 Qdrant performs runtime check of file system compatibility on start.

If it detects an unknown file system, you can see a warning like this: WARN qdrant: There is a potential issue with the filesystem for storage path ./storage. Details: HFS/HFS+ filesystem support is untested If runtime check fails, you might see an error message: ERROR qdrant: Filesystem check failed for storage path ./storage.

Details: FUSE filesystems may cause data corruption due to caching issues If an error like this is reported, it is NOT safe to continue working with current configuration and you‚Äôre at risk of losing your data.

Most common errors you might see, if you continue using Qdrant with incompatible file system: ERROR Panic occurred in file /qdrant/lib/gridstore/src/gridstore.rs at line 53: called `Result::unwrap()` on an `Err` value: OutputTooSmall { expected: 4, actual: 0 } or ERROR Service internal error: task XXX panicked with message "called `Result::unwrap()` on an `Err` value: OutputTooSmall { expected: 4, actual: 0 }" It might be also possible that vector data will be lost (set to all zeros) after service restart.

How to avoid Incompatible file system?

Most common used configuration of incompatible file system is usage of WSL-baced Docker containers in Windows.

When you mount Windows folder into Qdrant docker container, the Windows hyper visor creates a shared mount, which is not fully POSIX-compatible.

Prefer to use docker volumes instead of bind mount: # Create named volume docker volume create qdrant-storage # Use named volume with qdrant container docker run --rm -it \ -p 6333:6333 -p 6334:6334 \ -v qdrant-storage:/qdrant/storage qdrant/qdrant:v1.15.3 The above keeps the volume inside the Linux container, preventing issues with a mount shared with Windows.

Can‚Äôt open Collections meta Wal When starting a Qdrant instance as part of a distributed deployment, you may come across an error message similar to this: Can ' t open Collections meta Wal: Os { code: 11, kind: WouldBlock, message: "Resource temporarily unavailable" } It means that Qdrant cannot start because a collection cannot be loaded. Its associated WAL files are currently unavailable, likely because the same files are already being used by another Qdrant instance.

Each node must have their own separate storage directory, volume or mount.

The formed cluster will take care of sharing all data with each node, putting it all in the correct places for you. If using Kubernetes, each node must have their own volume. If using Docker, each node must have their own storage mount or volume. If using Qdrant directly, each node must have their own storage directory.

Using python gRPC client with multiprocessing When using the Python gRPC client with multiprocessing , you may encounter an error like this: <_InactiveRpcError of RPC that terminated with: status = StatusCode.UNAVAILABLE details = "sendmsg: Socket operation on non-socket (88)" debug_error_string = "UNKNOWN:Error received from peer  {grpc_message:"sendmsg: Socket operation on non-socket (88)", grpc_status:14, created_time:"....."}" This error happens, because multiprocessing creates copies of gRPC channels, which share the same socket. When the parent process closes the channel, it closes the socket, and the child processes try to use a closed socket.

To prevent this error, you can use the forkserver or spawn start methods for multiprocessing . import multiprocessing multiprocessing . set_start_method ( "forkserver" ) # or "spawn" Alternatively, you can switch to REST API, async client, or use built-in parallelization in the Python client - functions like qdrant.upload_points(...)
================================================================================
PAGE 32/39
================================================================================
Title: What is FastEmbed?
URL: https://qdrant.tech/documentation/fastembed/
--------------------------------------------------------------------------------

What is FastEmbed?

FastEmbed is a lightweight Python library built for embedding generation. It supports popular embedding models and offers a user-friendly experience for embedding data into vector space.

By using FastEmbed, you can ensure that your embedding generation process is not only fast and efficient but also highly accurate, meeting the needs of various machine learning and natural language processing applications.

FastEmbed easily integrates with Qdrant for a variety of multimodal search purposes.

Using FastEmbed Type Guide What you‚Äôll learn Beginner Generate Text Embeddings Install FastEmbed and generate dense text embeddings Dense Embeddings + Qdrant Generate and index dense embeddings for semantic similarity search Advanced miniCOIL Sparse Embeddings + Qdrant Use Qdrant‚Äôs sparse neural retriever for exact text search SPLADE Sparse Embeddings + Qdrant Generate sparse neural embeddings for exact text search ColBERT Multivector Embeddings + Qdrant Generate and index multi-vector representations; ideal for rescoring, or small-scale retrieval Reranking with FastEmbed Re-rank top-K results using FastEmbed cross-encoders Postprocessing Apply postprocessing techniques to embeddings after generation Why is FastEmbed useful?

Light: Unlike other inference frameworks, such as PyTorch, FastEmbed requires very little external dependencies. Because it uses the ONNX runtime, it is perfect for serverless environments like AWS Lambda.

Fast: By using ONNX, FastEmbed ensures high-performance inference across various hardware platforms.

Accurate: FastEmbed aims for better accuracy and recall than models like OpenAI‚Äôs Ada-002 . It always uses model which demonstrate strong results on the MTEB leaderboard.

Support: FastEmbed supports a wide range of models, including multilingual ones, to meet diverse use case needs.

================================================================================
PAGE 33/39
================================================================================
Title: How to Generate Text Embedings with FastEmbed
URL: https://qdrant.tech/documentation/fastembed/fastembed-quickstart/
--------------------------------------------------------------------------------

How to Generate Text Embedings with FastEmbed Install FastEmbed pip install fastembed Just for demo purposes, you will use Lists and NumPy to work with sample data. from typing import List import numpy as np Load default model In this example, you will use the default text embedding model, BAAI/bge-small-en-v1.5 . from fastembed import TextEmbedding Add sample data Now, add two sample documents. Your documents must be in a list, and each document must be a string documents : List [ str ] = [ "FastEmbed is lighter than Transformers & Sentence-Transformers." , "FastEmbed is supported by and maintained by Qdrant." , ] Download and initialize the model. Print a message to verify the process. embedding_model = TextEmbedding () print ( "The model BAAI/bge-small-en-v1.5 is ready to use." ) Embed data Generate embeddings for both documents. embeddings_generator = embedding_model . embed ( documents ) embeddings_list = list ( embeddings_generator ) len ( embeddings_list [ 0 ]) Here is the sample document list. The default model creates vectors with 384 dimensions.

Document: This is built to be faster and lighter than other embedding libraries e.g. Transformers, Sentence-Transformers, etc.

Vector of type: <class 'numpy.ndarray' > with shape: ( 384, ) Document: fastembed is supported by and maintained by Qdrant.

Vector of type: <class 'numpy.ndarray' > with shape: ( 384, ) Visualize embeddings print ( "Embeddings: \n " , embeddings_list ) The embeddings don‚Äôt look too interesting, but here is a visual.

Embeddings: [[ -0.11154681  0.00976555  0.00524559  0.01951888 -0.01934952  0.02943449 -0.10519084 -0.00890122  0.01831438  0.01486796 -0.05642502  0.02561352 -0.00120165  0.00637456  0.02633459  0.0089221   0.05313658  0.03955453 -0.04400245 -0.02929407  0.04691846 -0.02515868  0.00778646 -0.05410657 ...

-0.00243012 -0.01820582  0.02938612  0.02108984 -0.02178085  0.02971899 -0.00790564  0.03561783  0.0652488  -0.04371546 -0.05550042  0.02651665 -0.01116153 -0.01682246 -0.05976734 -0.03143916  0.06522726  0.01801389 -0.02611006  0.01627177 -0.0368538   0.03968835  0.027597    0.03305927 ]]
================================================================================
PAGE 34/39
================================================================================
Title: Using FastEmbed with Qdrant for Vector Search
URL: https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/
--------------------------------------------------------------------------------

Using FastEmbed with Qdrant for Vector Search Install Qdrant Client and FastEmbed pip install "qdrant-client[fastembed]>=1.14.2" Initialize the client Qdrant Client has a simple in-memory mode that lets you try semantic search locally. from qdrant_client import QdrantClient , models client = QdrantClient ( ":memory:" ) # Qdrant is running from RAM.

Add data Now you can add two sample documents, their associated metadata, and a point id for each. docs = [ "Qdrant has a LangChain integration for chatbots." , "Qdrant has a LlamaIndex integration for agents." , ] metadata = [ { "source" : "langchain-docs" }, { "source" : "llamaindex-docs" }, ] ids = [ 42 , 2 ] Create a collection Qdrant stores vectors and associated metadata in collections.

Collection requires vector parameters to be set during creation.

In this tutorial, we‚Äôll be using BAAI/bge-small-en to compute embeddings. model_name = "BAAI/bge-small-en" client . create_collection ( collection_name = "test_collection" , vectors_config = models .

VectorParams ( size = client . get_embedding_size ( model_name ), distance = models .

Distance .

COSINE ), # size and distance are model dependent ) Upsert documents to the collection Qdrant client can do inference implicitly within its methods via FastEmbed integration.

It requires wrapping your data in models, like models.Document (or models.Image if you‚Äôre working with images) metadata_with_docs = [ { "document" : doc , "source" : meta [ "source" ]} for doc , meta in zip ( docs , metadata ) ] client . upload_collection ( collection_name = "test_collection" , vectors = [ models .

Document ( text = doc , model = model_name ) for doc in docs ], payload = metadata_with_docs , ids = ids , ) Run vector search Here, you will ask a dummy question that will allow you to retrieve a semantically relevant result. search_result = client . query_points ( collection_name = "test_collection" , query = models .

Document ( text = "Which integration is best for agents?" , model = model_name ) ) . points print ( search_result ) The semantic search engine will retrieve the most similar result in order of relevance. In this case, the second statement about LlamaIndex is more relevant.

[ ScoredPoint ( id = 2 , score = 0.87491801319731 , payload = { "document" : "Qdrant has a LlamaIndex integration for agents." , "source" : "llamaindex-docs" , }, ... ), ScoredPoint ( id = 42 , score = 0.8351846627714035 , payload = { "document" : "Qdrant has a LangChain integration for chatbots." , "source" : "langchain-docs" , }, ... ), ]
================================================================================
PAGE 35/39
================================================================================
Title: How to use miniCOIL, Qdrant‚Äôs Sparse Neural Retriever
URL: https://qdrant.tech/documentation/fastembed/fastembed-minicoil/
--------------------------------------------------------------------------------

How to use miniCOIL, Qdrant‚Äôs Sparse Neural Retriever miniCOIL is an open-sourced sparse neural retrieval model that acts as if a BM25-based retriever understood the contextual meaning of keywords and ranked results accordingly. miniCOIL scoring is based on the BM25 formula scaled by the semantic similarity between matched keywords in a query and a document.

$$ \text{miniCOIL}(D,Q) = \sum_{i=1}^{N} \text{IDF}(q_i) \cdot \text{Importance}^{q_i}_{D} \cdot {\color{YellowGreen}\text{Meaning}^{q_i \times d_j}} \text{, where keyword } d_j \in D \text{ equals } q_i $$ A detailed breakdown of the idea behind miniCOIL can be found in the ‚ÄúminiCOIL: on the road to Usable Sparse Neural Retreival‚Äù article or, in a recorded talk ‚ÄúminiCOIL: Sparse Neural Retrieval Done Right‚Äù .

This tutorial will demonstrate how miniCOIL-based sparse neural retrieval performs compared to BM25-based lexical retrieval.

When to use miniCOIL When exact keyword matches in the retrieved results are a requirement, and all matches should be ranked based on the contextual meaning of keywords.

If results should be similar by meaning but are expressed differently, with no overlapping keywords, you should use dense embeddings or combine them with miniCOIL in a hybrid search setting.

Setup Install qdrant-client integration with fastembed . pip install "qdrant-client[fastembed]" Then, initialize the Qdrant client. You could use for experiments a free cluster in Qdrant Cloud or run a local Qdrant instance via Docker .

We‚Äôll run our search on a list of book and article titles containing the keywords ‚Äú vector ‚Äù and ‚Äú search ‚Äù used in different contexts, to demonstrate how miniCOIL captures the meaning of these keywords as opposed to BM25.

A dataset documents = [ "Vector Graphics in Modern Web Design" , "The Art of Search and Self-Discovery" , "Efficient Vector Search Algorithms for Large Datasets" , "Searching the Soul: A Journey Through Mindfulness" , "Vector-Based Animations for User Interface Design" , "Search Engines: A Technical and Social Overview" , "The Rise of Vector Databases in AI Systems" , "Search Patterns in Human Behavior" , "Vector Illustrations: A Guide for Creatives" , "Search and Rescue: Technologies in Emergency Response" , "Vectors in Physics: From Arrows to Equations" , "Searching for Lost Time in the Digital Age" , "Vector Spaces and Linear Transformations" , "The Endless Search for Truth in Philosophy" , "3D Modeling with Vectors in Blender" , "Search Optimization Strategies for E-commerce" , "Vector Drawing Techniques with Open-Source Tools" , "In Search of Meaning: A Psychological Perspective" , "Advanced Vector Calculus for Engineers" , "Search Interfaces: UX Principles and Case Studies" , "The Use of Vector Fields in Meteorology" , "Search and Destroy: Cybersecurity in the 21st Century" , "From Bitmap to Vector: A Designer‚Äôs Guide" , "Search Engines and the Democratization of Knowledge" , "Vector Geometry in Game Development" , "The Human Search for Connection in a Digital World" , "AI-Powered Vector Search in Recommendation Systems" , "Searchable Archives: The History of Digital Retrieval" , "Vector Control Strategies in Public Health" , "The Search for Extraterrestrial Intelligence" ] Create Collection Let‚Äôs create a collection to store and index titles.

As miniCOIL was designed with Qdrant‚Äôs ability to calculate the keywords Inverse Document Frequency (IDF) in mind, we need to configure miniCOIL sparse vectors with IDF modifier . client . create_collection ( collection_name = " {minicoil_collection_name} " , sparse_vectors_config = { "minicoil" : models .

SparseVectorParams ( modifier = models .

Modifier .

IDF #Inverse Document Frequency ) } ) Analogously, we configure a collection with BM25-based sparse vectors client . create_collection ( collection_name = " {bm25_collection_name} " , sparse_vectors_config = { "bm25" : models .

SparseVectorParams ( modifier = models .

Modifier .

IDF ) } ) Convert to Sparse Vectors & Upload to Qdrant Next, we need to convert titles to miniCOIL sparse representations and upsert them into the configured collection.

Qdrant and FastEmbed integration allows for hiding the inference process under the hood.

That means: FastEmbed downloads the selected model from Hugging Face;

FastEmbed runs local inference under the hood;

Inferenced sparse representations are uploaded to Qdrant.

#Estimating the average length of the documents in the corpus avg_documents_length = sum ( len ( document . split ()) for document in documents ) / len ( documents ) client . upsert ( collection_name = " {minicoil_collection_name} " , points = [ models .

PointStruct ( id = i , payload = { "text" : documents [ i ] }, vector = { # Sparse miniCOIL vectors "minicoil" : models .

Document ( text = documents [ i ], model = "Qdrant/minicoil-v1" , options = { "avg_len" : avg_documents_length } #Average length of documents in the corpus # (a part of the BM25 formula on which miniCOIL is built) ) }, ) for i in range ( len ( documents )) ], ) Analogously, we convert & upsert BM25-based sparse vectors #Estimating the average length of the documents in the corpus avg_documents_length = sum ( len ( document . split ()) for document in documents ) / len ( documents ) client . upsert ( collection_name = " {bm25_collection_name} " , points = [ models .

PointStruct ( id = i , payload = { "text" : documents [ i ] }, vector = { # Sparse vector from BM25 "bm25" : models .

Document ( text = documents [ i ], model = "Qdrant/bm25" , options = { "avg_len" : avg_documents_length } #Average length of documents in the corpus # (a part of the BM25 formula) ) }, ) for i in range ( len ( documents )) ], ) Retrieve with miniCOIL Using query ‚ÄúVectors in Medicine‚Äù , we‚Äôll demo the difference between miniCOIL and BM25-based retrieval.

None of the indexed titles contain the keyword ‚Äúmedicine‚Äù , so it won‚Äôt contribute to the similarity score.

At the same time, the word ‚Äúvector‚Äù appears once in many titles, and its role is roughly equal in all of them from the perspective of the BM25-based retriever. miniCOIL, however, can capture the meaning of the keyword ‚Äúvector‚Äù in the context of ‚Äúmedicine‚Äù and match a document where ‚Äúvector‚Äù is used in a medicine-related context.

For BM25-based retrieval: query = "Vectors in Medicine" client . query_points ( collection_name = " {bm25_collection_name} " , query = models .

Document ( text = query , model = "Qdrant/bm25" ), using = "bm25" , limit = 1 , ) Result will be: QueryResponse ( points =[ ScoredPoint ( id = 18, version = 1, score = 0.8405092, payload ={ 'title' : 'Advanced Vector Calculus for Engineers' } , vector = None, shard_key = None, order_value = None ) ] ) While for miniCOIL-based retrieval: query = "Vectors in Medicine" client . query_points ( collection_name = " {minicoil_collection_name} " , query = models .

Document ( text = query , model = "Qdrant/minicoil-v1" ), using = "minicoil" , limit = 1 ) We will get: QueryResponse ( points =[ ScoredPoint ( id = 28, version = 1, score = 0.7005557, payload ={ 'title' : 'Vector Control Strategies in Public Health' } , vector = None, shard_key = None, order_value = None ) ] )
================================================================================
PAGE 36/39
================================================================================
Title: How to Generate Sparse Vectors with SPLADE
URL: https://qdrant.tech/documentation/fastembed/fastembed-splade/
--------------------------------------------------------------------------------

How to Generate Sparse Vectors with SPLADE SPLADE is a novel method for learning sparse text representation vectors, outperforming BM25 in tasks like information retrieval and document classification. Its main advantage is generating efficient and interpretable sparse vectors, making it effective for large-scale text data.

Setup First, install FastEmbed. pip install - q fastembed Next, import the required modules for sparse embeddings and Python‚Äôs typing module. from fastembed import SparseTextEmbedding , SparseEmbedding You may always check the list of all supported sparse embedding models.

SparseTextEmbedding . list_supported_models () This will return a list of models, each with its details such as model name, vocabulary size, description, and sources.

[ { 'model' : 'prithivida/Splade_PP_en_v1' , 'sources' : { 'hf' : 'Qdrant/Splade_PP_en_v1' , ...

}, 'model_file' : 'model.onnx' , 'description' : 'Independent Implementation of SPLADE++ Model for English.' , 'license' : 'apache-2.0' , 'size_in_GB' : 0.532 , 'vocab_size' : 30522 , ...

}, ... ] # part of the output was omitted Now, load the model. model_name = "prithivida/Splade_PP_en_v1" # This triggers the model download model = SparseTextEmbedding ( model_name = model_name ) Embed data You need to define a list of documents to be embedded. documents : list [ str ] = [ "Chandrayaan-3 is India's third lunar mission" , "It aimed to land a rover on the Moon's surface - joining the US, China and Russia" , "The mission is a follow-up to Chandrayaan-2, which had partial success" , "Chandrayaan-3 will be launched by the Indian Space Research Organisation (ISRO)" , "The estimated cost of the mission is around $35 million" , "It will carry instruments to study the lunar surface and atmosphere" , "Chandrayaan-3 landed on the Moon's surface on 23rd August 2023" , "It consists of a lander named Vikram and a rover named Pragyan similar to Chandrayaan-2. Its propulsion module would act like an orbiter." , "The propulsion module carries the lander and rover configuration until the spacecraft is in a 100-kilometre (62 mi) lunar orbit" , "The mission used GSLV Mk III rocket for its launch" , "Chandrayaan-3 was launched from the Satish Dhawan Space Centre in Sriharikota" , "Chandrayaan-3 was launched earlier in the year 2023" , ] Then, generate sparse embeddings for each document.

Here, batch_size is optional and helps to process documents in batches. sparse_embeddings_list : list [ SparseEmbedding ] = list ( model . embed ( documents , batch_size = 6 ) ) Retrieve embeddings sparse_embeddings_list contains sparse embeddings for the documents provided earlier. Each element in this list is a SparseEmbedding object that contains the sparse vector representation of a document. index = 0 sparse_embeddings_list [ index ] This output is a SparseEmbedding object for the first document in our list. It contains two arrays: values and indices . - The values array represents the weights of the features (tokens) in the document. - The indices array represents the indices of these features in the model‚Äôs vocabulary.

Each pair of corresponding values and indices represents a token and its weight in the document.

SparseEmbedding ( values = array ([ 0.05297208 , 0.01963477 , 0.36459631 , 1.38508618 , 0.71776593 , 0.12667948 , 0.46230844 , 0.446771 , 0.26897505 , 1.01519883 , 1.5655334 , 0.29412213 , 1.53102326 , 0.59785569 , 1.1001817 , 0.02079751 , 0.09955651 , 0.44249091 , 0.09747757 , 1.53519952 , 1.36765671 , 0.15740395 , 0.49882549 , 0.38629025 , 0.76612782 , 1.25805044 , 0.39058095 , 0.27236196 , 0.45152301 , 0.48262018 , 0.26085234 , 1.35912788 , 0.70710695 , 1.71639752 ]), indices = array ([ 1010 , 1011 , 1016 , 1017 , 2001 , 2018 , 2034 , 2093 , 2117 , 2319 , 2353 , 2509 , 2634 , 2686 , 2796 , 2817 , 2922 , 2959 , 3003 , 3148 , 3260 , 3390 , 3462 , 3523 , 3822 , 4231 , 4316 , 4774 , 5590 , 5871 , 6416 , 11926 , 12076 , 16469 ])) Examine weights Now, print the first 5 features and their weights for better understanding. for i in range ( 5 ): print ( f "Token at index { sparse_embeddings_list [ 0 ] . indices [ i ] } has weight { sparse_embeddings_list [ 0 ] . values [ i ] } " ) The output will display the token indices and their corresponding weights for the first document.

Token at index 1010 has weight 0.05297207832336426 Token at index 1011 has weight 0.01963476650416851 Token at index 1016 has weight 0.36459630727767944 Token at index 1017 has weight 1.385086178779602 Token at index 2001 has weight 0.7177659273147583 Analyze results Let‚Äôs use the tokenizer vocab to make sense of these indices. import json from tokenizers import Tokenizer tokenizer = Tokenizer . from_pretrained ( "Qdrant/Splade_PP_en_v1" ) The get_tokens_and_weights function takes a SparseEmbedding object and a tokenizer as input. It will construct a dictionary where the keys are the decoded tokens, and the values are their corresponding weights. def get_tokens_and_weights ( sparse_embedding , tokenizer ): token_weight_dict = {} for i in range ( len ( sparse_embedding . indices )): token = tokenizer . decode ([ sparse_embedding . indices [ i ]]) weight = sparse_embedding . values [ i ] token_weight_dict [ token ] = weight # Sort the dictionary by weights token_weight_dict = dict ( sorted ( token_weight_dict . items (), key = lambda item : item [ 1 ], reverse = True )) return token_weight_dict # Test the function with the first SparseEmbedding print ( json . dumps ( get_tokens_and_weights ( sparse_embeddings_list [ index ], tokenizer ), indent = 4 )) Dictionary output The dictionary is then sorted by weights in descending order.

{ "chandra" : 1.7163975238800049 , "third" : 1.5655333995819092 , "##ya" : 1.535199522972107 , "india" : 1.5310232639312744 , "3" : 1.385086178779602 , "mission" : 1.3676567077636719 , "lunar" : 1.3591278791427612 , "moon" : 1.2580504417419434 , "indian" : 1.1001816987991333 , "##an" : 1.015198826789856 , "3rd" : 0.7661278247833252 , "was" : 0.7177659273147583 , "spacecraft" : 0.7071069478988647 , "space" : 0.5978556871414185 , "flight" : 0.4988254904747009 , "satellite" : 0.4826201796531677 , "first" : 0.46230843663215637 , "expedition" : 0.4515230059623718 , "three" : 0.4467709958553314 , "fourth" : 0.44249090552330017 , "vehicle" : 0.390580952167511 , "iii" : 0.3862902522087097 , "2" : 0.36459630727767944 , "##3" : 0.2941221296787262 , "planet" : 0.27236196398735046 , "second" : 0.26897504925727844 , "missions" : 0.2608523368835449 , "launched" : 0.15740394592285156 , "had" : 0.12667948007583618 , "largest" : 0.09955651313066483 , "leader" : 0.09747757017612457 , "," : 0.05297207832336426 , "study" : 0.02079751156270504 , "-" : 0.01963476650416851 } Observations The relative order of importance is quite useful. The most important tokens in the sentence have the highest weights.

Term Expansion: The model can expand the terms in the document. This means that the model can generate weights for tokens that are not present in the document but are related to the tokens in the document. This is a powerful feature that allows the model to capture the context of the document. Here, you‚Äôll see that the model has added the tokens ‚Äò3‚Äô from ‚Äôthird‚Äô and ‚Äòmoon‚Äô from ‚Äôlunar‚Äô to the sparse vector.

Design choices The weights are not normalized. This means that the sum of the weights is not 1 or 100. This is a common practice in sparse embeddings, as it allows the model to capture the importance of each token in the document.

Tokens are included in the sparse vector only if they are present in the model‚Äôs vocabulary. This means that the model will not generate a weight for tokens that it has not seen during training.

Tokens do not map to words directly ‚Äì allowing you to gracefully handle typo errors and out-of-vocabulary tokens.

================================================================================
PAGE 37/39
================================================================================
Title: How to Generate ColBERT Multivectors with FastEmbed
URL: https://qdrant.tech/documentation/fastembed/fastembed-colbert/
--------------------------------------------------------------------------------

How to Generate ColBERT Multivectors with FastEmbed ColBERT ColBERT is an embedding model that produces a matrix (multivector) representation of input text, generating one vector per token (a token being a meaningful text unit for a machine learning model).

This approach allows ColBERT to capture more nuanced input semantics than many dense embedding models, which represent an entire input with a single vector. By producing more granular input representations, ColBERT becomes a strong retriever. However, this advantage comes at the cost of increased resource consumption compared to traditional dense embedding models, both in terms of speed and memory.

Despite ColBERT being a powerful retriever, its speed limitation might make it less suitable for large-scale retrieval.

Therefore, we generally recommend using ColBERT for reranking a small set of already retrieved examples, rather than for first-stage retrieval.

A simple dense retriever can initially retrieve around 100-500 candidates, which can then be reranked with ColBERT to bring the most relevant results to the top.

ColBERT is a considerable alternative of a reranking model to cross-encoders , since it tends to be faster on inference time due to its late interaction mechanism.

How does late interaction work? Cross-encoders ingest a query and a document glued together as one input.

A cross-encoder model divides this input into meaningful (for the model) parts and checks how these parts relate.

So, all interactions between the query and the document happen ‚Äúearly‚Äù inside the model.

Late interaction models, such as ColBERT, only do the first part, generating document and query parts suitable for comparison.

All interactions between these parts are expected to be done ‚Äúlater‚Äù outside the model.

Using ColBERT in Qdrant Qdrant supports multivector representations out of the box so that you can use any late interaction model as ColBERT or ColPali in Qdrant without any additional pre/post-processing.

This tutorial uses ColBERT as a first-stage retriever on a toy dataset.

You can see how to use ColBERT as a reranker in our multi-stage queries documentation .

Setup Install fastembed . pip install fastembed Imports late interaction models for text embedding. from fastembed import LateInteractionTextEmbedding You can list which late interaction models are supported in FastEmbed.

LateInteractionTextEmbedding . list_supported_models () This command displays the available models. The output shows details about the model, including output embedding dimensions, model description, model size, model sources, and model file.

[{ 'model' : 'colbert-ir/colbertv2.0' , 'dim' : 128 , 'description' : 'Late interaction model' , 'size_in_GB' : 0.44 , 'sources' : { 'hf' : 'colbert-ir/colbertv2.0' }, 'model_file' : 'model.onnx' }, { 'model' : 'answerdotai/answerai-colbert-small-v1' , 'dim' : 96 , 'description' : 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, 2024 year' , 'size_in_GB' : 0.13 , 'sources' : { 'hf' : 'answerdotai/answerai-colbert-small-v1' }, 'model_file' : 'vespa_colbert.onnx' }] Now, load the model. model_name = "colbert-ir/colbertv2.0" embedding_model = LateInteractionTextEmbedding ( model_name ) The model files will be fetched and downloaded, with progress showing.

Embed data We will vectorize a toy movie description dataset with ColBERT: Movie description dataset descriptions = [ "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." , "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch." , "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist." , "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place." , "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past." , "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." , "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it." , "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop." , "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline." , "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent." , "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995)." , "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers." , "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home." , "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies." , "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in." , "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." , "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops." , "Story of 40-man Turkish task force who must defend a relay station." , "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour." , "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl." ] The vectorization is done with an embed generator function. descriptions_embeddings = list ( embedding_model . embed ( descriptions ) ) Let‚Äôs check the size of one of the produced embeddings. descriptions_embeddings [ 0 ] . shape We get the following result ( 48, 128 ) That means that for the first description, we have 48 vectors of lengths 128 representing it.

Upload embeddings to Qdrant Install qdrant-client pip install "qdrant-client>=1.14.2" Qdrant Client has a simple in-memory mode that allows you to experiment locally on small data volumes.

Alternatively, you could use for experiments a free cluster in Qdrant Cloud. from qdrant_client import QdrantClient , models qdrant_client = QdrantClient ( ":memory:" ) # Qdrant is running from RAM.

Now, let‚Äôs create a small collection with our movie data.

For that, we will use the multivectors functionality supported in Qdrant.

To configure multivector collection, we need to specify: similarity metric between vectors; the size of each vector (for ColBERT, it‚Äôs 128 ); similarity metric between multivectors (matrices), for example, maximum , so for vector from matrix A, we find the most similar vector from matrix B, and their similarity score will be out matrix similarity. qdrant_client . create_collection ( collection_name = "movies" , vectors_config = models .

VectorParams ( size = 128 , #size of each vector produced by ColBERT distance = models .

Distance .

COSINE , #similarity metric between each vector multivector_config = models .

MultiVectorConfig ( comparator = models .

MultiVectorComparator .

MAX_SIM #similarity metric between multivectors (matrices) ), ), ) To make this collection human-readable, let‚Äôs save movie metadata (name, description in text form and movie‚Äôs length) together with an embedded description.

Movie metadata metadata = [{ "movie_name" : "The Passion of Joan of Arc" , "movie_watch_time_min" : 114 , "movie_description" : "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." }, { "movie_name" : "Sherlock Jr." , "movie_watch_time_min" : 45 , "movie_description" : "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch." }, { "movie_name" : "Heat" , "movie_watch_time_min" : 170 , "movie_description" : "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist." }, { "movie_name" : "Kagemusha" , "movie_watch_time_min" : 162 , "movie_description" : "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place." }, { "movie_name" : "Kubo and the Two Strings" , "movie_watch_time_min" : 101 , "movie_description" : "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past." }, { "movie_name" : "Sardar Udham" , "movie_watch_time_min" : 164 , "movie_description" : "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." }, { "movie_name" : "Paprika" , "movie_watch_time_min" : 90 , "movie_description" : "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it." }, { "movie_name" : "After Hours" , "movie_watch_time_min" : 97 , "movie_description" : "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop." }, { "movie_name" : "Udta Punjab" , "movie_watch_time_min" : 148 , "movie_description" : "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline." }, { "movie_name" : "Philomena" , "movie_watch_time_min" : 98 , "movie_description" : "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent." }, { "movie_name" : "Neon Genesis Evangelion: The End of Evangelion" , "movie_watch_time_min" : 87 , "movie_description" : "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995)." }, { "movie_name" : "The Dirty Dozen" , "movie_watch_time_min" : 150 , "movie_description" : "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers." }, { "movie_name" : "Toy Story 3" , "movie_watch_time_min" : 103 , "movie_description" : "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home." }, { "movie_name" : "Edge of Tomorrow" , "movie_watch_time_min" : 113 , "movie_description" : "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies." }, { "movie_name" : "Some Like It Hot" , "movie_watch_time_min" : 121 , "movie_description" : "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in." }, { "movie_name" : "Snow White and the Seven Dwarfs" , "movie_watch_time_min" : 83 , "movie_description" : "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." }, { "movie_name" : "It Happened One Night" , "movie_watch_time_min" : 105 , "movie_description" : "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops." }, { "movie_name" : "Nefes: Vatan Sagolsun" , "movie_watch_time_min" : 128 , "movie_description" : "Story of 40-man Turkish task force who must defend a relay station." }, { "movie_name" : "This Is Spinal Tap" , "movie_watch_time_min" : 82 , "movie_description" : "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour." }, { "movie_name" : "Let the Right One In" , "movie_watch_time_min" : 114 , "movie_description" : "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl." }] qdrant_client . upload_points ( collection_name = "movies" , points = [ models .

PointStruct ( id = idx , payload = metadata [ idx ], vector = vector ) for idx , vector in enumerate ( descriptions_embeddings ) ], ) Upload with implicit embeddings computation description_documents = [ models .

Document ( text = description , model = model_name ) for description in descriptions ] qdrant_client . upload_points ( collection_name = "movies" , points = [ models .

PointStruct ( id = idx , payload = metadata [ idx ], vector = description_document ) for idx , description_document in enumerate ( description_documents ) ], ) Querying ColBERT uses two distinct methods for embedding documents and queries, as do we in Fastembed. However, we altered query pre-processing used in ColBERT, so we don‚Äôt have to cut all queries after 32-token length but ingest longer queries directly. qdrant_client . query_points ( collection_name = "movies" , query = list ( embedding_model . query_embed ( "A movie for kids with fantasy elements and wonders" ))[ 0 ], #converting generator object into numpy.ndarray limit = 1 , #How many closest to the query movies we would like to get #with_vectors=True, #If this option is used, vectors will also be returned with_payload = True #So metadata is provided in the output ) Query points with implicit embeddings computation query_document = models .

Document ( text = "A movie for kids with fantasy elements and wonders" , model = model_name ) qdrant_client . query_points ( collection_name = "movies" , query = query_document , limit = 1 , ) The result is the following: QueryResponse ( points =[ ScoredPoint ( id = 4, version = 0, score = 12.063469, payload ={ 'movie_name' : 'Kubo and the Two Strings' , 'movie_watch_time_min' : 101, 'movie_description' : 'A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past.' } , vector = None, shard_key = None, order_value = None )])
================================================================================
PAGE 38/39
================================================================================
Title: How to use rerankers with FastEmbed
URL: https://qdrant.tech/documentation/fastembed/fastembed-rerankers/
--------------------------------------------------------------------------------

How to use rerankers with FastEmbed Rerankers A reranker is a model that improves the ordering of search results. A subset of documents is initially retrieved using a fast, simple method (e.g., BM25 or dense embeddings). Then, a reranker ‚Äì a more powerful, precise, but slower and heavier model ‚Äì re-evaluates this subset to refine document relevance to the query.

Rerankers analyze token-level interactions between the query and each document in depth, making them expensive to use but precise in defining relevance. They trade speed for accuracy, so they are best used on a limited candidate set rather than the entire corpus.

Goal of this Tutorial It‚Äôs common to use cross-encoder models as rerankers. This tutorial uses Jina Reranker v2 Base Multilingual (licensed under CC-BY-NC-4.0) ‚Äì a cross-encoder reranker supported in FastEmbed.

We use the all-MiniLM-L6-v2 dense embedding model (also supported in FastEmbed) as a first-stage retriever and then refine results with Jina Reranker v2 .

Setup Install qdrant-client with fastembed . pip install "qdrant-client[fastembed]>=1.14.1" Import cross-encoders and text embeddings for the first-stage retrieval. from fastembed import TextEmbedding from fastembed.rerank.cross_encoder import TextCrossEncoder You can list the cross-encoder rerankers supported in FastEmbed using the following command.

TextCrossEncoder . list_supported_models () This command displays the available models, including details such as output embedding dimensions, model description, model size, model sources, and model file.

Avaliable models [{ 'model' : 'Xenova/ms-marco-MiniLM-L-6-v2' , 'size_in_GB' : 0.08 , 'sources' : { 'hf' : 'Xenova/ms-marco-MiniLM-L-6-v2' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'MiniLM-L-6-v2 model optimized for re-ranking tasks.' , 'license' : 'apache-2.0' }, { 'model' : 'Xenova/ms-marco-MiniLM-L-12-v2' , 'size_in_GB' : 0.12 , 'sources' : { 'hf' : 'Xenova/ms-marco-MiniLM-L-12-v2' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'MiniLM-L-12-v2 model optimized for re-ranking tasks.' , 'license' : 'apache-2.0' }, { 'model' : 'BAAI/bge-reranker-base' , 'size_in_GB' : 1.04 , 'sources' : { 'hf' : 'BAAI/bge-reranker-base' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'BGE reranker base model for cross-encoder re-ranking.' , 'license' : 'mit' }, { 'model' : 'jinaai/jina-reranker-v1-tiny-en' , 'size_in_GB' : 0.13 , 'sources' : { 'hf' : 'jinaai/jina-reranker-v1-tiny-en' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'Designed for blazing-fast re-ranking with 8K context length and fewer parameters than jina-reranker-v1-turbo-en.' , 'license' : 'apache-2.0' }, { 'model' : 'jinaai/jina-reranker-v1-turbo-en' , 'size_in_GB' : 0.15 , 'sources' : { 'hf' : 'jinaai/jina-reranker-v1-turbo-en' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'Designed for blazing-fast re-ranking with 8K context length.' , 'license' : 'apache-2.0' }, { 'model' : 'jinaai/jina-reranker-v2-base-multilingual' , 'size_in_GB' : 1.11 , 'sources' : { 'hf' : 'jinaai/jina-reranker-v2-base-multilingual' }, 'model_file' : 'onnx/model.onnx' , 'description' : 'A multi-lingual reranker model for cross-encoder re-ranking with 1K context length and sliding window' , 'license' : 'cc-by-nc-4.0' }] # some of the fields are omitted for brevity Now, load the first-stage retriever and reranker. encoder_name = "sentence-transformers/all-MiniLM-L6-v2" dense_embedding_model = TextEmbedding ( model_name = encoder_name ) reranker = TextCrossEncoder ( model_name = 'jinaai/jina-reranker-v2-base-multilingual' ) The model files will be fetched and downloaded, with progress displayed.

Embed & index data for the first-stage retrieval We will vectorize a toy movie description dataset using the all-MiniLM-L6-v2 model and save the embeddings in Qdrant for first-stage retrieval.

Then, we will use a cross-encoder reranking model to rerank a small subset of data retrieved in the first stage.

Movie description dataset descriptions = [ "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." , "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch." , "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist." , "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place." , "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past." , "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." , "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it." , "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop." , "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline." , "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent." , "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995)." , "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers." , "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home." , "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies." , "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in." , "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." , "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops." , "Story of 40-man Turkish task force who must defend a relay station." , "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour." , "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl." ] descriptions_embeddings = list ( dense_embedding_model . embed ( descriptions ) ) Let‚Äôs upload the embeddings to Qdrant.

Qdrant Client offers a simple in-memory mode, allowing you to experiment locally with small data volumes.

Alternatively, you can use a free cluster in Qdrant Cloud for experiments. from qdrant_client import QdrantClient , models client = QdrantClient ( ":memory:" ) # Qdrant is running from RAM.

Let‚Äôs create a collection with our movie data. client . create_collection ( collection_name = "movies" , vectors_config = { "embedding" : models .

VectorParams ( size = client . get_embedding_size ( "sentence-transformers/all-MiniLM-L6-v2" ), distance = models .

Distance .

COSINE ) } ) And upload the embeddings to it. client . upload_points ( collection_name = "movies" , points = [ models .

PointStruct ( id = idx , payload = { "description" : description }, vector = { "embedding" : vector } ) for idx , ( description , vector ) in enumerate ( zip ( descriptions , descriptions_embeddings ) ) ], ) Upload with implicit embeddings computation client . upload_points ( collection_name = "movies" , points = [ models .

PointStruct ( id = idx , payload = { "description" : description }, vector = { "embedding" : models .

Document ( text = description , model = encoder_name )}, ) for idx , description in enumerate ( descriptions ) ], ) First-stage retrieval Let‚Äôs see how relevant the results will be using only an all-MiniLM-L6-v2 -based dense retriever. query = "A story about a strong historically significant female figure." query_embedded = list ( dense_embedding_model . query_embed ( query ))[ 0 ] initial_retrieval = client . query_points ( collection_name = "movies" , using = "embedding" , query = query_embedded , with_payload = True , limit = 10 ) description_hits = [] for i , hit in enumerate ( initial_retrieval . points ): print ( f 'Result number { i + 1 } is \" { hit . payload [ "description" ] } \" ' ) description_hits . append ( hit . payload [ "description" ]) Query points with implicit embeddings computation query = "A story about a strong historically significant female figure." initial_retrieval = client . query_points ( collection_name = "movies" , using = "embedding" , query = models .

Document ( text = query , model = encoder_name ), with_payload = True , limit = 10 ) The result is as follows: Result number 1 is "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent." Result number 2 is "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." ...

Result number 9 is "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." Result number 10 is "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." We can see that the description of ‚ÄúThe Messenger: The Story of Joan of Arc‚Äù , which is the most fitting, appears 10th in the results.

Let‚Äôs try refining the order of the retrieved subset with Jina Reranker v2 . It takes a query and a set of documents (movie descriptions) as input and calculates a relevance score based on token-level interactions between the query and each document. new_scores = list ( reranker . rerank ( query , description_hits ) ) # returns scores between query and each document ranking = [ ( i , score ) for i , score in enumerate ( new_scores ) ] # saving document indices ranking . sort ( key = lambda x : x [ 1 ], reverse = True ) # sorting them in order of relevance defined by reranker for i , rank in enumerate ( ranking ): print ( f '''Reranked result number { i + 1 } is \" { description_hits [ rank [ 0 ]] } \" ''' ) The reranker moves the desired movie to the first position based on relevance.

Reranked result number 1 is "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." Reranked result number 2 is "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." ...

Reranked result number 9 is "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop." Reranked result number 10 is "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." Conclusion Rerankers refine search results by reordering retrieved candidates through deeper semantic analysis. For efficiency, they should be applied only to a small subset of retrieved results .

Balance speed and accuracy in search by leveraging the power of rerankers!

================================================================================
PAGE 39/39
================================================================================
Title: Multi-Vector Postprocessing
URL: https://qdrant.tech/documentation/fastembed/fastembed-postprocessing/
--------------------------------------------------------------------------------

Multi-Vector Postprocessing FastEmbed‚Äôs postprocessing module provides techniques for transforming and optimizing embeddings after generation. These postprocessing methods can improve search performance, reduce storage requirements, or adapt embeddings for specific use cases.

Currently, the postprocessing module includes MUVERA (Multi-Vector Retrieval Algorithm) for speeding up multi-vector embeddings. Additional postprocessing techniques are planned for future releases.

MUVERA MUVERA transforms variable-length sequences of vectors into fixed-dimensional single-vector representations. These approximations can be used for fast initial retrieval using traditional vector search methods like HNSW. Once you‚Äôve retrieved a small set of candidates quickly, you can then rerank them using the original multi-vector representations for maximum accuracy.

This hybrid approach combines the speed of single-vector search with the accuracy of multi-vector retrieval. Instead of comparing all documents in your collection using expensive multi-vector similarity computations, MUVERA lets you: Retrieve quickly : Use MUVERA embeddings to find the top candidates with traditional vector search with oversampling Rerank precisely : Apply multi-vector similarity with MaxSim only to this small candidate set The trade-off is increased storage requirements, as you need to store both the MUVERA embeddings and the original multi-vector representations. However, the performance gains make this approach practical for production systems with large document collections, and other techniques, such as off-loading to disk, may help you reduce the cost.

For a detailed technical explanation of how MUVERA works, see our article: MUVERA: Making Multivectors More Performant .

Using MUVERA in FastEmbed This tutorial demonstrates using MUVERA for fast retrieval with ColBERT reranking on a toy dataset. If you‚Äôre new to multi-vector embeddings, we recommend first reading How to Generate ColBERT Multivectors with FastEmbed .

Setup Install FastEmbed 0.7.2 or later to access MUVERA postprocessing. pip install "fastembed>=0.7.2" Import the necessary modules for late interaction embeddings and MUVERA postprocessing. from fastembed import LateInteractionTextEmbedding from fastembed.postprocess import Muvera Load Model and Create MUVERA Processor Load the ColBERT model and wrap it with a MUVERA processor. model_name = "colbert-ir/colbertv2.0" model = LateInteractionTextEmbedding ( model_name = model_name ) # Create MUVERA processor with recommended parameters muvera = Muvera . from_multivector_model ( model = model , k_sim = 6 , dim_proj = 32 , r_reps = 20 ) The MUVERA parameters control the size and quality of the resulting embeddings. These recommended values balance speed and accuracy. The k_sim parameter determines the number of clusters (2^6 = 64), dim_proj sets the projection dimensions, and r_reps specifies the number of repetitions for robustness.

Embed Data with ColBERT We‚Äôll use a toy movie description dataset to demonstrate MUVERA.

Movie description dataset descriptions = [ "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions." , "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch." , "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist." , "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place." , "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past." , "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre." , "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it." , "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop." , "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline." , "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent." , "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995)." , "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers." , "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home." , "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies." , "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in." , "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household." , "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops." , "Story of 40-man Turkish task force who must defend a relay station." , "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour." , "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl." ] Generate multi-vector embeddings for the movie descriptions. descriptions_embeddings = list ( model . embed ( descriptions )) Let‚Äôs check the shape of one of the multi-vector embeddings. descriptions_embeddings [ 0 ] . shape The first document consists of 33 tokens, each represented by a 128-dimensional vector.

( 33, 128 ) Process with MUVERA Now, transform the multi-vector embeddings into MUVERA‚Äôs single-vector representations. muvera_embeddings = [ muvera . process_document ( emb ) for emb in descriptions_embeddings ] Let‚Äôs check the shape of a MUVERA embedding. muvera_embeddings [ 0 ] . shape The MUVERA dimensionality depends on the method configuration, and in our case it will be quite high.

( 40960, ) The MUVERA embedding is a single vector with 40,960 dimensions. While this is larger than typical dense embeddings (which are usually a few hundred to a few thousand dimensions), it‚Äôs significantly faster to search than the original multi-vector representation because traditional vector search indexes like HNSW are optimized for single-vector similarity.

Upload to Qdrant Install qdrant-client . pip install "qdrant-client>=1.14.2" We‚Äôll use Qdrant running locally in a Docker container for this example. Alternatively, you can use a free cluster in Qdrant Cloud. from qdrant_client import QdrantClient , models client = QdrantClient ( "http://localhost:6333" ) Create a collection that stores both MUVERA embeddings and the original multi-vector representations using named vectors . client . create_collection ( collection_name = "movies-muvera" , vectors_config = { "muvera" : models .

VectorParams ( size = muvera . embedding_size , # Depends on the MUVERA configuration distance = models .

Distance .

COSINE ), "colbert" : models .

VectorParams ( size = model . embedding_size , # Model-specific distance = models .

Distance .

COSINE , multivector_config = models .

MultiVectorConfig ( comparator = models .

MultiVectorComparator .

MAX_SIM ) ) } ) Upload both representations to the collection. client . upload_points ( collection_name = "movies-muvera" , points = [ models .

PointStruct ( id = idx , payload = { "description" : description }, vector = { "muvera" : muvera_emb , "colbert" : colbert_emb } ) for idx , ( description , muvera_emb , colbert_emb ) in enumerate ( zip ( descriptions , muvera_embeddings , descriptions_embeddings ) ) ] ) Hybrid Search: MUVERA Retrieval + ColBERT Reranking Now let‚Äôs perform a search using the hybrid approach. Qdrant supports multi-stage queries through the prefetch parameter, which lets us combine MUVERA‚Äôs fast retrieval with ColBERT‚Äôs accurate rescoring in a single query.

First, create query embeddings in both formats. query = "A movie for kids with fantasy elements and wonders" query_multivec = list ( model . query_embed ( query ))[ 0 ] query_muvera = muvera . process_query ( query_multivec ) Now perform a two-stage query using Qdrant‚Äôs native multi-stage search: results = client . query_points ( collection_name = "movies-muvera" , prefetch = models .

Prefetch ( query = query_muvera , using = "muvera" , limit = 20 , # Stage 1: Retrieve 20 candidates with MUVERA (fast) ), query = query_multivec , # Stage 2: Rescore with ColBERT multi-vector (accurate) using = "colbert" , limit = 3 , # Return top 3 results after rescoring with_payload = True ) The prefetch parameter retrieves candidates using MUVERA, then the main query rescores those candidates using ColBERT‚Äôs multi-vector representation. Qdrant automatically handles the MaxSim computation for multi-vector similarity.

Display the results. for i , point in enumerate ( results . points , 1 ): print ( f 'Result { i } : " { point . payload [ "description" ] } "' ) print ( f "Score: { point . score : .2f } \n " ) Here is how they should look like for the toy dataset we‚Äôre using: Result 1: "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past." Score: 12.06 Result 2: "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl." Score: 10.75 Result 3: "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it." Score: 10.04 This hybrid approach maintains nearly the same accuracy as full multi-vector search across the entire collection while being significantly faster. The expensive multi-vector similarity computation is only applied to the 20 candidates retrieved by MUVERA rather than all documents in the collection.

Conclusion MUVERA postprocessing enables practical large-scale multi-vector search by creating fast-to-search approximations of multi-vector embeddings. The recommended approach combines MUVERA with Qdrant‚Äôs native multi-stage query capabilities: Fast retrieval : Use MUVERA embeddings with prefetch to retrieve candidate documents Precise reranking : Qdrant automatically rescores candidates with ColBERT multi-vectors This hybrid pattern scales efficiently to large collections by limiting expensive multi-vector computations to only the candidate set retrieved by MUVERA, while maintaining nearly identical search quality compared to pure multi-vector search.

The trade-off is increased storage, as you need to maintain both representations in your collection.

MUVERA is particularly valuable for production systems with large document collections where multi-vector search would otherwise be too slow for first-stage retrieval. The combination of FastEmbed‚Äôs MUVERA postprocessing and Qdrant‚Äôs multi-stage queries provides a seamless, performant solution.

Upgrade to FastEmbed 0.7.2 or later with pip install --upgrade fastembed to start using MUVERA postprocessing today.
